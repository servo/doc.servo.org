initSidebarItems({"constant":[["_PREFETCH_LOCALITY0","See `prefetch`."],["_PREFETCH_LOCALITY1","See `prefetch`."],["_PREFETCH_LOCALITY2","See `prefetch`."],["_PREFETCH_LOCALITY3","See `prefetch`."],["_PREFETCH_READ","See `prefetch`."],["_PREFETCH_WRITE","See `prefetch`."],["_TMFAILURE_CNCL","Transaction executed a TCANCEL instruction"],["_TMFAILURE_DBG","Transaction aborted due to a debug trap."],["_TMFAILURE_ERR","Transaction aborted because a non-permissible operation was attempted"],["_TMFAILURE_IMP","Fallback error type for any other reason"],["_TMFAILURE_INT","Transaction failed from interrupt"],["_TMFAILURE_MEM","Transaction aborted because a conflict occurred"],["_TMFAILURE_NEST","Transaction aborted due to transactional nesting level was exceeded"],["_TMFAILURE_REASON","Extraction mask for failure reason"],["_TMFAILURE_RTRY","Transaction retry is possible."],["_TMFAILURE_SIZE","Transaction aborted due to read or write set limit was exceeded"],["_TMFAILURE_TRIVIAL","Indicates a TRIVIAL version of TM is available"],["_TMSTART_SUCCESS","Transaction successfully started."]],"fn":[["__breakpoint","Inserts a breakpoint instruction."],["__crc32b","CRC32 single round checksum for bytes (8 bits)."],["__crc32cb","CRC32-C single round checksum for bytes (8 bits)."],["__crc32cd","CRC32-C single round checksum for quad words (64 bits)."],["__crc32ch","CRC32-C single round checksum for half words (16 bits)."],["__crc32cw","CRC32-C single round checksum for words (32 bits)."],["__crc32d","CRC32 single round checksum for quad words (64 bits)."],["__crc32h","CRC32 single round checksum for half words (16 bits)."],["__crc32w","CRC32 single round checksum for words (32 bits)."],["__dmb","Generates a DMB (data memory barrier) instruction or equivalent CP15 instruction."],["__dsb","Generates a DSB (data synchronization barrier) instruction or equivalent CP15 instruction."],["__isb","Generates an ISB (instruction synchronization barrier) instruction or equivalent CP15 instruction."],["__nop","Generates an unspecified no-op instruction."],["__rsr","Reads a 32-bit system register"],["__rsrp","Reads a system register containing an address"],["__sev","Generates a SEV (send a global event) hint instruction."],["__sevl","Generates a send a local event hint instruction."],["__tcancel","Cancels the current transaction and discards all state modifications that were performed transactionally."],["__tcommit","Commits the current transaction. For a nested transaction, the only effect is that the transactional nesting depth is decreased. For an outer transaction, the state modifications performed transactionally are committed to the architectural state."],["__tstart","Starts a new transaction. When the transaction starts successfully the return value is 0. If the transaction fails, all state modifications are discarded and a cause of the failure is encoded in the return value."],["__ttest","Tests if executing inside a transaction. If no transaction is currently executing, the return value is 0. Otherwise, this intrinsic returns the depth of the transaction."],["__wfe","Generates a WFE (wait for event) hint instruction, or nothing."],["__wfi","Generates a WFI (wait for interrupt) hint instruction, or nothing."],["__wsr","Writes a 32-bit system register"],["__wsrp","Writes a system register containing an address"],["__yield","Generates a YIELD hint instruction."],["_cls_u32","Counts the leading most significant bits set."],["_cls_u64","Counts the leading most significant bits set."],["_clz_u64","Count Leading Zeros."],["_prefetch","Fetch the cache line that contains address `p` using the given `RW` and `LOCALITY`."],["_rbit_u64","Reverse the bit order."],["_rev_u64","Reverse the order of the bytes."],["brk","Generates the trap instruction `BRK 1`"],["vaba_s16",""],["vaba_s32",""],["vaba_s8",""],["vaba_u16",""],["vaba_u32",""],["vaba_u8",""],["vabal_high_s16","Signed Absolute difference and Accumulate Long"],["vabal_high_s32","Signed Absolute difference and Accumulate Long"],["vabal_high_s8","Signed Absolute difference and Accumulate Long"],["vabal_high_u16","Unsigned Absolute difference and Accumulate Long"],["vabal_high_u32","Unsigned Absolute difference and Accumulate Long"],["vabal_high_u8","Unsigned Absolute difference and Accumulate Long"],["vabal_s16","Signed Absolute difference and Accumulate Long"],["vabal_s32","Signed Absolute difference and Accumulate Long"],["vabal_s8","Signed Absolute difference and Accumulate Long"],["vabal_u16","Unsigned Absolute difference and Accumulate Long"],["vabal_u32","Unsigned Absolute difference and Accumulate Long"],["vabal_u8","Unsigned Absolute difference and Accumulate Long"],["vabaq_s16",""],["vabaq_s32",""],["vabaq_s8",""],["vabaq_u16",""],["vabaq_u32",""],["vabaq_u8",""],["vabd_f32","Absolute difference between the arguments of Floating"],["vabd_f64","Absolute difference between the arguments of Floating"],["vabd_s16","Absolute difference between the arguments"],["vabd_s32","Absolute difference between the arguments"],["vabd_s8","Absolute difference between the arguments"],["vabd_u16","Absolute difference between the arguments"],["vabd_u32","Absolute difference between the arguments"],["vabd_u8","Absolute difference between the arguments"],["vabdd_f64","Floating-point absolute difference"],["vabdl_high_s16","Signed Absolute difference Long"],["vabdl_high_s32","Signed Absolute difference Long"],["vabdl_high_s8","Signed Absolute difference Long"],["vabdl_high_u16","Unsigned Absolute difference Long"],["vabdl_high_u32","Unsigned Absolute difference Long"],["vabdl_high_u8","Unsigned Absolute difference Long"],["vabdl_s16","Signed Absolute difference Long"],["vabdl_s32","Signed Absolute difference Long"],["vabdl_s8","Signed Absolute difference Long"],["vabdl_u16","Unsigned Absolute difference Long"],["vabdl_u32","Unsigned Absolute difference Long"],["vabdl_u8","Unsigned Absolute difference Long"],["vabdq_f32","Absolute difference between the arguments of Floating"],["vabdq_f64","Absolute difference between the arguments of Floating"],["vabdq_s16","Absolute difference between the arguments"],["vabdq_s32","Absolute difference between the arguments"],["vabdq_s8","Absolute difference between the arguments"],["vabdq_u16","Absolute difference between the arguments"],["vabdq_u32","Absolute difference between the arguments"],["vabdq_u8","Absolute difference between the arguments"],["vabds_f32","Floating-point absolute difference"],["vabs_f32","Floating-point absolute value"],["vabs_f64","Floating-point absolute value"],["vabs_s16","Absolute value (wrapping)."],["vabs_s32","Absolute value (wrapping)."],["vabs_s64","Absolute Value (wrapping)."],["vabs_s8","Absolute value (wrapping)."],["vabsd_s64","Absolute Value (wrapping)."],["vabsq_f32","Floating-point absolute value"],["vabsq_f64","Floating-point absolute value"],["vabsq_s16","Absolute value (wrapping)."],["vabsq_s32","Absolute value (wrapping)."],["vabsq_s64","Absolute Value (wrapping)."],["vabsq_s8","Absolute value (wrapping)."],["vadd_f32","Vector add."],["vadd_f64","Vector add."],["vadd_p16","Bitwise exclusive OR"],["vadd_p64","Bitwise exclusive OR"],["vadd_p8","Bitwise exclusive OR"],["vadd_s16","Vector add."],["vadd_s32","Vector add."],["vadd_s64","Vector add."],["vadd_s8","Vector add."],["vadd_u16","Vector add."],["vadd_u32","Vector add."],["vadd_u64","Vector add."],["vadd_u8","Vector add."],["vaddd_s64","Vector add."],["vaddd_u64","Vector add."],["vaddhn_high_s16","Add returning High Narrow (high half)."],["vaddhn_high_s32","Add returning High Narrow (high half)."],["vaddhn_high_s64","Add returning High Narrow (high half)."],["vaddhn_high_u16","Add returning High Narrow (high half)."],["vaddhn_high_u32","Add returning High Narrow (high half)."],["vaddhn_high_u64","Add returning High Narrow (high half)."],["vaddhn_s16","Add returning High Narrow."],["vaddhn_s32","Add returning High Narrow."],["vaddhn_s64","Add returning High Narrow."],["vaddhn_u16","Add returning High Narrow."],["vaddhn_u32","Add returning High Narrow."],["vaddhn_u64","Add returning High Narrow."],["vaddl_high_s16","Signed Add Long (vector, high half)."],["vaddl_high_s32","Signed Add Long (vector, high half)."],["vaddl_high_s8","Signed Add Long (vector, high half)."],["vaddl_high_u16","Unsigned Add Long (vector, high half)."],["vaddl_high_u32","Unsigned Add Long (vector, high half)."],["vaddl_high_u8","Unsigned Add Long (vector, high half)."],["vaddl_s16","Signed Add Long (vector)."],["vaddl_s32","Signed Add Long (vector)."],["vaddl_s8","Signed Add Long (vector)."],["vaddl_u16","Unsigned Add Long (vector)."],["vaddl_u32","Unsigned Add Long (vector)."],["vaddl_u8","Unsigned Add Long (vector)."],["vaddlv_s16","Signed Add Long across Vector"],["vaddlv_s32","Signed Add Long across Vector"],["vaddlv_s8","Signed Add Long across Vector"],["vaddlv_u16","Unsigned Add Long across Vector"],["vaddlv_u32","Unsigned Add Long across Vector"],["vaddlv_u8","Unsigned Add Long across Vector"],["vaddlvq_s16","Signed Add Long across Vector"],["vaddlvq_s32","Signed Add Long across Vector"],["vaddlvq_s8","Signed Add Long across Vector"],["vaddlvq_u16","Unsigned Add Long across Vector"],["vaddlvq_u32","Unsigned Add Long across Vector"],["vaddlvq_u8","Unsigned Add Long across Vector"],["vaddq_f32","Vector add."],["vaddq_f64","Vector add."],["vaddq_p128","Bitwise exclusive OR"],["vaddq_p16","Bitwise exclusive OR"],["vaddq_p64","Bitwise exclusive OR"],["vaddq_p8","Bitwise exclusive OR"],["vaddq_s16","Vector add."],["vaddq_s32","Vector add."],["vaddq_s64","Vector add."],["vaddq_s8","Vector add."],["vaddq_u16","Vector add."],["vaddq_u32","Vector add."],["vaddq_u64","Vector add."],["vaddq_u8","Vector add."],["vaddv_f32","Floating-point add across vector"],["vaddv_s16","Add across vector"],["vaddv_s32","Add across vector"],["vaddv_s8","Add across vector"],["vaddv_u16","Add across vector"],["vaddv_u32","Add across vector"],["vaddv_u8","Add across vector"],["vaddvq_f32","Floating-point add across vector"],["vaddvq_f64","Floating-point add across vector"],["vaddvq_s16","Add across vector"],["vaddvq_s32","Add across vector"],["vaddvq_s64","Add across vector"],["vaddvq_s8","Add across vector"],["vaddvq_u16","Add across vector"],["vaddvq_u32","Add across vector"],["vaddvq_u64","Add across vector"],["vaddvq_u8","Add across vector"],["vaddw_high_s16","Signed Add Wide (high half)."],["vaddw_high_s32","Signed Add Wide (high half)."],["vaddw_high_s8","Signed Add Wide (high half)."],["vaddw_high_u16","Unsigned Add Wide (high half)."],["vaddw_high_u32","Unsigned Add Wide (high half)."],["vaddw_high_u8","Unsigned Add Wide (high half)."],["vaddw_s16","Signed Add Wide."],["vaddw_s32","Signed Add Wide."],["vaddw_s8","Signed Add Wide."],["vaddw_u16","Unsigned Add Wide."],["vaddw_u32","Unsigned Add Wide."],["vaddw_u8","Unsigned Add Wide."],["vaesdq_u8","AES single round decryption."],["vaeseq_u8","AES single round encryption."],["vaesimcq_u8","AES inverse mix columns."],["vaesmcq_u8","AES mix columns."],["vand_s16","Vector bitwise and"],["vand_s32","Vector bitwise and"],["vand_s64","Vector bitwise and"],["vand_s8","Vector bitwise and"],["vand_u16","Vector bitwise and"],["vand_u32","Vector bitwise and"],["vand_u64","Vector bitwise and"],["vand_u8","Vector bitwise and"],["vandq_s16","Vector bitwise and"],["vandq_s32","Vector bitwise and"],["vandq_s64","Vector bitwise and"],["vandq_s8","Vector bitwise and"],["vandq_u16","Vector bitwise and"],["vandq_u32","Vector bitwise and"],["vandq_u64","Vector bitwise and"],["vandq_u8","Vector bitwise and"],["vbcaxq_s16","Bit clear and exclusive OR"],["vbcaxq_s32","Bit clear and exclusive OR"],["vbcaxq_s64","Bit clear and exclusive OR"],["vbcaxq_s8","Bit clear and exclusive OR"],["vbcaxq_u16","Bit clear and exclusive OR"],["vbcaxq_u32","Bit clear and exclusive OR"],["vbcaxq_u64","Bit clear and exclusive OR"],["vbcaxq_u8","Bit clear and exclusive OR"],["vbic_s16","Vector bitwise bit clear"],["vbic_s32","Vector bitwise bit clear"],["vbic_s64","Vector bitwise bit clear"],["vbic_s8","Vector bitwise bit clear"],["vbic_u16","Vector bitwise bit clear"],["vbic_u32","Vector bitwise bit clear"],["vbic_u64","Vector bitwise bit clear"],["vbic_u8","Vector bitwise bit clear"],["vbicq_s16","Vector bitwise bit clear"],["vbicq_s32","Vector bitwise bit clear"],["vbicq_s64","Vector bitwise bit clear"],["vbicq_s8","Vector bitwise bit clear"],["vbicq_u16","Vector bitwise bit clear"],["vbicq_u32","Vector bitwise bit clear"],["vbicq_u64","Vector bitwise bit clear"],["vbicq_u8","Vector bitwise bit clear"],["vbsl_f32","Bitwise Select."],["vbsl_f64","Bitwise Select instructions. This instruction sets each bit in the destination SIMD&FP register to the corresponding bit from the first source SIMD&FP register when the original destination bit was 1, otherwise from the second source SIMD&FP register."],["vbsl_p16","Bitwise Select."],["vbsl_p64","Bitwise Select."],["vbsl_p8","Bitwise Select."],["vbsl_s16","Bitwise Select."],["vbsl_s32","Bitwise Select."],["vbsl_s64","Bitwise Select."],["vbsl_s8","Bitwise Select instructions. This instruction sets each bit in the destination SIMD&FP register to the corresponding bit from the first source SIMD&FP register when the original destination bit was 1, otherwise from the second source SIMD&FP register. Bitwise Select."],["vbsl_u16","Bitwise Select."],["vbsl_u32","Bitwise Select."],["vbsl_u64","Bitwise Select."],["vbsl_u8","Bitwise Select."],["vbslq_f32","Bitwise Select. (128-bit)"],["vbslq_f64","Bitwise Select. (128-bit)"],["vbslq_p16","Bitwise Select. (128-bit)"],["vbslq_p64","Bitwise Select. (128-bit)"],["vbslq_p8","Bitwise Select. (128-bit)"],["vbslq_s16","Bitwise Select. (128-bit)"],["vbslq_s32","Bitwise Select. (128-bit)"],["vbslq_s64","Bitwise Select. (128-bit)"],["vbslq_s8","Bitwise Select. (128-bit)"],["vbslq_u16","Bitwise Select. (128-bit)"],["vbslq_u32","Bitwise Select. (128-bit)"],["vbslq_u64","Bitwise Select. (128-bit)"],["vbslq_u8","Bitwise Select. (128-bit)"],["vcadd_rot270_f32","Floating-point complex add"],["vcadd_rot90_f32","Floating-point complex add"],["vcaddq_rot270_f32","Floating-point complex add"],["vcaddq_rot270_f64","Floating-point complex add"],["vcaddq_rot90_f32","Floating-point complex add"],["vcaddq_rot90_f64","Floating-point complex add"],["vcage_f32","Floating-point absolute compare greater than or equal"],["vcage_f64","Floating-point absolute compare greater than or equal"],["vcaged_f64","Floating-point absolute compare greater than or equal"],["vcageq_f32","Floating-point absolute compare greater than or equal"],["vcageq_f64","Floating-point absolute compare greater than or equal"],["vcages_f32","Floating-point absolute compare greater than or equal"],["vcagt_f32","Floating-point absolute compare greater than"],["vcagt_f64","Floating-point absolute compare greater than"],["vcagtd_f64","Floating-point absolute compare greater than"],["vcagtq_f32","Floating-point absolute compare greater than"],["vcagtq_f64","Floating-point absolute compare greater than"],["vcagts_f32","Floating-point absolute compare greater than"],["vcale_f32","Floating-point absolute compare less than or equal"],["vcale_f64","Floating-point absolute compare less than or equal"],["vcaled_f64","Floating-point absolute compare less than or equal"],["vcaleq_f32","Floating-point absolute compare less than or equal"],["vcaleq_f64","Floating-point absolute compare less than or equal"],["vcales_f32","Floating-point absolute compare less than or equal"],["vcalt_f32","Floating-point absolute compare less than"],["vcalt_f64","Floating-point absolute compare less than"],["vcaltd_f64","Floating-point absolute compare less than"],["vcaltq_f32","Floating-point absolute compare less than"],["vcaltq_f64","Floating-point absolute compare less than"],["vcalts_f32","Floating-point absolute compare less than"],["vceq_f32","Floating-point compare equal"],["vceq_f64","Floating-point compare equal"],["vceq_p64","Compare bitwise Equal (vector)"],["vceq_p8","Compare bitwise Equal (vector)"],["vceq_s16","Compare bitwise Equal (vector)"],["vceq_s32","Compare bitwise Equal (vector)"],["vceq_s64","Compare bitwise Equal (vector)"],["vceq_s8","Compare bitwise Equal (vector)"],["vceq_u16","Compare bitwise Equal (vector)"],["vceq_u32","Compare bitwise Equal (vector)"],["vceq_u64","Compare bitwise Equal (vector)"],["vceq_u8","Compare bitwise Equal (vector)"],["vceqd_f64","Floating-point compare equal"],["vceqd_s64","Compare bitwise equal"],["vceqd_u64","Compare bitwise equal"],["vceqq_f32","Floating-point compare equal"],["vceqq_f64","Floating-point compare equal"],["vceqq_p64","Compare bitwise Equal (vector)"],["vceqq_p8","Compare bitwise Equal (vector)"],["vceqq_s16","Compare bitwise Equal (vector)"],["vceqq_s32","Compare bitwise Equal (vector)"],["vceqq_s64","Compare bitwise Equal (vector)"],["vceqq_s8","Compare bitwise Equal (vector)"],["vceqq_u16","Compare bitwise Equal (vector)"],["vceqq_u32","Compare bitwise Equal (vector)"],["vceqq_u64","Compare bitwise Equal (vector)"],["vceqq_u8","Compare bitwise Equal (vector)"],["vceqs_f32","Floating-point compare equal"],["vceqz_f32","Floating-point compare bitwise equal to zero"],["vceqz_f64","Floating-point compare bitwise equal to zero"],["vceqz_p64","Signed compare bitwise equal to zero"],["vceqz_p8","Signed compare bitwise equal to zero"],["vceqz_s16","Signed compare bitwise equal to zero"],["vceqz_s32","Signed compare bitwise equal to zero"],["vceqz_s64","Signed compare bitwise equal to zero"],["vceqz_s8","Signed compare bitwise equal to zero"],["vceqz_u16","Unsigned compare bitwise equal to zero"],["vceqz_u32","Unsigned compare bitwise equal to zero"],["vceqz_u64","Unsigned compare bitwise equal to zero"],["vceqz_u8","Unsigned compare bitwise equal to zero"],["vceqzd_f64","Floating-point compare bitwise equal to zero"],["vceqzd_s64","Compare bitwise equal to zero"],["vceqzd_u64","Compare bitwise equal to zero"],["vceqzq_f32","Floating-point compare bitwise equal to zero"],["vceqzq_f64","Floating-point compare bitwise equal to zero"],["vceqzq_p64","Signed compare bitwise equal to zero"],["vceqzq_p8","Signed compare bitwise equal to zero"],["vceqzq_s16","Signed compare bitwise equal to zero"],["vceqzq_s32","Signed compare bitwise equal to zero"],["vceqzq_s64","Signed compare bitwise equal to zero"],["vceqzq_s8","Signed compare bitwise equal to zero"],["vceqzq_u16","Unsigned compare bitwise equal to zero"],["vceqzq_u32","Unsigned compare bitwise equal to zero"],["vceqzq_u64","Unsigned compare bitwise equal to zero"],["vceqzq_u8","Unsigned compare bitwise equal to zero"],["vceqzs_f32","Floating-point compare bitwise equal to zero"],["vcge_f32","Floating-point compare greater than or equal"],["vcge_f64","Floating-point compare greater than or equal"],["vcge_s16","Compare signed greater than or equal"],["vcge_s32","Compare signed greater than or equal"],["vcge_s64","Compare signed greater than or equal"],["vcge_s8","Compare signed greater than or equal"],["vcge_u16","Compare unsigned greater than or equal"],["vcge_u32","Compare unsigned greater than or equal"],["vcge_u64","Compare unsigned greater than or equal"],["vcge_u8","Compare unsigned greater than or equal"],["vcged_f64","Floating-point compare greater than or equal"],["vcged_s64","Compare greater than or equal"],["vcged_u64","Compare greater than or equal"],["vcgeq_f32","Floating-point compare greater than or equal"],["vcgeq_f64","Floating-point compare greater than or equal"],["vcgeq_s16","Compare signed greater than or equal"],["vcgeq_s32","Compare signed greater than or equal"],["vcgeq_s64","Compare signed greater than or equal"],["vcgeq_s8","Compare signed greater than or equal"],["vcgeq_u16","Compare unsigned greater than or equal"],["vcgeq_u32","Compare unsigned greater than or equal"],["vcgeq_u64","Compare unsigned greater than or equal"],["vcgeq_u8","Compare unsigned greater than or equal"],["vcges_f32","Floating-point compare greater than or equal"],["vcgez_f32","Floating-point compare greater than or equal to zero"],["vcgez_f64","Floating-point compare greater than or equal to zero"],["vcgez_s16","Compare signed greater than or equal to zero"],["vcgez_s32","Compare signed greater than or equal to zero"],["vcgez_s64","Compare signed greater than or equal to zero"],["vcgez_s8","Compare signed greater than or equal to zero"],["vcgezd_f64","Floating-point compare greater than or equal to zero"],["vcgezd_s64","Compare signed greater than or equal to zero"],["vcgezq_f32","Floating-point compare greater than or equal to zero"],["vcgezq_f64","Floating-point compare greater than or equal to zero"],["vcgezq_s16","Compare signed greater than or equal to zero"],["vcgezq_s32","Compare signed greater than or equal to zero"],["vcgezq_s64","Compare signed greater than or equal to zero"],["vcgezq_s8","Compare signed greater than or equal to zero"],["vcgezs_f32","Floating-point compare greater than or equal to zero"],["vcgt_f32","Floating-point compare greater than"],["vcgt_f64","Floating-point compare greater than"],["vcgt_s16","Compare signed greater than"],["vcgt_s32","Compare signed greater than"],["vcgt_s64","Compare signed greater than"],["vcgt_s8","Compare signed greater than"],["vcgt_u16","Compare unsigned highe"],["vcgt_u32","Compare unsigned highe"],["vcgt_u64","Compare unsigned highe"],["vcgt_u8","Compare unsigned highe"],["vcgtd_f64","Floating-point compare greater than"],["vcgtd_s64","Compare greater than"],["vcgtd_u64","Compare greater than"],["vcgtq_f32","Floating-point compare greater than"],["vcgtq_f64","Floating-point compare greater than"],["vcgtq_s16","Compare signed greater than"],["vcgtq_s32","Compare signed greater than"],["vcgtq_s64","Compare signed greater than"],["vcgtq_s8","Compare signed greater than"],["vcgtq_u16","Compare unsigned highe"],["vcgtq_u32","Compare unsigned highe"],["vcgtq_u64","Compare unsigned highe"],["vcgtq_u8","Compare unsigned highe"],["vcgts_f32","Floating-point compare greater than"],["vcgtz_f32","Floating-point compare greater than zero"],["vcgtz_f64","Floating-point compare greater than zero"],["vcgtz_s16","Compare signed greater than zero"],["vcgtz_s32","Compare signed greater than zero"],["vcgtz_s64","Compare signed greater than zero"],["vcgtz_s8","Compare signed greater than zero"],["vcgtzd_f64","Floating-point compare greater than zero"],["vcgtzd_s64","Compare signed greater than zero"],["vcgtzq_f32","Floating-point compare greater than zero"],["vcgtzq_f64","Floating-point compare greater than zero"],["vcgtzq_s16","Compare signed greater than zero"],["vcgtzq_s32","Compare signed greater than zero"],["vcgtzq_s64","Compare signed greater than zero"],["vcgtzq_s8","Compare signed greater than zero"],["vcgtzs_f32","Floating-point compare greater than zero"],["vcle_f32","Floating-point compare less than or equal"],["vcle_f64","Floating-point compare less than or equal"],["vcle_s16","Compare signed less than or equal"],["vcle_s32","Compare signed less than or equal"],["vcle_s64","Compare signed less than or equal"],["vcle_s8","Compare signed less than or equal"],["vcle_u16","Compare unsigned less than or equal"],["vcle_u32","Compare unsigned less than or equal"],["vcle_u64","Compare unsigned less than or equal"],["vcle_u8","Compare unsigned less than or equal"],["vcled_f64","Floating-point compare less than or equal"],["vcled_s64","Compare less than or equal"],["vcled_u64","Compare less than or equal"],["vcleq_f32","Floating-point compare less than or equal"],["vcleq_f64","Floating-point compare less than or equal"],["vcleq_s16","Compare signed less than or equal"],["vcleq_s32","Compare signed less than or equal"],["vcleq_s64","Compare signed less than or equal"],["vcleq_s8","Compare signed less than or equal"],["vcleq_u16","Compare unsigned less than or equal"],["vcleq_u32","Compare unsigned less than or equal"],["vcleq_u64","Compare unsigned less than or equal"],["vcleq_u8","Compare unsigned less than or equal"],["vcles_f32","Floating-point compare less than or equal"],["vclez_f32","Floating-point compare less than or equal to zero"],["vclez_f64","Floating-point compare less than or equal to zero"],["vclez_s16","Compare signed less than or equal to zero"],["vclez_s32","Compare signed less than or equal to zero"],["vclez_s64","Compare signed less than or equal to zero"],["vclez_s8","Compare signed less than or equal to zero"],["vclezd_f64","Floating-point compare less than or equal to zero"],["vclezd_s64","Compare less than or equal to zero"],["vclezq_f32","Floating-point compare less than or equal to zero"],["vclezq_f64","Floating-point compare less than or equal to zero"],["vclezq_s16","Compare signed less than or equal to zero"],["vclezq_s32","Compare signed less than or equal to zero"],["vclezq_s64","Compare signed less than or equal to zero"],["vclezq_s8","Compare signed less than or equal to zero"],["vclezs_f32","Floating-point compare less than or equal to zero"],["vcls_s16","Count leading sign bits"],["vcls_s32","Count leading sign bits"],["vcls_s8","Count leading sign bits"],["vcls_u16","Count leading sign bits"],["vcls_u32","Count leading sign bits"],["vcls_u8","Count leading sign bits"],["vclsq_s16","Count leading sign bits"],["vclsq_s32","Count leading sign bits"],["vclsq_s8","Count leading sign bits"],["vclsq_u16","Count leading sign bits"],["vclsq_u32","Count leading sign bits"],["vclsq_u8","Count leading sign bits"],["vclt_f32","Floating-point compare less than"],["vclt_f64","Floating-point compare less than"],["vclt_s16","Compare signed less than"],["vclt_s32","Compare signed less than"],["vclt_s64","Compare signed less than"],["vclt_s8","Compare signed less than"],["vclt_u16","Compare unsigned less than"],["vclt_u32","Compare unsigned less than"],["vclt_u64","Compare unsigned less than"],["vclt_u8","Compare unsigned less than"],["vcltd_f64","Floating-point compare less than"],["vcltd_s64","Compare less than"],["vcltd_u64","Compare less than"],["vcltq_f32","Floating-point compare less than"],["vcltq_f64","Floating-point compare less than"],["vcltq_s16","Compare signed less than"],["vcltq_s32","Compare signed less than"],["vcltq_s64","Compare signed less than"],["vcltq_s8","Compare signed less than"],["vcltq_u16","Compare unsigned less than"],["vcltq_u32","Compare unsigned less than"],["vcltq_u64","Compare unsigned less than"],["vcltq_u8","Compare unsigned less than"],["vclts_f32","Floating-point compare less than"],["vcltz_f32","Floating-point compare less than zero"],["vcltz_f64","Floating-point compare less than zero"],["vcltz_s16","Compare signed less than zero"],["vcltz_s32","Compare signed less than zero"],["vcltz_s64","Compare signed less than zero"],["vcltz_s8","Compare signed less than zero"],["vcltzd_f64","Floating-point compare less than zero"],["vcltzd_s64","Compare less than zero"],["vcltzq_f32","Floating-point compare less than zero"],["vcltzq_f64","Floating-point compare less than zero"],["vcltzq_s16","Compare signed less than zero"],["vcltzq_s32","Compare signed less than zero"],["vcltzq_s64","Compare signed less than zero"],["vcltzq_s8","Compare signed less than zero"],["vcltzs_f32","Floating-point compare less than zero"],["vclz_s16","Count leading zero bits"],["vclz_s32","Count leading zero bits"],["vclz_s8","Count leading zero bits"],["vclz_u16","Count leading zero bits"],["vclz_u32","Count leading zero bits"],["vclz_u8","Count leading zero bits"],["vclzq_s16","Count leading zero bits"],["vclzq_s32","Count leading zero bits"],["vclzq_s8","Count leading zero bits"],["vclzq_u16","Count leading zero bits"],["vclzq_u32","Count leading zero bits"],["vclzq_u8","Count leading zero bits"],["vcmla_f32","Floating-point complex multiply accumulate"],["vcmla_lane_f32","Floating-point complex multiply accumulate"],["vcmla_laneq_f32","Floating-point complex multiply accumulate"],["vcmla_rot180_f32","Floating-point complex multiply accumulate"],["vcmla_rot180_lane_f32","Floating-point complex multiply accumulate"],["vcmla_rot180_laneq_f32","Floating-point complex multiply accumulate"],["vcmla_rot270_f32","Floating-point complex multiply accumulate"],["vcmla_rot270_lane_f32","Floating-point complex multiply accumulate"],["vcmla_rot270_laneq_f32","Floating-point complex multiply accumulate"],["vcmla_rot90_f32","Floating-point complex multiply accumulate"],["vcmla_rot90_lane_f32","Floating-point complex multiply accumulate"],["vcmla_rot90_laneq_f32","Floating-point complex multiply accumulate"],["vcmlaq_f32","Floating-point complex multiply accumulate"],["vcmlaq_f64","Floating-point complex multiply accumulate"],["vcmlaq_lane_f32","Floating-point complex multiply accumulate"],["vcmlaq_laneq_f32","Floating-point complex multiply accumulate"],["vcmlaq_rot180_f32","Floating-point complex multiply accumulate"],["vcmlaq_rot180_f64","Floating-point complex multiply accumulate"],["vcmlaq_rot180_lane_f32","Floating-point complex multiply accumulate"],["vcmlaq_rot180_laneq_f32","Floating-point complex multiply accumulate"],["vcmlaq_rot270_f32","Floating-point complex multiply accumulate"],["vcmlaq_rot270_f64","Floating-point complex multiply accumulate"],["vcmlaq_rot270_lane_f32","Floating-point complex multiply accumulate"],["vcmlaq_rot270_laneq_f32","Floating-point complex multiply accumulate"],["vcmlaq_rot90_f32","Floating-point complex multiply accumulate"],["vcmlaq_rot90_f64","Floating-point complex multiply accumulate"],["vcmlaq_rot90_lane_f32","Floating-point complex multiply accumulate"],["vcmlaq_rot90_laneq_f32","Floating-point complex multiply accumulate"],["vcnt_p8","Population count per byte."],["vcnt_s8","Population count per byte."],["vcnt_u8","Population count per byte."],["vcntq_p8","Population count per byte."],["vcntq_s8","Population count per byte."],["vcntq_u8","Population count per byte."],["vcombine_f32","Vector combine"],["vcombine_f64","Vector combine"],["vcombine_p16","Vector combine"],["vcombine_p64","Vector combine"],["vcombine_p8","Vector combine"],["vcombine_s16","Vector combine"],["vcombine_s32","Vector combine"],["vcombine_s64","Vector combine"],["vcombine_s8","Vector combine"],["vcombine_u16","Vector combine"],["vcombine_u32","Vector combine"],["vcombine_u64","Vector combine"],["vcombine_u8","Vector combine"],["vcopy_lane_f32","Insert vector element from another vector element"],["vcopy_lane_f64","Duplicate vector element to vector or scalar"],["vcopy_lane_p16","Insert vector element from another vector element"],["vcopy_lane_p64","Duplicate vector element to vector or scalar"],["vcopy_lane_p8","Insert vector element from another vector element"],["vcopy_lane_s16","Insert vector element from another vector element"],["vcopy_lane_s32","Insert vector element from another vector element"],["vcopy_lane_s64","Duplicate vector element to vector or scalar"],["vcopy_lane_s8","Insert vector element from another vector element"],["vcopy_lane_u16","Insert vector element from another vector element"],["vcopy_lane_u32","Insert vector element from another vector element"],["vcopy_lane_u64","Duplicate vector element to vector or scalar"],["vcopy_lane_u8","Insert vector element from another vector element"],["vcopy_laneq_f32","Insert vector element from another vector element"],["vcopy_laneq_f64","Duplicate vector element to vector or scalar"],["vcopy_laneq_p16","Insert vector element from another vector element"],["vcopy_laneq_p64","Duplicate vector element to vector or scalar"],["vcopy_laneq_p8","Insert vector element from another vector element"],["vcopy_laneq_s16","Insert vector element from another vector element"],["vcopy_laneq_s32","Insert vector element from another vector element"],["vcopy_laneq_s64","Duplicate vector element to vector or scalar"],["vcopy_laneq_s8","Insert vector element from another vector element"],["vcopy_laneq_u16","Insert vector element from another vector element"],["vcopy_laneq_u32","Insert vector element from another vector element"],["vcopy_laneq_u64","Duplicate vector element to vector or scalar"],["vcopy_laneq_u8","Insert vector element from another vector element"],["vcopyq_lane_f32","Insert vector element from another vector element"],["vcopyq_lane_f64","Insert vector element from another vector element"],["vcopyq_lane_p16","Insert vector element from another vector element"],["vcopyq_lane_p64","Insert vector element from another vector element"],["vcopyq_lane_p8","Insert vector element from another vector element"],["vcopyq_lane_s16","Insert vector element from another vector element"],["vcopyq_lane_s32","Insert vector element from another vector element"],["vcopyq_lane_s64","Insert vector element from another vector element"],["vcopyq_lane_s8","Insert vector element from another vector element"],["vcopyq_lane_u16","Insert vector element from another vector element"],["vcopyq_lane_u32","Insert vector element from another vector element"],["vcopyq_lane_u64","Insert vector element from another vector element"],["vcopyq_lane_u8","Insert vector element from another vector element"],["vcopyq_laneq_f32","Insert vector element from another vector element"],["vcopyq_laneq_f64","Insert vector element from another vector element"],["vcopyq_laneq_p16","Insert vector element from another vector element"],["vcopyq_laneq_p64","Insert vector element from another vector element"],["vcopyq_laneq_p8","Insert vector element from another vector element"],["vcopyq_laneq_s16","Insert vector element from another vector element"],["vcopyq_laneq_s32","Insert vector element from another vector element"],["vcopyq_laneq_s64","Insert vector element from another vector element"],["vcopyq_laneq_s8","Insert vector element from another vector element"],["vcopyq_laneq_u16","Insert vector element from another vector element"],["vcopyq_laneq_u32","Insert vector element from another vector element"],["vcopyq_laneq_u64","Insert vector element from another vector element"],["vcopyq_laneq_u8","Insert vector element from another vector element"],["vcreate_f32","Insert vector element from another vector element"],["vcreate_f64","Insert vector element from another vector element"],["vcreate_p16","Insert vector element from another vector element"],["vcreate_p64","Insert vector element from another vector element"],["vcreate_p8","Insert vector element from another vector element"],["vcreate_s16","Insert vector element from another vector element"],["vcreate_s32","Insert vector element from another vector element"],["vcreate_s64","Insert vector element from another vector element"],["vcreate_s8","Insert vector element from another vector element"],["vcreate_u16","Insert vector element from another vector element"],["vcreate_u32","Insert vector element from another vector element"],["vcreate_u64","Insert vector element from another vector element"],["vcreate_u8","Insert vector element from another vector element"],["vcvt_f32_f64","Floating-point convert to lower precision narrow"],["vcvt_f32_s32","Fixed-point convert to floating-point"],["vcvt_f32_u32","Fixed-point convert to floating-point"],["vcvt_f64_f32","Floating-point convert to higher precision long"],["vcvt_f64_s64","Fixed-point convert to floating-point"],["vcvt_f64_u64","Fixed-point convert to floating-point"],["vcvt_high_f32_f64","Floating-point convert to lower precision narrow"],["vcvt_high_f64_f32","Floating-point convert to higher precision long"],["vcvt_n_f64_s64","Fixed-point convert to floating-point"],["vcvt_n_f64_u64","Fixed-point convert to floating-point"],["vcvt_n_s64_f64","Floating-point convert to fixed-point, rounding toward zero"],["vcvt_n_u64_f64","Floating-point convert to fixed-point, rounding toward zero"],["vcvt_s32_f32","Floating-point convert to signed fixed-point, rounding toward zero"],["vcvt_s64_f64","Floating-point convert to signed fixed-point, rounding toward zero"],["vcvt_u32_f32","Floating-point convert to unsigned fixed-point, rounding toward zero"],["vcvt_u64_f64","Floating-point convert to unsigned fixed-point, rounding toward zero"],["vcvta_s32_f32","Floating-point convert to signed integer, rounding to nearest with ties to away"],["vcvta_s64_f64","Floating-point convert to signed integer, rounding to nearest with ties to away"],["vcvta_u32_f32","Floating-point convert to unsigned integer, rounding to nearest with ties to away"],["vcvta_u64_f64","Floating-point convert to unsigned integer, rounding to nearest with ties to away"],["vcvtad_s64_f64","Floating-point convert to integer, rounding to nearest with ties to away"],["vcvtad_u64_f64","Floating-point convert to integer, rounding to nearest with ties to away"],["vcvtaq_s32_f32","Floating-point convert to signed integer, rounding to nearest with ties to away"],["vcvtaq_s64_f64","Floating-point convert to signed integer, rounding to nearest with ties to away"],["vcvtaq_u32_f32","Floating-point convert to unsigned integer, rounding to nearest with ties to away"],["vcvtaq_u64_f64","Floating-point convert to unsigned integer, rounding to nearest with ties to away"],["vcvtas_s32_f32","Floating-point convert to integer, rounding to nearest with ties to away"],["vcvtas_u32_f32","Floating-point convert to integer, rounding to nearest with ties to away"],["vcvtd_f64_s64","Fixed-point convert to floating-point"],["vcvtd_f64_u64","Fixed-point convert to floating-point"],["vcvtd_n_f64_s64","Fixed-point convert to floating-point"],["vcvtd_n_f64_u64","Fixed-point convert to floating-point"],["vcvtd_n_s64_f64","Floating-point convert to fixed-point, rounding toward zero"],["vcvtd_n_u64_f64","Floating-point convert to fixed-point, rounding toward zero"],["vcvtd_s64_f64","Fixed-point convert to floating-point"],["vcvtd_u64_f64","Fixed-point convert to floating-point"],["vcvtm_s32_f32","Floating-point convert to signed integer, rounding toward minus infinity"],["vcvtm_s64_f64","Floating-point convert to signed integer, rounding toward minus infinity"],["vcvtm_u32_f32","Floating-point convert to unsigned integer, rounding toward minus infinity"],["vcvtm_u64_f64","Floating-point convert to unsigned integer, rounding toward minus infinity"],["vcvtmd_s64_f64","Floating-point convert to signed integer, rounding toward minus infinity"],["vcvtmd_u64_f64","Floating-point convert to unsigned integer, rounding toward minus infinity"],["vcvtmq_s32_f32","Floating-point convert to signed integer, rounding toward minus infinity"],["vcvtmq_s64_f64","Floating-point convert to signed integer, rounding toward minus infinity"],["vcvtmq_u32_f32","Floating-point convert to unsigned integer, rounding toward minus infinity"],["vcvtmq_u64_f64","Floating-point convert to unsigned integer, rounding toward minus infinity"],["vcvtms_s32_f32","Floating-point convert to signed integer, rounding toward minus infinity"],["vcvtms_u32_f32","Floating-point convert to unsigned integer, rounding toward minus infinity"],["vcvtn_s32_f32","Floating-point convert to signed integer, rounding to nearest with ties to even"],["vcvtn_s64_f64","Floating-point convert to signed integer, rounding to nearest with ties to even"],["vcvtn_u32_f32","Floating-point convert to unsigned integer, rounding to nearest with ties to even"],["vcvtn_u64_f64","Floating-point convert to unsigned integer, rounding to nearest with ties to even"],["vcvtnd_s64_f64","Floating-point convert to signed integer, rounding to nearest with ties to even"],["vcvtnd_u64_f64","Floating-point convert to unsigned integer, rounding to nearest with ties to even"],["vcvtnq_s32_f32","Floating-point convert to signed integer, rounding to nearest with ties to even"],["vcvtnq_s64_f64","Floating-point convert to signed integer, rounding to nearest with ties to even"],["vcvtnq_u32_f32","Floating-point convert to unsigned integer, rounding to nearest with ties to even"],["vcvtnq_u64_f64","Floating-point convert to unsigned integer, rounding to nearest with ties to even"],["vcvtns_s32_f32","Floating-point convert to signed integer, rounding to nearest with ties to even"],["vcvtns_u32_f32","Floating-point convert to unsigned integer, rounding to nearest with ties to even"],["vcvtp_s32_f32","Floating-point convert to signed integer, rounding toward plus infinity"],["vcvtp_s64_f64","Floating-point convert to signed integer, rounding toward plus infinity"],["vcvtp_u32_f32","Floating-point convert to unsigned integer, rounding toward plus infinity"],["vcvtp_u64_f64","Floating-point convert to unsigned integer, rounding toward plus infinity"],["vcvtpd_s64_f64","Floating-point convert to signed integer, rounding toward plus infinity"],["vcvtpd_u64_f64","Floating-point convert to unsigned integer, rounding toward plus infinity"],["vcvtpq_s32_f32","Floating-point convert to signed integer, rounding toward plus infinity"],["vcvtpq_s64_f64","Floating-point convert to signed integer, rounding toward plus infinity"],["vcvtpq_u32_f32","Floating-point convert to unsigned integer, rounding toward plus infinity"],["vcvtpq_u64_f64","Floating-point convert to unsigned integer, rounding toward plus infinity"],["vcvtps_s32_f32","Floating-point convert to signed integer, rounding toward plus infinity"],["vcvtps_u32_f32","Floating-point convert to unsigned integer, rounding toward plus infinity"],["vcvtq_f32_s32","Fixed-point convert to floating-point"],["vcvtq_f32_u32","Fixed-point convert to floating-point"],["vcvtq_f64_s64","Fixed-point convert to floating-point"],["vcvtq_f64_u64","Fixed-point convert to floating-point"],["vcvtq_n_f64_s64","Fixed-point convert to floating-point"],["vcvtq_n_f64_u64","Fixed-point convert to floating-point"],["vcvtq_n_s64_f64","Floating-point convert to fixed-point, rounding toward zero"],["vcvtq_n_u64_f64","Floating-point convert to fixed-point, rounding toward zero"],["vcvtq_s32_f32","Floating-point convert to signed fixed-point, rounding toward zero"],["vcvtq_s64_f64","Floating-point convert to signed fixed-point, rounding toward zero"],["vcvtq_u32_f32","Floating-point convert to unsigned fixed-point, rounding toward zero"],["vcvtq_u64_f64","Floating-point convert to unsigned fixed-point, rounding toward zero"],["vcvts_f32_s32","Fixed-point convert to floating-point"],["vcvts_f32_u32","Fixed-point convert to floating-point"],["vcvts_n_f32_s32","Fixed-point convert to floating-point"],["vcvts_n_f32_u32","Fixed-point convert to floating-point"],["vcvts_n_s32_f32","Floating-point convert to fixed-point, rounding toward zero"],["vcvts_n_u32_f32","Floating-point convert to fixed-point, rounding toward zero"],["vcvts_s32_f32","Fixed-point convert to floating-point"],["vcvts_u32_f32","Fixed-point convert to floating-point"],["vcvtx_f32_f64","Floating-point convert to lower precision narrow, rounding to odd"],["vcvtx_high_f32_f64","Floating-point convert to lower precision narrow, rounding to odd"],["vcvtxd_f32_f64","Floating-point convert to lower precision narrow, rounding to odd"],["vdiv_f32","Divide"],["vdiv_f64","Divide"],["vdivq_f32","Divide"],["vdivq_f64","Divide"],["vdot_lane_s32","Dot product arithmetic"],["vdot_lane_u32","Dot product arithmetic"],["vdot_laneq_s32","Dot product arithmetic"],["vdot_laneq_u32","Dot product arithmetic"],["vdot_s32","Dot product arithmetic"],["vdot_u32","Dot product arithmetic"],["vdotq_lane_s32","Dot product arithmetic"],["vdotq_lane_u32","Dot product arithmetic"],["vdotq_laneq_s32","Dot product arithmetic"],["vdotq_laneq_u32","Dot product arithmetic"],["vdotq_s32","Dot product arithmetic"],["vdotq_u32","Dot product arithmetic"],["vdup_lane_f32","Set all vector lanes to the same value"],["vdup_lane_f64","Set all vector lanes to the same value"],["vdup_lane_p16","Set all vector lanes to the same value"],["vdup_lane_p64","Set all vector lanes to the same value"],["vdup_lane_p8","Set all vector lanes to the same value"],["vdup_lane_s16","Set all vector lanes to the same value"],["vdup_lane_s32","Set all vector lanes to the same value"],["vdup_lane_s64","Set all vector lanes to the same value"],["vdup_lane_s8","Set all vector lanes to the same value"],["vdup_lane_u16","Set all vector lanes to the same value"],["vdup_lane_u32","Set all vector lanes to the same value"],["vdup_lane_u64","Set all vector lanes to the same value"],["vdup_lane_u8","Set all vector lanes to the same value"],["vdup_laneq_f32","Set all vector lanes to the same value"],["vdup_laneq_f64","Set all vector lanes to the same value"],["vdup_laneq_p16","Set all vector lanes to the same value"],["vdup_laneq_p64","Set all vector lanes to the same value"],["vdup_laneq_p8","Set all vector lanes to the same value"],["vdup_laneq_s16","Set all vector lanes to the same value"],["vdup_laneq_s32","Set all vector lanes to the same value"],["vdup_laneq_s64","Set all vector lanes to the same value"],["vdup_laneq_s8","Set all vector lanes to the same value"],["vdup_laneq_u16","Set all vector lanes to the same value"],["vdup_laneq_u32","Set all vector lanes to the same value"],["vdup_laneq_u64","Set all vector lanes to the same value"],["vdup_laneq_u8","Set all vector lanes to the same value"],["vdup_n_f32","Duplicate vector element to vector or scalar"],["vdup_n_f64","Duplicate vector element to vector or scalar"],["vdup_n_p16","Duplicate vector element to vector or scalar"],["vdup_n_p64","Duplicate vector element to vector or scalar"],["vdup_n_p8","Duplicate vector element to vector or scalar"],["vdup_n_s16","Duplicate vector element to vector or scalar"],["vdup_n_s32","Duplicate vector element to vector or scalar"],["vdup_n_s64","Duplicate vector element to vector or scalar"],["vdup_n_s8","Duplicate vector element to vector or scalar"],["vdup_n_u16","Duplicate vector element to vector or scalar"],["vdup_n_u32","Duplicate vector element to vector or scalar"],["vdup_n_u64","Duplicate vector element to vector or scalar"],["vdup_n_u8","Duplicate vector element to vector or scalar"],["vdupb_lane_p8","Set all vector lanes to the same value"],["vdupb_lane_s8","Set all vector lanes to the same value"],["vdupb_lane_u8","Set all vector lanes to the same value"],["vdupb_laneq_p8","Set all vector lanes to the same value"],["vdupb_laneq_s8","Set all vector lanes to the same value"],["vdupb_laneq_u8","Set all vector lanes to the same value"],["vdupd_lane_f64","Set all vector lanes to the same value"],["vdupd_lane_s64","Set all vector lanes to the same value"],["vdupd_lane_u64","Set all vector lanes to the same value"],["vdupd_laneq_f64","Set all vector lanes to the same value"],["vdupd_laneq_s64","Set all vector lanes to the same value"],["vdupd_laneq_u64","Set all vector lanes to the same value"],["vduph_lane_p16","Set all vector lanes to the same value"],["vduph_lane_s16","Set all vector lanes to the same value"],["vduph_lane_u16","Set all vector lanes to the same value"],["vduph_laneq_p16","Set all vector lanes to the same value"],["vduph_laneq_s16","Set all vector lanes to the same value"],["vduph_laneq_u16","Set all vector lanes to the same value"],["vdupq_lane_f32","Set all vector lanes to the same value"],["vdupq_lane_f64","Set all vector lanes to the same value"],["vdupq_lane_p16","Set all vector lanes to the same value"],["vdupq_lane_p64","Set all vector lanes to the same value"],["vdupq_lane_p8","Set all vector lanes to the same value"],["vdupq_lane_s16","Set all vector lanes to the same value"],["vdupq_lane_s32","Set all vector lanes to the same value"],["vdupq_lane_s64","Set all vector lanes to the same value"],["vdupq_lane_s8","Set all vector lanes to the same value"],["vdupq_lane_u16","Set all vector lanes to the same value"],["vdupq_lane_u32","Set all vector lanes to the same value"],["vdupq_lane_u64","Set all vector lanes to the same value"],["vdupq_lane_u8","Set all vector lanes to the same value"],["vdupq_laneq_f32","Set all vector lanes to the same value"],["vdupq_laneq_f64","Set all vector lanes to the same value"],["vdupq_laneq_p16","Set all vector lanes to the same value"],["vdupq_laneq_p64","Set all vector lanes to the same value"],["vdupq_laneq_p8","Set all vector lanes to the same value"],["vdupq_laneq_s16","Set all vector lanes to the same value"],["vdupq_laneq_s32","Set all vector lanes to the same value"],["vdupq_laneq_s64","Set all vector lanes to the same value"],["vdupq_laneq_s8","Set all vector lanes to the same value"],["vdupq_laneq_u16","Set all vector lanes to the same value"],["vdupq_laneq_u32","Set all vector lanes to the same value"],["vdupq_laneq_u64","Set all vector lanes to the same value"],["vdupq_laneq_u8","Set all vector lanes to the same value"],["vdupq_n_f32","Duplicate vector element to vector or scalar"],["vdupq_n_f64","Duplicate vector element to vector or scalar"],["vdupq_n_p16","Duplicate vector element to vector or scalar"],["vdupq_n_p64","Duplicate vector element to vector or scalar"],["vdupq_n_p8","Duplicate vector element to vector or scalar"],["vdupq_n_s16","Duplicate vector element to vector or scalar"],["vdupq_n_s32","Duplicate vector element to vector or scalar"],["vdupq_n_s64","Duplicate vector element to vector or scalar"],["vdupq_n_s8","Duplicate vector element to vector or scalar"],["vdupq_n_u16","Duplicate vector element to vector or scalar"],["vdupq_n_u32","Duplicate vector element to vector or scalar"],["vdupq_n_u64","Duplicate vector element to vector or scalar"],["vdupq_n_u8","Duplicate vector element to vector or scalar"],["vdups_lane_f32","Set all vector lanes to the same value"],["vdups_lane_s32","Set all vector lanes to the same value"],["vdups_lane_u32","Set all vector lanes to the same value"],["vdups_laneq_f32","Set all vector lanes to the same value"],["vdups_laneq_s32","Set all vector lanes to the same value"],["vdups_laneq_u32","Set all vector lanes to the same value"],["veor3q_s16","Three-way exclusive OR"],["veor3q_s32","Three-way exclusive OR"],["veor3q_s64","Three-way exclusive OR"],["veor3q_s8","Three-way exclusive OR"],["veor3q_u16","Three-way exclusive OR"],["veor3q_u32","Three-way exclusive OR"],["veor3q_u64","Three-way exclusive OR"],["veor3q_u8","Three-way exclusive OR"],["veor_s16","Vector bitwise exclusive or (vector)"],["veor_s32","Vector bitwise exclusive or (vector)"],["veor_s64","Vector bitwise exclusive or (vector)"],["veor_s8","Vector bitwise exclusive or (vector)"],["veor_u16","Vector bitwise exclusive or (vector)"],["veor_u32","Vector bitwise exclusive or (vector)"],["veor_u64","Vector bitwise exclusive or (vector)"],["veor_u8","Vector bitwise exclusive or (vector)"],["veorq_s16","Vector bitwise exclusive or (vector)"],["veorq_s32","Vector bitwise exclusive or (vector)"],["veorq_s64","Vector bitwise exclusive or (vector)"],["veorq_s8","Vector bitwise exclusive or (vector)"],["veorq_u16","Vector bitwise exclusive or (vector)"],["veorq_u32","Vector bitwise exclusive or (vector)"],["veorq_u64","Vector bitwise exclusive or (vector)"],["veorq_u8","Vector bitwise exclusive or (vector)"],["vext_f32","Extract vector from pair of vectors"],["vext_f64","Extract vector from pair of vectors"],["vext_p16","Extract vector from pair of vectors"],["vext_p64","Extract vector from pair of vectors"],["vext_p8","Extract vector from pair of vectors"],["vext_s16","Extract vector from pair of vectors"],["vext_s32","Extract vector from pair of vectors"],["vext_s64","Extract vector from pair of vectors"],["vext_s8","Extract vector from pair of vectors"],["vext_u16","Extract vector from pair of vectors"],["vext_u32","Extract vector from pair of vectors"],["vext_u64","Extract vector from pair of vectors"],["vext_u8","Extract vector from pair of vectors"],["vextq_f32","Extract vector from pair of vectors"],["vextq_f64","Extract vector from pair of vectors"],["vextq_p16","Extract vector from pair of vectors"],["vextq_p64","Extract vector from pair of vectors"],["vextq_p8","Extract vector from pair of vectors"],["vextq_s16","Extract vector from pair of vectors"],["vextq_s32","Extract vector from pair of vectors"],["vextq_s64","Extract vector from pair of vectors"],["vextq_s8","Extract vector from pair of vectors"],["vextq_u16","Extract vector from pair of vectors"],["vextq_u32","Extract vector from pair of vectors"],["vextq_u64","Extract vector from pair of vectors"],["vextq_u8","Extract vector from pair of vectors"],["vfma_f32","Floating-point fused Multiply-Add to accumulator(vector)"],["vfma_f64","Floating-point fused Multiply-Add to accumulator(vector)"],["vfma_lane_f32","Floating-point fused multiply-add to accumulator"],["vfma_lane_f64","Floating-point fused multiply-add to accumulator"],["vfma_laneq_f32","Floating-point fused multiply-add to accumulator"],["vfma_laneq_f64","Floating-point fused multiply-add to accumulator"],["vfma_n_f32","Floating-point fused Multiply-Add to accumulator(vector)"],["vfma_n_f64","Floating-point fused Multiply-Add to accumulator(vector)"],["vfmad_lane_f64","Floating-point fused multiply-add to accumulator"],["vfmad_laneq_f64","Floating-point fused multiply-add to accumulator"],["vfmaq_f32","Floating-point fused Multiply-Add to accumulator(vector)"],["vfmaq_f64","Floating-point fused Multiply-Add to accumulator(vector)"],["vfmaq_lane_f32","Floating-point fused multiply-add to accumulator"],["vfmaq_lane_f64","Floating-point fused multiply-add to accumulator"],["vfmaq_laneq_f32","Floating-point fused multiply-add to accumulator"],["vfmaq_laneq_f64","Floating-point fused multiply-add to accumulator"],["vfmaq_n_f32","Floating-point fused Multiply-Add to accumulator(vector)"],["vfmaq_n_f64","Floating-point fused Multiply-Add to accumulator(vector)"],["vfmas_lane_f32","Floating-point fused multiply-add to accumulator"],["vfmas_laneq_f32","Floating-point fused multiply-add to accumulator"],["vfms_f32","Floating-point fused multiply-subtract from accumulator"],["vfms_f64","Floating-point fused multiply-subtract from accumulator"],["vfms_lane_f32","Floating-point fused multiply-subtract to accumulator"],["vfms_lane_f64","Floating-point fused multiply-subtract to accumulator"],["vfms_laneq_f32","Floating-point fused multiply-subtract to accumulator"],["vfms_laneq_f64","Floating-point fused multiply-subtract to accumulator"],["vfms_n_f32","Floating-point fused Multiply-subtract to accumulator(vector)"],["vfms_n_f64","Floating-point fused Multiply-subtract to accumulator(vector)"],["vfmsd_lane_f64","Floating-point fused multiply-subtract to accumulator"],["vfmsd_laneq_f64","Floating-point fused multiply-subtract to accumulator"],["vfmsq_f32","Floating-point fused multiply-subtract from accumulator"],["vfmsq_f64","Floating-point fused multiply-subtract from accumulator"],["vfmsq_lane_f32","Floating-point fused multiply-subtract to accumulator"],["vfmsq_lane_f64","Floating-point fused multiply-subtract to accumulator"],["vfmsq_laneq_f32","Floating-point fused multiply-subtract to accumulator"],["vfmsq_laneq_f64","Floating-point fused multiply-subtract to accumulator"],["vfmsq_n_f32","Floating-point fused Multiply-subtract to accumulator(vector)"],["vfmsq_n_f64","Floating-point fused Multiply-subtract to accumulator(vector)"],["vfmss_lane_f32","Floating-point fused multiply-subtract to accumulator"],["vfmss_laneq_f32","Floating-point fused multiply-subtract to accumulator"],["vget_high_f32","Duplicate vector element to vector or scalar"],["vget_high_f64","Duplicate vector element to vector or scalar"],["vget_high_p16","Duplicate vector element to vector or scalar"],["vget_high_p64","Duplicate vector element to vector or scalar"],["vget_high_p8","Duplicate vector element to vector or scalar"],["vget_high_s16","Duplicate vector element to vector or scalar"],["vget_high_s32","Duplicate vector element to vector or scalar"],["vget_high_s64","Duplicate vector element to vector or scalar"],["vget_high_s8","Duplicate vector element to vector or scalar"],["vget_high_u16","Duplicate vector element to vector or scalar"],["vget_high_u32","Duplicate vector element to vector or scalar"],["vget_high_u64","Duplicate vector element to vector or scalar"],["vget_high_u8","Duplicate vector element to vector or scalar"],["vget_lane_f32","Duplicate vector element to vector or scalar"],["vget_lane_f64","Duplicate vector element to vector or scalar"],["vget_lane_p16","Move vector element to general-purpose register"],["vget_lane_p64","Move vector element to general-purpose register"],["vget_lane_p8","Move vector element to general-purpose register"],["vget_lane_s16","Move vector element to general-purpose register"],["vget_lane_s32","Move vector element to general-purpose register"],["vget_lane_s64","Move vector element to general-purpose register"],["vget_lane_s8","Move vector element to general-purpose register"],["vget_lane_u16","Move vector element to general-purpose register"],["vget_lane_u32","Move vector element to general-purpose register"],["vget_lane_u64","Move vector element to general-purpose register"],["vget_lane_u8","Move vector element to general-purpose register"],["vget_low_f32","Duplicate vector element to vector or scalar"],["vget_low_f64","Duplicate vector element to vector or scalar"],["vget_low_p16","Duplicate vector element to vector or scalar"],["vget_low_p64","Duplicate vector element to vector or scalar"],["vget_low_p8","Duplicate vector element to vector or scalar"],["vget_low_s16","Duplicate vector element to vector or scalar"],["vget_low_s32","Duplicate vector element to vector or scalar"],["vget_low_s64","Duplicate vector element to vector or scalar"],["vget_low_s8","Duplicate vector element to vector or scalar"],["vget_low_u16","Duplicate vector element to vector or scalar"],["vget_low_u32","Duplicate vector element to vector or scalar"],["vget_low_u64","Duplicate vector element to vector or scalar"],["vget_low_u8","Duplicate vector element to vector or scalar"],["vgetq_lane_f32","Duplicate vector element to vector or scalar"],["vgetq_lane_f64","Duplicate vector element to vector or scalar"],["vgetq_lane_p16","Move vector element to general-purpose register"],["vgetq_lane_p64","Move vector element to general-purpose register"],["vgetq_lane_p8","Move vector element to general-purpose register"],["vgetq_lane_s16","Move vector element to general-purpose register"],["vgetq_lane_s32","Move vector element to general-purpose register"],["vgetq_lane_s64","Move vector element to general-purpose register"],["vgetq_lane_s8","Move vector element to general-purpose register"],["vgetq_lane_u16","Move vector element to general-purpose register"],["vgetq_lane_u32","Move vector element to general-purpose register"],["vgetq_lane_u64","Move vector element to general-purpose register"],["vgetq_lane_u8","Move vector element to general-purpose register"],["vhadd_s16","Halving add"],["vhadd_s32","Halving add"],["vhadd_s8","Halving add"],["vhadd_u16","Halving add"],["vhadd_u32","Halving add"],["vhadd_u8","Halving add"],["vhaddq_s16","Halving add"],["vhaddq_s32","Halving add"],["vhaddq_s8","Halving add"],["vhaddq_u16","Halving add"],["vhaddq_u32","Halving add"],["vhaddq_u8","Halving add"],["vhsub_s16","Signed halving subtract"],["vhsub_s32","Signed halving subtract"],["vhsub_s8","Signed halving subtract"],["vhsub_u16","Signed halving subtract"],["vhsub_u32","Signed halving subtract"],["vhsub_u8","Signed halving subtract"],["vhsubq_s16","Signed halving subtract"],["vhsubq_s32","Signed halving subtract"],["vhsubq_s8","Signed halving subtract"],["vhsubq_u16","Signed halving subtract"],["vhsubq_u32","Signed halving subtract"],["vhsubq_u8","Signed halving subtract"],["vld1_dup_f32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_f64","Load multiple single-element structures to one, two, three, or four registers"],["vld1_dup_p16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_p64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_p8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_f32","Load multiple single-element structures to one, two, three, or four registers."],["vld1_f32_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_f32_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_f32_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_f64","Load multiple single-element structures to one, two, three, or four registers."],["vld1_f64_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_f64_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_f64_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_lane_f32","Load one single-element structure to one lane of one register."],["vld1_lane_f64","Load one single-element structure to one lane of one register."],["vld1_lane_p16","Load one single-element structure to one lane of one register."],["vld1_lane_p64","Load one single-element structure to one lane of one register."],["vld1_lane_p8","Load one single-element structure to one lane of one register."],["vld1_lane_s16","Load one single-element structure to one lane of one register."],["vld1_lane_s32","Load one single-element structure to one lane of one register."],["vld1_lane_s64","Load one single-element structure to one lane of one register."],["vld1_lane_s8","Load one single-element structure to one lane of one register."],["vld1_lane_u16","Load one single-element structure to one lane of one register."],["vld1_lane_u32","Load one single-element structure to one lane of one register."],["vld1_lane_u64","Load one single-element structure to one lane of one register."],["vld1_lane_u8","Load one single-element structure to one lane of one register."],["vld1_p16","Load multiple single-element structures to one, two, three, or four registers."],["vld1_p16_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_p16_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_p16_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_p64","Load multiple single-element structures to one, two, three, or four registers."],["vld1_p64_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_p64_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_p64_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_p8","Load multiple single-element structures to one, two, three, or four registers."],["vld1_p8_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_p8_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_p8_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s16","Load multiple single-element structures to one, two, three, or four registers."],["vld1_s16_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s16_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s16_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s32","Load multiple single-element structures to one, two, three, or four registers."],["vld1_s32_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s32_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s32_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s64","Load multiple single-element structures to one, two, three, or four registers."],["vld1_s64_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s64_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s64_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s8","Load multiple single-element structures to one, two, three, or four registers."],["vld1_s8_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s8_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_s8_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u16","Load multiple single-element structures to one, two, three, or four registers."],["vld1_u16_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u16_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u16_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u32","Load multiple single-element structures to one, two, three, or four registers."],["vld1_u32_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u32_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u32_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u64","Load multiple single-element structures to one, two, three, or four registers."],["vld1_u64_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u64_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u64_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u8","Load multiple single-element structures to one, two, three, or four registers."],["vld1_u8_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u8_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1_u8_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_dup_f32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_f64","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_dup_p16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_p64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_p8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_f32","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_f32_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_f32_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_f32_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_f64","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_f64_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_f64_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_f64_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_lane_f32","Load one single-element structure to one lane of one register."],["vld1q_lane_f64","Load one single-element structure to one lane of one register."],["vld1q_lane_p16","Load one single-element structure to one lane of one register."],["vld1q_lane_p64","Load one single-element structure to one lane of one register."],["vld1q_lane_p8","Load one single-element structure to one lane of one register."],["vld1q_lane_s16","Load one single-element structure to one lane of one register."],["vld1q_lane_s32","Load one single-element structure to one lane of one register."],["vld1q_lane_s64","Load one single-element structure to one lane of one register."],["vld1q_lane_s8","Load one single-element structure to one lane of one register."],["vld1q_lane_u16","Load one single-element structure to one lane of one register."],["vld1q_lane_u32","Load one single-element structure to one lane of one register."],["vld1q_lane_u64","Load one single-element structure to one lane of one register."],["vld1q_lane_u8","Load one single-element structure to one lane of one register."],["vld1q_p16","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_p16_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_p16_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_p16_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_p64","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_p64_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_p64_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_p64_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_p8","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_p8_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_p8_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_p8_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s16","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_s16_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s16_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s16_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s32","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_s32_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s32_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s32_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s64","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_s64_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s64_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s64_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s8","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_s8_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s8_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_s8_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u16","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_u16_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u16_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u16_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u32","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_u32_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u32_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u32_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u64","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_u64_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u64_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u64_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u8","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_u8_x2","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u8_x3","Load multiple single-element structures to one, two, three, or four registers"],["vld1q_u8_x4","Load multiple single-element structures to one, two, three, or four registers"],["vld2_dup_f64","Load single 2-element structure and replicate to all lanes of two registers"],["vld2_dup_p16","Load single 2-element structure and replicate to all lanes of two registers"],["vld2_dup_p64","Load single 2-element structure and replicate to all lanes of two registers"],["vld2_dup_p8","Load single 2-element structure and replicate to all lanes of two registers"],["vld2_dup_u16","Load single 2-element structure and replicate to all lanes of two registers"],["vld2_dup_u32","Load single 2-element structure and replicate to all lanes of two registers"],["vld2_dup_u64","Load single 2-element structure and replicate to all lanes of two registers"],["vld2_dup_u8","Load single 2-element structure and replicate to all lanes of two registers"],["vld2_f64","Load multiple 2-element structures to two registers"],["vld2_lane_f64","Load multiple 2-element structures to two registers"],["vld2_lane_p16","Load multiple 2-element structures to two registers"],["vld2_lane_p64","Load multiple 2-element structures to two registers"],["vld2_lane_p8","Load multiple 2-element structures to two registers"],["vld2_lane_s64","Load multiple 2-element structures to two registers"],["vld2_lane_u16","Load multiple 2-element structures to two registers"],["vld2_lane_u32","Load multiple 2-element structures to two registers"],["vld2_lane_u64","Load multiple 2-element structures to two registers"],["vld2_lane_u8","Load multiple 2-element structures to two registers"],["vld2_p16","Load multiple 2-element structures to two registers"],["vld2_p64","Load multiple 2-element structures to two registers"],["vld2_p8","Load multiple 2-element structures to two registers"],["vld2_u16","Load multiple 2-element structures to two registers"],["vld2_u32","Load multiple 2-element structures to two registers"],["vld2_u64","Load multiple 2-element structures to two registers"],["vld2_u8","Load multiple 2-element structures to two registers"],["vld2q_dup_f64","Load single 2-element structure and replicate to all lanes of two registers"],["vld2q_dup_p16","Load single 2-element structure and replicate to all lanes of two registers"],["vld2q_dup_p64","Load single 2-element structure and replicate to all lanes of two registers"],["vld2q_dup_p8","Load single 2-element structure and replicate to all lanes of two registers"],["vld2q_dup_s64","Load single 2-element structure and replicate to all lanes of two registers"],["vld2q_dup_u16","Load single 2-element structure and replicate to all lanes of two registers"],["vld2q_dup_u32","Load single 2-element structure and replicate to all lanes of two registers"],["vld2q_dup_u64","Load single 2-element structure and replicate to all lanes of two registers"],["vld2q_dup_u8","Load single 2-element structure and replicate to all lanes of two registers"],["vld2q_f64","Load multiple 2-element structures to two registers"],["vld2q_lane_f64","Load multiple 2-element structures to two registers"],["vld2q_lane_p16","Load multiple 2-element structures to two registers"],["vld2q_lane_p64","Load multiple 2-element structures to two registers"],["vld2q_lane_p8","Load multiple 2-element structures to two registers"],["vld2q_lane_s64","Load multiple 2-element structures to two registers"],["vld2q_lane_s8","Load multiple 2-element structures to two registers"],["vld2q_lane_u16","Load multiple 2-element structures to two registers"],["vld2q_lane_u32","Load multiple 2-element structures to two registers"],["vld2q_lane_u64","Load multiple 2-element structures to two registers"],["vld2q_lane_u8","Load multiple 2-element structures to two registers"],["vld2q_p16","Load multiple 2-element structures to two registers"],["vld2q_p64","Load multiple 2-element structures to two registers"],["vld2q_p8","Load multiple 2-element structures to two registers"],["vld2q_s64","Load multiple 2-element structures to two registers"],["vld2q_u16","Load multiple 2-element structures to two registers"],["vld2q_u32","Load multiple 2-element structures to two registers"],["vld2q_u64","Load multiple 2-element structures to two registers"],["vld2q_u8","Load multiple 2-element structures to two registers"],["vld3_dup_f64","Load single 3-element structure and replicate to all lanes of three registers"],["vld3_dup_p16","Load single 3-element structure and replicate to all lanes of three registers"],["vld3_dup_p64","Load single 3-element structure and replicate to all lanes of three registers"],["vld3_dup_p8","Load single 3-element structure and replicate to all lanes of three registers"],["vld3_dup_u16","Load single 3-element structure and replicate to all lanes of three registers"],["vld3_dup_u32","Load single 3-element structure and replicate to all lanes of three registers"],["vld3_dup_u64","Load single 3-element structure and replicate to all lanes of three registers"],["vld3_dup_u8","Load single 3-element structure and replicate to all lanes of three registers"],["vld3_f64","Load multiple 3-element structures to three registers"],["vld3_lane_f64","Load multiple 3-element structures to three registers"],["vld3_lane_p16","Load multiple 3-element structures to three registers"],["vld3_lane_p64","Load multiple 3-element structures to three registers"],["vld3_lane_p8","Load multiple 3-element structures to three registers"],["vld3_lane_s64","Load multiple 3-element structures to two registers"],["vld3_lane_u16","Load multiple 3-element structures to three registers"],["vld3_lane_u32","Load multiple 3-element structures to three registers"],["vld3_lane_u64","Load multiple 3-element structures to three registers"],["vld3_lane_u8","Load multiple 3-element structures to three registers"],["vld3_p16","Load multiple 3-element structures to three registers"],["vld3_p64","Load multiple 3-element structures to three registers"],["vld3_p8","Load multiple 3-element structures to three registers"],["vld3_u16","Load multiple 3-element structures to three registers"],["vld3_u32","Load multiple 3-element structures to three registers"],["vld3_u64","Load multiple 3-element structures to three registers"],["vld3_u8","Load multiple 3-element structures to three registers"],["vld3q_dup_f64","Load single 3-element structure and replicate to all lanes of three registers"],["vld3q_dup_p16","Load single 3-element structure and replicate to all lanes of three registers"],["vld3q_dup_p64","Load single 3-element structure and replicate to all lanes of three registers"],["vld3q_dup_p8","Load single 3-element structure and replicate to all lanes of three registers"],["vld3q_dup_s64","Load single 3-element structure and replicate to all lanes of three registers"],["vld3q_dup_u16","Load single 3-element structure and replicate to all lanes of three registers"],["vld3q_dup_u32","Load single 3-element structure and replicate to all lanes of three registers"],["vld3q_dup_u64","Load single 3-element structure and replicate to all lanes of three registers"],["vld3q_dup_u8","Load single 3-element structure and replicate to all lanes of three registers"],["vld3q_f64","Load multiple 3-element structures to three registers"],["vld3q_lane_f64","Load multiple 3-element structures to three registers"],["vld3q_lane_p16","Load multiple 3-element structures to three registers"],["vld3q_lane_p64","Load multiple 3-element structures to three registers"],["vld3q_lane_p8","Load multiple 3-element structures to three registers"],["vld3q_lane_s64","Load multiple 3-element structures to two registers"],["vld3q_lane_s8","Load multiple 3-element structures to two registers"],["vld3q_lane_u16","Load multiple 3-element structures to three registers"],["vld3q_lane_u32","Load multiple 3-element structures to three registers"],["vld3q_lane_u64","Load multiple 3-element structures to three registers"],["vld3q_lane_u8","Load multiple 3-element structures to three registers"],["vld3q_p16","Load multiple 3-element structures to three registers"],["vld3q_p64","Load multiple 3-element structures to three registers"],["vld3q_p8","Load multiple 3-element structures to three registers"],["vld3q_s64","Load multiple 3-element structures to three registers"],["vld3q_u16","Load multiple 3-element structures to three registers"],["vld3q_u32","Load multiple 3-element structures to three registers"],["vld3q_u64","Load multiple 3-element structures to three registers"],["vld3q_u8","Load multiple 3-element structures to three registers"],["vld4_dup_f64","Load single 4-element structure and replicate to all lanes of four registers"],["vld4_dup_p16","Load single 4-element structure and replicate to all lanes of four registers"],["vld4_dup_p64","Load single 4-element structure and replicate to all lanes of four registers"],["vld4_dup_p8","Load single 4-element structure and replicate to all lanes of four registers"],["vld4_dup_u16","Load single 4-element structure and replicate to all lanes of four registers"],["vld4_dup_u32","Load single 4-element structure and replicate to all lanes of four registers"],["vld4_dup_u64","Load single 4-element structure and replicate to all lanes of four registers"],["vld4_dup_u8","Load single 4-element structure and replicate to all lanes of four registers"],["vld4_f64","Load multiple 4-element structures to four registers"],["vld4_lane_f64","Load multiple 4-element structures to four registers"],["vld4_lane_p16","Load multiple 4-element structures to four registers"],["vld4_lane_p64","Load multiple 4-element structures to four registers"],["vld4_lane_p8","Load multiple 4-element structures to four registers"],["vld4_lane_s64","Load multiple 4-element structures to four registers"],["vld4_lane_u16","Load multiple 4-element structures to four registers"],["vld4_lane_u32","Load multiple 4-element structures to four registers"],["vld4_lane_u64","Load multiple 4-element structures to four registers"],["vld4_lane_u8","Load multiple 4-element structures to four registers"],["vld4_p16","Load multiple 4-element structures to four registers"],["vld4_p64","Load multiple 4-element structures to four registers"],["vld4_p8","Load multiple 4-element structures to four registers"],["vld4_u16","Load multiple 4-element structures to four registers"],["vld4_u32","Load multiple 4-element structures to four registers"],["vld4_u64","Load multiple 4-element structures to four registers"],["vld4_u8","Load multiple 4-element structures to four registers"],["vld4q_dup_f64","Load single 4-element structure and replicate to all lanes of four registers"],["vld4q_dup_p16","Load single 4-element structure and replicate to all lanes of four registers"],["vld4q_dup_p64","Load single 4-element structure and replicate to all lanes of four registers"],["vld4q_dup_p8","Load single 4-element structure and replicate to all lanes of four registers"],["vld4q_dup_s64","Load single 4-element structure and replicate to all lanes of four registers"],["vld4q_dup_u16","Load single 4-element structure and replicate to all lanes of four registers"],["vld4q_dup_u32","Load single 4-element structure and replicate to all lanes of four registers"],["vld4q_dup_u64","Load single 4-element structure and replicate to all lanes of four registers"],["vld4q_dup_u8","Load single 4-element structure and replicate to all lanes of four registers"],["vld4q_f64","Load multiple 4-element structures to four registers"],["vld4q_lane_f64","Load multiple 4-element structures to four registers"],["vld4q_lane_p16","Load multiple 4-element structures to four registers"],["vld4q_lane_p64","Load multiple 4-element structures to four registers"],["vld4q_lane_p8","Load multiple 4-element structures to four registers"],["vld4q_lane_s64","Load multiple 4-element structures to four registers"],["vld4q_lane_s8","Load multiple 4-element structures to four registers"],["vld4q_lane_u16","Load multiple 4-element structures to four registers"],["vld4q_lane_u32","Load multiple 4-element structures to four registers"],["vld4q_lane_u64","Load multiple 4-element structures to four registers"],["vld4q_lane_u8","Load multiple 4-element structures to four registers"],["vld4q_p16","Load multiple 4-element structures to four registers"],["vld4q_p64","Load multiple 4-element structures to four registers"],["vld4q_p8","Load multiple 4-element structures to four registers"],["vld4q_s64","Load multiple 4-element structures to four registers"],["vld4q_u16","Load multiple 4-element structures to four registers"],["vld4q_u32","Load multiple 4-element structures to four registers"],["vld4q_u64","Load multiple 4-element structures to four registers"],["vld4q_u8","Load multiple 4-element structures to four registers"],["vldrq_p128","Load SIMD&FP register (immediate offset)"],["vmax_f32","Maximum (vector)"],["vmax_f64","Maximum (vector)"],["vmax_s16","Maximum (vector)"],["vmax_s32","Maximum (vector)"],["vmax_s8","Maximum (vector)"],["vmax_u16","Maximum (vector)"],["vmax_u32","Maximum (vector)"],["vmax_u8","Maximum (vector)"],["vmaxnm_f32","Floating-point Maximun Number (vector)"],["vmaxnm_f64","Floating-point Maximun Number (vector)"],["vmaxnmq_f32","Floating-point Maximun Number (vector)"],["vmaxnmq_f64","Floating-point Maximun Number (vector)"],["vmaxnmv_f32","Floating-point maximum number across vector"],["vmaxnmvq_f32","Floating-point maximum number across vector"],["vmaxnmvq_f64","Floating-point maximum number across vector"],["vmaxq_f32","Maximum (vector)"],["vmaxq_f64","Maximum (vector)"],["vmaxq_s16","Maximum (vector)"],["vmaxq_s32","Maximum (vector)"],["vmaxq_s8","Maximum (vector)"],["vmaxq_u16","Maximum (vector)"],["vmaxq_u32","Maximum (vector)"],["vmaxq_u8","Maximum (vector)"],["vmaxv_f32","Horizontal vector max."],["vmaxv_s16","Horizontal vector max."],["vmaxv_s32","Horizontal vector max."],["vmaxv_s8","Horizontal vector max."],["vmaxv_u16","Horizontal vector max."],["vmaxv_u32","Horizontal vector max."],["vmaxv_u8","Horizontal vector max."],["vmaxvq_f32","Horizontal vector max."],["vmaxvq_f64","Horizontal vector max."],["vmaxvq_s16","Horizontal vector max."],["vmaxvq_s32","Horizontal vector max."],["vmaxvq_s8","Horizontal vector max."],["vmaxvq_u16","Horizontal vector max."],["vmaxvq_u32","Horizontal vector max."],["vmaxvq_u8","Horizontal vector max."],["vmin_f32","Minimum (vector)"],["vmin_f64","Minimum (vector)"],["vmin_s16","Minimum (vector)"],["vmin_s32","Minimum (vector)"],["vmin_s8","Minimum (vector)"],["vmin_u16","Minimum (vector)"],["vmin_u32","Minimum (vector)"],["vmin_u8","Minimum (vector)"],["vminnm_f32","Floating-point Minimun Number (vector)"],["vminnm_f64","Floating-point Minimun Number (vector)"],["vminnmq_f32","Floating-point Minimun Number (vector)"],["vminnmq_f64","Floating-point Minimun Number (vector)"],["vminnmv_f32","Floating-point minimum number across vector"],["vminnmvq_f32","Floating-point minimum number across vector"],["vminnmvq_f64","Floating-point minimum number across vector"],["vminq_f32","Minimum (vector)"],["vminq_f64","Minimum (vector)"],["vminq_s16","Minimum (vector)"],["vminq_s32","Minimum (vector)"],["vminq_s8","Minimum (vector)"],["vminq_u16","Minimum (vector)"],["vminq_u32","Minimum (vector)"],["vminq_u8","Minimum (vector)"],["vminv_f32","Horizontal vector min."],["vminv_s16","Horizontal vector min."],["vminv_s32","Horizontal vector min."],["vminv_s8","Horizontal vector min."],["vminv_u16","Horizontal vector min."],["vminv_u32","Horizontal vector min."],["vminv_u8","Horizontal vector min."],["vminvq_f32","Horizontal vector min."],["vminvq_f64","Horizontal vector min."],["vminvq_s16","Horizontal vector min."],["vminvq_s32","Horizontal vector min."],["vminvq_s8","Horizontal vector min."],["vminvq_u16","Horizontal vector min."],["vminvq_u32","Horizontal vector min."],["vminvq_u8","Horizontal vector min."],["vmla_f32","Floating-point multiply-add to accumulator"],["vmla_f64","Floating-point multiply-add to accumulator"],["vmla_lane_f32","Vector multiply accumulate with scalar"],["vmla_lane_s16","Vector multiply accumulate with scalar"],["vmla_lane_s32","Vector multiply accumulate with scalar"],["vmla_lane_u16","Vector multiply accumulate with scalar"],["vmla_lane_u32","Vector multiply accumulate with scalar"],["vmla_laneq_f32","Vector multiply accumulate with scalar"],["vmla_laneq_s16","Vector multiply accumulate with scalar"],["vmla_laneq_s32","Vector multiply accumulate with scalar"],["vmla_laneq_u16","Vector multiply accumulate with scalar"],["vmla_laneq_u32","Vector multiply accumulate with scalar"],["vmla_n_f32","Vector multiply accumulate with scalar"],["vmla_n_s16","Vector multiply accumulate with scalar"],["vmla_n_s32","Vector multiply accumulate with scalar"],["vmla_n_u16","Vector multiply accumulate with scalar"],["vmla_n_u32","Vector multiply accumulate with scalar"],["vmla_s16","Multiply-add to accumulator"],["vmla_s32","Multiply-add to accumulator"],["vmla_s8","Multiply-add to accumulator"],["vmla_u16","Multiply-add to accumulator"],["vmla_u32","Multiply-add to accumulator"],["vmla_u8","Multiply-add to accumulator"],["vmlal_high_lane_s16","Multiply-add long"],["vmlal_high_lane_s32","Multiply-add long"],["vmlal_high_lane_u16","Multiply-add long"],["vmlal_high_lane_u32","Multiply-add long"],["vmlal_high_laneq_s16","Multiply-add long"],["vmlal_high_laneq_s32","Multiply-add long"],["vmlal_high_laneq_u16","Multiply-add long"],["vmlal_high_laneq_u32","Multiply-add long"],["vmlal_high_n_s16","Multiply-add long"],["vmlal_high_n_s32","Multiply-add long"],["vmlal_high_n_u16","Multiply-add long"],["vmlal_high_n_u32","Multiply-add long"],["vmlal_high_s16","Signed multiply-add long"],["vmlal_high_s32","Signed multiply-add long"],["vmlal_high_s8","Signed multiply-add long"],["vmlal_high_u16","Unsigned multiply-add long"],["vmlal_high_u32","Unsigned multiply-add long"],["vmlal_high_u8","Unsigned multiply-add long"],["vmlal_lane_s16","Vector widening multiply accumulate with scalar"],["vmlal_lane_s32","Vector widening multiply accumulate with scalar"],["vmlal_lane_u16","Vector widening multiply accumulate with scalar"],["vmlal_lane_u32","Vector widening multiply accumulate with scalar"],["vmlal_laneq_s16","Vector widening multiply accumulate with scalar"],["vmlal_laneq_s32","Vector widening multiply accumulate with scalar"],["vmlal_laneq_u16","Vector widening multiply accumulate with scalar"],["vmlal_laneq_u32","Vector widening multiply accumulate with scalar"],["vmlal_n_s16","Vector widening multiply accumulate with scalar"],["vmlal_n_s32","Vector widening multiply accumulate with scalar"],["vmlal_n_u16","Vector widening multiply accumulate with scalar"],["vmlal_n_u32","Vector widening multiply accumulate with scalar"],["vmlal_s16","Signed multiply-add long"],["vmlal_s32","Signed multiply-add long"],["vmlal_s8","Signed multiply-add long"],["vmlal_u16","Unsigned multiply-add long"],["vmlal_u32","Unsigned multiply-add long"],["vmlal_u8","Unsigned multiply-add long"],["vmlaq_f32","Floating-point multiply-add to accumulator"],["vmlaq_f64","Floating-point multiply-add to accumulator"],["vmlaq_lane_f32","Vector multiply accumulate with scalar"],["vmlaq_lane_s16","Vector multiply accumulate with scalar"],["vmlaq_lane_s32","Vector multiply accumulate with scalar"],["vmlaq_lane_u16","Vector multiply accumulate with scalar"],["vmlaq_lane_u32","Vector multiply accumulate with scalar"],["vmlaq_laneq_f32","Vector multiply accumulate with scalar"],["vmlaq_laneq_s16","Vector multiply accumulate with scalar"],["vmlaq_laneq_s32","Vector multiply accumulate with scalar"],["vmlaq_laneq_u16","Vector multiply accumulate with scalar"],["vmlaq_laneq_u32","Vector multiply accumulate with scalar"],["vmlaq_n_f32","Vector multiply accumulate with scalar"],["vmlaq_n_s16","Vector multiply accumulate with scalar"],["vmlaq_n_s32","Vector multiply accumulate with scalar"],["vmlaq_n_u16","Vector multiply accumulate with scalar"],["vmlaq_n_u32","Vector multiply accumulate with scalar"],["vmlaq_s16","Multiply-add to accumulator"],["vmlaq_s32","Multiply-add to accumulator"],["vmlaq_s8","Multiply-add to accumulator"],["vmlaq_u16","Multiply-add to accumulator"],["vmlaq_u32","Multiply-add to accumulator"],["vmlaq_u8","Multiply-add to accumulator"],["vmls_f32","Floating-point multiply-subtract from accumulator"],["vmls_f64","Floating-point multiply-subtract from accumulator"],["vmls_lane_f32","Vector multiply subtract with scalar"],["vmls_lane_s16","Vector multiply subtract with scalar"],["vmls_lane_s32","Vector multiply subtract with scalar"],["vmls_lane_u16","Vector multiply subtract with scalar"],["vmls_lane_u32","Vector multiply subtract with scalar"],["vmls_laneq_f32","Vector multiply subtract with scalar"],["vmls_laneq_s16","Vector multiply subtract with scalar"],["vmls_laneq_s32","Vector multiply subtract with scalar"],["vmls_laneq_u16","Vector multiply subtract with scalar"],["vmls_laneq_u32","Vector multiply subtract with scalar"],["vmls_n_f32","Vector multiply subtract with scalar"],["vmls_n_s16","Vector multiply subtract with scalar"],["vmls_n_s32","Vector multiply subtract with scalar"],["vmls_n_u16","Vector multiply subtract with scalar"],["vmls_n_u32","Vector multiply subtract with scalar"],["vmls_s16","Multiply-subtract from accumulator"],["vmls_s32","Multiply-subtract from accumulator"],["vmls_s8","Multiply-subtract from accumulator"],["vmls_u16","Multiply-subtract from accumulator"],["vmls_u32","Multiply-subtract from accumulator"],["vmls_u8","Multiply-subtract from accumulator"],["vmlsl_high_lane_s16","Multiply-subtract long"],["vmlsl_high_lane_s32","Multiply-subtract long"],["vmlsl_high_lane_u16","Multiply-subtract long"],["vmlsl_high_lane_u32","Multiply-subtract long"],["vmlsl_high_laneq_s16","Multiply-subtract long"],["vmlsl_high_laneq_s32","Multiply-subtract long"],["vmlsl_high_laneq_u16","Multiply-subtract long"],["vmlsl_high_laneq_u32","Multiply-subtract long"],["vmlsl_high_n_s16","Multiply-subtract long"],["vmlsl_high_n_s32","Multiply-subtract long"],["vmlsl_high_n_u16","Multiply-subtract long"],["vmlsl_high_n_u32","Multiply-subtract long"],["vmlsl_high_s16","Signed multiply-subtract long"],["vmlsl_high_s32","Signed multiply-subtract long"],["vmlsl_high_s8","Signed multiply-subtract long"],["vmlsl_high_u16","Unsigned multiply-subtract long"],["vmlsl_high_u32","Unsigned multiply-subtract long"],["vmlsl_high_u8","Unsigned multiply-subtract long"],["vmlsl_lane_s16","Vector widening multiply subtract with scalar"],["vmlsl_lane_s32","Vector widening multiply subtract with scalar"],["vmlsl_lane_u16","Vector widening multiply subtract with scalar"],["vmlsl_lane_u32","Vector widening multiply subtract with scalar"],["vmlsl_laneq_s16","Vector widening multiply subtract with scalar"],["vmlsl_laneq_s32","Vector widening multiply subtract with scalar"],["vmlsl_laneq_u16","Vector widening multiply subtract with scalar"],["vmlsl_laneq_u32","Vector widening multiply subtract with scalar"],["vmlsl_n_s16","Vector widening multiply subtract with scalar"],["vmlsl_n_s32","Vector widening multiply subtract with scalar"],["vmlsl_n_u16","Vector widening multiply subtract with scalar"],["vmlsl_n_u32","Vector widening multiply subtract with scalar"],["vmlsl_s16","Signed multiply-subtract long"],["vmlsl_s32","Signed multiply-subtract long"],["vmlsl_s8","Signed multiply-subtract long"],["vmlsl_u16","Unsigned multiply-subtract long"],["vmlsl_u32","Unsigned multiply-subtract long"],["vmlsl_u8","Unsigned multiply-subtract long"],["vmlsq_f32","Floating-point multiply-subtract from accumulator"],["vmlsq_f64","Floating-point multiply-subtract from accumulator"],["vmlsq_lane_f32","Vector multiply subtract with scalar"],["vmlsq_lane_s16","Vector multiply subtract with scalar"],["vmlsq_lane_s32","Vector multiply subtract with scalar"],["vmlsq_lane_u16","Vector multiply subtract with scalar"],["vmlsq_lane_u32","Vector multiply subtract with scalar"],["vmlsq_laneq_f32","Vector multiply subtract with scalar"],["vmlsq_laneq_s16","Vector multiply subtract with scalar"],["vmlsq_laneq_s32","Vector multiply subtract with scalar"],["vmlsq_laneq_u16","Vector multiply subtract with scalar"],["vmlsq_laneq_u32","Vector multiply subtract with scalar"],["vmlsq_n_f32","Vector multiply subtract with scalar"],["vmlsq_n_s16","Vector multiply subtract with scalar"],["vmlsq_n_s32","Vector multiply subtract with scalar"],["vmlsq_n_u16","Vector multiply subtract with scalar"],["vmlsq_n_u32","Vector multiply subtract with scalar"],["vmlsq_s16","Multiply-subtract from accumulator"],["vmlsq_s32","Multiply-subtract from accumulator"],["vmlsq_s8","Multiply-subtract from accumulator"],["vmlsq_u16","Multiply-subtract from accumulator"],["vmlsq_u32","Multiply-subtract from accumulator"],["vmlsq_u8","Multiply-subtract from accumulator"],["vmmlaq_s32","8-bit integer matrix multiply-accumulate"],["vmmlaq_u32","8-bit integer matrix multiply-accumulate"],["vmov_n_f32","Duplicate vector element to vector or scalar"],["vmov_n_f64","Duplicate vector element to vector or scalar"],["vmov_n_p16","Duplicate vector element to vector or scalar"],["vmov_n_p64","Duplicate vector element to vector or scalar"],["vmov_n_p8","Duplicate vector element to vector or scalar"],["vmov_n_s16","Duplicate vector element to vector or scalar"],["vmov_n_s32","Duplicate vector element to vector or scalar"],["vmov_n_s64","Duplicate vector element to vector or scalar"],["vmov_n_s8","Duplicate vector element to vector or scalar"],["vmov_n_u16","Duplicate vector element to vector or scalar"],["vmov_n_u32","Duplicate vector element to vector or scalar"],["vmov_n_u64","Duplicate vector element to vector or scalar"],["vmov_n_u8","Duplicate vector element to vector or scalar"],["vmovl_high_s16","Vector move"],["vmovl_high_s32","Vector move"],["vmovl_high_s8","Vector move"],["vmovl_high_u16","Vector move"],["vmovl_high_u32","Vector move"],["vmovl_high_u8","Vector move"],["vmovl_s16","Vector long move."],["vmovl_s32","Vector long move."],["vmovl_s8","Vector long move."],["vmovl_u16","Vector long move."],["vmovl_u32","Vector long move."],["vmovl_u8","Vector long move."],["vmovn_high_s16","Extract narrow"],["vmovn_high_s32","Extract narrow"],["vmovn_high_s64","Extract narrow"],["vmovn_high_u16","Extract narrow"],["vmovn_high_u32","Extract narrow"],["vmovn_high_u64","Extract narrow"],["vmovn_s16","Vector narrow integer."],["vmovn_s32","Vector narrow integer."],["vmovn_s64","Vector narrow integer."],["vmovn_u16","Vector narrow integer."],["vmovn_u32","Vector narrow integer."],["vmovn_u64","Vector narrow integer."],["vmovq_n_f32","Duplicate vector element to vector or scalar"],["vmovq_n_f64","Duplicate vector element to vector or scalar"],["vmovq_n_p16","Duplicate vector element to vector or scalar"],["vmovq_n_p64","Duplicate vector element to vector or scalar"],["vmovq_n_p8","Duplicate vector element to vector or scalar"],["vmovq_n_s16","Duplicate vector element to vector or scalar"],["vmovq_n_s32","Duplicate vector element to vector or scalar"],["vmovq_n_s64","Duplicate vector element to vector or scalar"],["vmovq_n_s8","Duplicate vector element to vector or scalar"],["vmovq_n_u16","Duplicate vector element to vector or scalar"],["vmovq_n_u32","Duplicate vector element to vector or scalar"],["vmovq_n_u64","Duplicate vector element to vector or scalar"],["vmovq_n_u8","Duplicate vector element to vector or scalar"],["vmul_f32","Multiply"],["vmul_f64","Multiply"],["vmul_lane_f32","Floating-point multiply"],["vmul_lane_f64","Floating-point multiply"],["vmul_lane_s16","Multiply"],["vmul_lane_s32","Multiply"],["vmul_lane_u16","Multiply"],["vmul_lane_u32","Multiply"],["vmul_laneq_f32","Floating-point multiply"],["vmul_laneq_f64","Floating-point multiply"],["vmul_laneq_s16","Multiply"],["vmul_laneq_s32","Multiply"],["vmul_laneq_u16","Multiply"],["vmul_laneq_u32","Multiply"],["vmul_n_f32","Vector multiply by scalar"],["vmul_n_f64","Vector multiply by scalar"],["vmul_n_s16","Vector multiply by scalar"],["vmul_n_s32","Vector multiply by scalar"],["vmul_n_u16","Vector multiply by scalar"],["vmul_n_u32","Vector multiply by scalar"],["vmul_p8","Polynomial multiply"],["vmul_s16","Multiply"],["vmul_s32","Multiply"],["vmul_s8","Multiply"],["vmul_u16","Multiply"],["vmul_u32","Multiply"],["vmul_u8","Multiply"],["vmuld_lane_f64","Floating-point multiply"],["vmuld_laneq_f64","Floating-point multiply"],["vmull_high_lane_s16","Multiply long"],["vmull_high_lane_s32","Multiply long"],["vmull_high_lane_u16","Multiply long"],["vmull_high_lane_u32","Multiply long"],["vmull_high_laneq_s16","Multiply long"],["vmull_high_laneq_s32","Multiply long"],["vmull_high_laneq_u16","Multiply long"],["vmull_high_laneq_u32","Multiply long"],["vmull_high_n_s16","Multiply long"],["vmull_high_n_s32","Multiply long"],["vmull_high_n_u16","Multiply long"],["vmull_high_n_u32","Multiply long"],["vmull_high_p64","Polynomial multiply long"],["vmull_high_p8","Polynomial multiply long"],["vmull_high_s16","Signed multiply long"],["vmull_high_s32","Signed multiply long"],["vmull_high_s8","Signed multiply long"],["vmull_high_u16","Unsigned multiply long"],["vmull_high_u32","Unsigned multiply long"],["vmull_high_u8","Unsigned multiply long"],["vmull_lane_s16","Vector long multiply by scalar"],["vmull_lane_s32","Vector long multiply by scalar"],["vmull_lane_u16","Vector long multiply by scalar"],["vmull_lane_u32","Vector long multiply by scalar"],["vmull_laneq_s16","Vector long multiply by scalar"],["vmull_laneq_s32","Vector long multiply by scalar"],["vmull_laneq_u16","Vector long multiply by scalar"],["vmull_laneq_u32","Vector long multiply by scalar"],["vmull_n_s16","Vector long multiply with scalar"],["vmull_n_s32","Vector long multiply with scalar"],["vmull_n_u16","Vector long multiply with scalar"],["vmull_n_u32","Vector long multiply with scalar"],["vmull_p64","Polynomial multiply long"],["vmull_p8","Polynomial multiply long"],["vmull_s16","Signed multiply long"],["vmull_s32","Signed multiply long"],["vmull_s8","Signed multiply long"],["vmull_u16","Unsigned multiply long"],["vmull_u32","Unsigned multiply long"],["vmull_u8","Unsigned multiply long"],["vmulq_f32","Multiply"],["vmulq_f64","Multiply"],["vmulq_lane_f32","Floating-point multiply"],["vmulq_lane_f64","Floating-point multiply"],["vmulq_lane_s16","Multiply"],["vmulq_lane_s32","Multiply"],["vmulq_lane_u16","Multiply"],["vmulq_lane_u32","Multiply"],["vmulq_laneq_f32","Floating-point multiply"],["vmulq_laneq_f64","Floating-point multiply"],["vmulq_laneq_s16","Multiply"],["vmulq_laneq_s32","Multiply"],["vmulq_laneq_u16","Multiply"],["vmulq_laneq_u32","Multiply"],["vmulq_n_f32","Vector multiply by scalar"],["vmulq_n_f64","Vector multiply by scalar"],["vmulq_n_s16","Vector multiply by scalar"],["vmulq_n_s32","Vector multiply by scalar"],["vmulq_n_u16","Vector multiply by scalar"],["vmulq_n_u32","Vector multiply by scalar"],["vmulq_p8","Polynomial multiply"],["vmulq_s16","Multiply"],["vmulq_s32","Multiply"],["vmulq_s8","Multiply"],["vmulq_u16","Multiply"],["vmulq_u32","Multiply"],["vmulq_u8","Multiply"],["vmuls_lane_f32","Floating-point multiply"],["vmuls_laneq_f32","Floating-point multiply"],["vmulx_f32","Floating-point multiply extended"],["vmulx_f64","Floating-point multiply extended"],["vmulx_lane_f32","Floating-point multiply extended"],["vmulx_lane_f64","Floating-point multiply extended"],["vmulx_laneq_f32","Floating-point multiply extended"],["vmulx_laneq_f64","Floating-point multiply extended"],["vmulxd_f64","Floating-point multiply extended"],["vmulxd_lane_f64","Floating-point multiply extended"],["vmulxd_laneq_f64","Floating-point multiply extended"],["vmulxq_f32","Floating-point multiply extended"],["vmulxq_f64","Floating-point multiply extended"],["vmulxq_lane_f32","Floating-point multiply extended"],["vmulxq_lane_f64","Floating-point multiply extended"],["vmulxq_laneq_f32","Floating-point multiply extended"],["vmulxq_laneq_f64","Floating-point multiply extended"],["vmulxs_f32","Floating-point multiply extended"],["vmulxs_lane_f32","Floating-point multiply extended"],["vmulxs_laneq_f32","Floating-point multiply extended"],["vmvn_p8","Vector bitwise not."],["vmvn_s16","Vector bitwise not."],["vmvn_s32","Vector bitwise not."],["vmvn_s8","Vector bitwise not."],["vmvn_u16","Vector bitwise not."],["vmvn_u32","Vector bitwise not."],["vmvn_u8","Vector bitwise not."],["vmvnq_p8","Vector bitwise not."],["vmvnq_s16","Vector bitwise not."],["vmvnq_s32","Vector bitwise not."],["vmvnq_s8","Vector bitwise not."],["vmvnq_u16","Vector bitwise not."],["vmvnq_u32","Vector bitwise not."],["vmvnq_u8","Vector bitwise not."],["vneg_f32","Negate"],["vneg_f64","Negate"],["vneg_s16","Negate"],["vneg_s32","Negate"],["vneg_s64","Negate"],["vneg_s8","Negate"],["vnegd_s64","Negate"],["vnegq_f32","Negate"],["vnegq_f64","Negate"],["vnegq_s16","Negate"],["vnegq_s32","Negate"],["vnegq_s64","Negate"],["vnegq_s8","Negate"],["vorn_s16","Vector bitwise inclusive OR NOT"],["vorn_s32","Vector bitwise inclusive OR NOT"],["vorn_s64","Vector bitwise inclusive OR NOT"],["vorn_s8","Vector bitwise inclusive OR NOT"],["vorn_u16","Vector bitwise inclusive OR NOT"],["vorn_u32","Vector bitwise inclusive OR NOT"],["vorn_u64","Vector bitwise inclusive OR NOT"],["vorn_u8","Vector bitwise inclusive OR NOT"],["vornq_s16","Vector bitwise inclusive OR NOT"],["vornq_s32","Vector bitwise inclusive OR NOT"],["vornq_s64","Vector bitwise inclusive OR NOT"],["vornq_s8","Vector bitwise inclusive OR NOT"],["vornq_u16","Vector bitwise inclusive OR NOT"],["vornq_u32","Vector bitwise inclusive OR NOT"],["vornq_u64","Vector bitwise inclusive OR NOT"],["vornq_u8","Vector bitwise inclusive OR NOT"],["vorr_s16","Vector bitwise or (immediate, inclusive)"],["vorr_s32","Vector bitwise or (immediate, inclusive)"],["vorr_s64","Vector bitwise or (immediate, inclusive)"],["vorr_s8","Vector bitwise or (immediate, inclusive)"],["vorr_u16","Vector bitwise or (immediate, inclusive)"],["vorr_u32","Vector bitwise or (immediate, inclusive)"],["vorr_u64","Vector bitwise or (immediate, inclusive)"],["vorr_u8","Vector bitwise or (immediate, inclusive)"],["vorrq_s16","Vector bitwise or (immediate, inclusive)"],["vorrq_s32","Vector bitwise or (immediate, inclusive)"],["vorrq_s64","Vector bitwise or (immediate, inclusive)"],["vorrq_s8","Vector bitwise or (immediate, inclusive)"],["vorrq_u16","Vector bitwise or (immediate, inclusive)"],["vorrq_u32","Vector bitwise or (immediate, inclusive)"],["vorrq_u64","Vector bitwise or (immediate, inclusive)"],["vorrq_u8","Vector bitwise or (immediate, inclusive)"],["vpadal_s16","Signed Add and Accumulate Long Pairwise."],["vpadal_s32","Signed Add and Accumulate Long Pairwise."],["vpadal_s8","Signed Add and Accumulate Long Pairwise."],["vpadal_u16","Unsigned Add and Accumulate Long Pairwise."],["vpadal_u32","Unsigned Add and Accumulate Long Pairwise."],["vpadal_u8","Unsigned Add and Accumulate Long Pairwise."],["vpadalq_s16","Signed Add and Accumulate Long Pairwise."],["vpadalq_s32","Signed Add and Accumulate Long Pairwise."],["vpadalq_s8","Signed Add and Accumulate Long Pairwise."],["vpadalq_u16","Unsigned Add and Accumulate Long Pairwise."],["vpadalq_u32","Unsigned Add and Accumulate Long Pairwise."],["vpadalq_u8","Unsigned Add and Accumulate Long Pairwise."],["vpadd_f32","Floating-point add pairwise"],["vpadd_s16","Add pairwise."],["vpadd_s32","Add pairwise."],["vpadd_s8","Add pairwise."],["vpadd_u16","Add pairwise."],["vpadd_u32","Add pairwise."],["vpadd_u8","Add pairwise."],["vpaddd_f64","Floating-point add pairwise"],["vpaddd_s64","Add pairwise"],["vpaddd_u64","Add pairwise"],["vpaddl_s16","Signed Add Long Pairwise."],["vpaddl_s32","Signed Add Long Pairwise."],["vpaddl_s8","Signed Add Long Pairwise."],["vpaddl_u16","Unsigned Add Long Pairwise."],["vpaddl_u32","Unsigned Add Long Pairwise."],["vpaddl_u8","Unsigned Add Long Pairwise."],["vpaddlq_s16","Signed Add Long Pairwise."],["vpaddlq_s32","Signed Add Long Pairwise."],["vpaddlq_s8","Signed Add Long Pairwise."],["vpaddlq_u16","Unsigned Add Long Pairwise."],["vpaddlq_u32","Unsigned Add Long Pairwise."],["vpaddlq_u8","Unsigned Add Long Pairwise."],["vpaddq_f32","Floating-point add pairwise"],["vpaddq_f64","Floating-point add pairwise"],["vpaddq_s16","Add pairwise"],["vpaddq_s32","Add pairwise"],["vpaddq_s64","Add pairwise"],["vpaddq_s8","Add pairwise"],["vpaddq_u16","Add pairwise"],["vpaddq_u32","Add pairwise"],["vpaddq_u64","Add pairwise"],["vpaddq_u8","Add pairwise"],["vpadds_f32","Floating-point add pairwise"],["vpmax_f32","Folding maximum of adjacent pairs"],["vpmax_s16","Folding maximum of adjacent pairs"],["vpmax_s32","Folding maximum of adjacent pairs"],["vpmax_s8","Folding maximum of adjacent pairs"],["vpmax_u16","Folding maximum of adjacent pairs"],["vpmax_u32","Folding maximum of adjacent pairs"],["vpmax_u8","Folding maximum of adjacent pairs"],["vpmaxnm_f32","Floating-point Maximum Number Pairwise (vector)."],["vpmaxnmq_f32","Floating-point Maximum Number Pairwise (vector)."],["vpmaxnmq_f64","Floating-point Maximum Number Pairwise (vector)."],["vpmaxnmqd_f64","Floating-point maximum number pairwise"],["vpmaxnms_f32","Floating-point maximum number pairwise"],["vpmaxq_f32","Folding maximum of adjacent pairs"],["vpmaxq_f64","Folding maximum of adjacent pairs"],["vpmaxq_s16","Folding maximum of adjacent pairs"],["vpmaxq_s32","Folding maximum of adjacent pairs"],["vpmaxq_s8","Folding maximum of adjacent pairs"],["vpmaxq_u16","Folding maximum of adjacent pairs"],["vpmaxq_u32","Folding maximum of adjacent pairs"],["vpmaxq_u8","Folding maximum of adjacent pairs"],["vpmaxqd_f64","Floating-point maximum pairwise"],["vpmaxs_f32","Floating-point maximum pairwise"],["vpmin_f32","Folding minimum of adjacent pairs"],["vpmin_s16","Folding minimum of adjacent pairs"],["vpmin_s32","Folding minimum of adjacent pairs"],["vpmin_s8","Folding minimum of adjacent pairs"],["vpmin_u16","Folding minimum of adjacent pairs"],["vpmin_u32","Folding minimum of adjacent pairs"],["vpmin_u8","Folding minimum of adjacent pairs"],["vpminnm_f32","Floating-point Minimum Number Pairwise (vector)."],["vpminnmq_f32","Floating-point Minimum Number Pairwise (vector)."],["vpminnmq_f64","Floating-point Minimum Number Pairwise (vector)."],["vpminnmqd_f64","Floating-point minimum number pairwise"],["vpminnms_f32","Floating-point minimum number pairwise"],["vpminq_f32","Folding minimum of adjacent pairs"],["vpminq_f64","Folding minimum of adjacent pairs"],["vpminq_s16","Folding minimum of adjacent pairs"],["vpminq_s32","Folding minimum of adjacent pairs"],["vpminq_s8","Folding minimum of adjacent pairs"],["vpminq_u16","Folding minimum of adjacent pairs"],["vpminq_u32","Folding minimum of adjacent pairs"],["vpminq_u8","Folding minimum of adjacent pairs"],["vpminqd_f64","Floating-point minimum pairwise"],["vpmins_f32","Floating-point minimum pairwise"],["vqabs_s16","Singned saturating Absolute value"],["vqabs_s32","Singned saturating Absolute value"],["vqabs_s64","Singned saturating Absolute value"],["vqabs_s8","Singned saturating Absolute value"],["vqabsb_s8","Signed saturating absolute value"],["vqabsd_s64","Signed saturating absolute value"],["vqabsh_s16","Signed saturating absolute value"],["vqabsq_s16","Singned saturating Absolute value"],["vqabsq_s32","Singned saturating Absolute value"],["vqabsq_s64","Singned saturating Absolute value"],["vqabsq_s8","Singned saturating Absolute value"],["vqabss_s32","Signed saturating absolute value"],["vqadd_s16","Saturating add"],["vqadd_s32","Saturating add"],["vqadd_s64","Saturating add"],["vqadd_s8","Saturating add"],["vqadd_u16","Saturating add"],["vqadd_u32","Saturating add"],["vqadd_u64","Saturating add"],["vqadd_u8","Saturating add"],["vqaddb_s8","Saturating add"],["vqaddb_u8","Saturating add"],["vqaddd_s64","Saturating add"],["vqaddd_u64","Saturating add"],["vqaddh_s16","Saturating add"],["vqaddh_u16","Saturating add"],["vqaddq_s16","Saturating add"],["vqaddq_s32","Saturating add"],["vqaddq_s64","Saturating add"],["vqaddq_s8","Saturating add"],["vqaddq_u16","Saturating add"],["vqaddq_u32","Saturating add"],["vqaddq_u64","Saturating add"],["vqaddq_u8","Saturating add"],["vqadds_s32","Saturating add"],["vqadds_u32","Saturating add"],["vqdmlal_high_lane_s16","Signed saturating doubling multiply-add long"],["vqdmlal_high_lane_s32","Signed saturating doubling multiply-add long"],["vqdmlal_high_laneq_s16","Signed saturating doubling multiply-add long"],["vqdmlal_high_laneq_s32","Signed saturating doubling multiply-add long"],["vqdmlal_high_n_s16","Signed saturating doubling multiply-add long"],["vqdmlal_high_n_s32","Signed saturating doubling multiply-add long"],["vqdmlal_high_s16","Signed saturating doubling multiply-add long"],["vqdmlal_high_s32","Signed saturating doubling multiply-add long"],["vqdmlal_lane_s16","Vector widening saturating doubling multiply accumulate with scalar"],["vqdmlal_lane_s32","Vector widening saturating doubling multiply accumulate with scalar"],["vqdmlal_laneq_s16","Vector widening saturating doubling multiply accumulate with scalar"],["vqdmlal_laneq_s32","Vector widening saturating doubling multiply accumulate with scalar"],["vqdmlal_n_s16","Vector widening saturating doubling multiply accumulate with scalar"],["vqdmlal_n_s32","Vector widening saturating doubling multiply accumulate with scalar"],["vqdmlal_s16","Signed saturating doubling multiply-add long"],["vqdmlal_s32","Signed saturating doubling multiply-add long"],["vqdmlalh_lane_s16","Signed saturating doubling multiply-add long"],["vqdmlalh_laneq_s16","Signed saturating doubling multiply-add long"],["vqdmlalh_s16","Signed saturating doubling multiply-add long"],["vqdmlals_lane_s32","Signed saturating doubling multiply-add long"],["vqdmlals_laneq_s32","Signed saturating doubling multiply-add long"],["vqdmlals_s32","Signed saturating doubling multiply-add long"],["vqdmlsl_high_lane_s16","Signed saturating doubling multiply-subtract long"],["vqdmlsl_high_lane_s32","Signed saturating doubling multiply-subtract long"],["vqdmlsl_high_laneq_s16","Signed saturating doubling multiply-subtract long"],["vqdmlsl_high_laneq_s32","Signed saturating doubling multiply-subtract long"],["vqdmlsl_high_n_s16","Signed saturating doubling multiply-subtract long"],["vqdmlsl_high_n_s32","Signed saturating doubling multiply-subtract long"],["vqdmlsl_high_s16","Signed saturating doubling multiply-subtract long"],["vqdmlsl_high_s32","Signed saturating doubling multiply-subtract long"],["vqdmlsl_lane_s16","Vector widening saturating doubling multiply subtract with scalar"],["vqdmlsl_lane_s32","Vector widening saturating doubling multiply subtract with scalar"],["vqdmlsl_laneq_s16","Vector widening saturating doubling multiply subtract with scalar"],["vqdmlsl_laneq_s32","Vector widening saturating doubling multiply subtract with scalar"],["vqdmlsl_n_s16","Vector widening saturating doubling multiply subtract with scalar"],["vqdmlsl_n_s32","Vector widening saturating doubling multiply subtract with scalar"],["vqdmlsl_s16","Signed saturating doubling multiply-subtract long"],["vqdmlsl_s32","Signed saturating doubling multiply-subtract long"],["vqdmlslh_lane_s16","Signed saturating doubling multiply-subtract long"],["vqdmlslh_laneq_s16","Signed saturating doubling multiply-subtract long"],["vqdmlslh_s16","Signed saturating doubling multiply-subtract long"],["vqdmlsls_lane_s32","Signed saturating doubling multiply-subtract long"],["vqdmlsls_laneq_s32","Signed saturating doubling multiply-subtract long"],["vqdmlsls_s32","Signed saturating doubling multiply-subtract long"],["vqdmulh_lane_s16","Vector saturating doubling multiply high by scalar"],["vqdmulh_lane_s32","Vector saturating doubling multiply high by scalar"],["vqdmulh_laneq_s16","Vector saturating doubling multiply high by scalar"],["vqdmulh_laneq_s32","Vector saturating doubling multiply high by scalar"],["vqdmulh_n_s16","Vector saturating doubling multiply high with scalar"],["vqdmulh_n_s32","Vector saturating doubling multiply high with scalar"],["vqdmulh_s16","Signed saturating doubling multiply returning high half"],["vqdmulh_s32","Signed saturating doubling multiply returning high half"],["vqdmulhh_lane_s16","Signed saturating doubling multiply returning high half"],["vqdmulhh_laneq_s16","Signed saturating doubling multiply returning high half"],["vqdmulhh_s16","Signed saturating doubling multiply returning high half"],["vqdmulhq_lane_s16","Vector saturating doubling multiply high by scalar"],["vqdmulhq_lane_s32","Vector saturating doubling multiply high by scalar"],["vqdmulhq_laneq_s16","Vector saturating doubling multiply high by scalar"],["vqdmulhq_laneq_s32","Vector saturating doubling multiply high by scalar"],["vqdmulhq_n_s16","Vector saturating doubling multiply high with scalar"],["vqdmulhq_n_s32","Vector saturating doubling multiply high with scalar"],["vqdmulhq_s16","Signed saturating doubling multiply returning high half"],["vqdmulhq_s32","Signed saturating doubling multiply returning high half"],["vqdmulhs_lane_s32","Signed saturating doubling multiply returning high half"],["vqdmulhs_laneq_s32","Signed saturating doubling multiply returning high half"],["vqdmulhs_s32","Signed saturating doubling multiply returning high half"],["vqdmull_high_lane_s16","Signed saturating doubling multiply long"],["vqdmull_high_lane_s32","Signed saturating doubling multiply long"],["vqdmull_high_laneq_s16","Signed saturating doubling multiply long"],["vqdmull_high_laneq_s32","Signed saturating doubling multiply long"],["vqdmull_high_n_s16","Signed saturating doubling multiply long"],["vqdmull_high_n_s32","Signed saturating doubling multiply long"],["vqdmull_high_s16","Signed saturating doubling multiply long"],["vqdmull_high_s32","Signed saturating doubling multiply long"],["vqdmull_lane_s16","Vector saturating doubling long multiply by scalar"],["vqdmull_lane_s32","Vector saturating doubling long multiply by scalar"],["vqdmull_laneq_s16","Vector saturating doubling long multiply by scalar"],["vqdmull_laneq_s32","Vector saturating doubling long multiply by scalar"],["vqdmull_n_s16","Vector saturating doubling long multiply with scalar"],["vqdmull_n_s32","Vector saturating doubling long multiply with scalar"],["vqdmull_s16","Signed saturating doubling multiply long"],["vqdmull_s32","Signed saturating doubling multiply long"],["vqdmullh_lane_s16","Signed saturating doubling multiply long"],["vqdmullh_laneq_s16","Signed saturating doubling multiply long"],["vqdmullh_s16","Signed saturating doubling multiply long"],["vqdmulls_lane_s32","Signed saturating doubling multiply long"],["vqdmulls_laneq_s32","Signed saturating doubling multiply long"],["vqdmulls_s32","Signed saturating doubling multiply long"],["vqmovn_high_s16","Signed saturating extract narrow"],["vqmovn_high_s32","Signed saturating extract narrow"],["vqmovn_high_s64","Signed saturating extract narrow"],["vqmovn_high_u16","Signed saturating extract narrow"],["vqmovn_high_u32","Signed saturating extract narrow"],["vqmovn_high_u64","Signed saturating extract narrow"],["vqmovn_s16","Signed saturating extract narrow"],["vqmovn_s32","Signed saturating extract narrow"],["vqmovn_s64","Signed saturating extract narrow"],["vqmovn_u16","Unsigned saturating extract narrow"],["vqmovn_u32","Unsigned saturating extract narrow"],["vqmovn_u64","Unsigned saturating extract narrow"],["vqmovnd_s64","Saturating extract narrow"],["vqmovnd_u64","Saturating extract narrow"],["vqmovnh_s16","Saturating extract narrow"],["vqmovnh_u16","Saturating extract narrow"],["vqmovns_s32","Saturating extract narrow"],["vqmovns_u32","Saturating extract narrow"],["vqmovun_high_s16","Signed saturating extract unsigned narrow"],["vqmovun_high_s32","Signed saturating extract unsigned narrow"],["vqmovun_high_s64","Signed saturating extract unsigned narrow"],["vqmovun_s16","Signed saturating extract unsigned narrow"],["vqmovun_s32","Signed saturating extract unsigned narrow"],["vqmovun_s64","Signed saturating extract unsigned narrow"],["vqmovund_s64","Signed saturating extract unsigned narrow"],["vqmovunh_s16","Signed saturating extract unsigned narrow"],["vqmovuns_s32","Signed saturating extract unsigned narrow"],["vqneg_s16","Signed saturating negate"],["vqneg_s32","Signed saturating negate"],["vqneg_s64","Signed saturating negate"],["vqneg_s8","Signed saturating negate"],["vqnegb_s8","Signed saturating negate"],["vqnegd_s64","Signed saturating negate"],["vqnegh_s16","Signed saturating negate"],["vqnegq_s16","Signed saturating negate"],["vqnegq_s32","Signed saturating negate"],["vqnegq_s64","Signed saturating negate"],["vqnegq_s8","Signed saturating negate"],["vqnegs_s32","Signed saturating negate"],["vqrdmlah_lane_s16","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlah_lane_s32","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlah_laneq_s16","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlah_laneq_s32","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlah_s16","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlah_s32","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahh_lane_s16","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahh_laneq_s16","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahh_s16","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahq_lane_s16","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahq_lane_s32","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahq_laneq_s16","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahq_laneq_s32","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahq_s16","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahq_s32","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahs_lane_s32","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahs_laneq_s32","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlahs_s32","Signed saturating rounding doubling multiply accumulate returning high half"],["vqrdmlsh_lane_s16","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlsh_lane_s32","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlsh_laneq_s16","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlsh_laneq_s32","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlsh_s16","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlsh_s32","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshh_lane_s16","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshh_laneq_s16","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshh_s16","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshq_lane_s16","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshq_lane_s32","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshq_laneq_s16","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshq_laneq_s32","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshq_s16","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshq_s32","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshs_lane_s32","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshs_laneq_s32","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmlshs_s32","Signed saturating rounding doubling multiply subtract returning high half"],["vqrdmulh_lane_s16","Vector rounding saturating doubling multiply high by scalar"],["vqrdmulh_lane_s32","Vector rounding saturating doubling multiply high by scalar"],["vqrdmulh_laneq_s16","Vector rounding saturating doubling multiply high by scalar"],["vqrdmulh_laneq_s32","Vector rounding saturating doubling multiply high by scalar"],["vqrdmulh_n_s16","Vector saturating rounding doubling multiply high with scalar"],["vqrdmulh_n_s32","Vector saturating rounding doubling multiply high with scalar"],["vqrdmulh_s16","Signed saturating rounding doubling multiply returning high half"],["vqrdmulh_s32","Signed saturating rounding doubling multiply returning high half"],["vqrdmulhh_lane_s16","Signed saturating rounding doubling multiply returning high half"],["vqrdmulhh_laneq_s16","Signed saturating rounding doubling multiply returning high half"],["vqrdmulhh_s16","Signed saturating rounding doubling multiply returning high half"],["vqrdmulhq_lane_s16","Vector rounding saturating doubling multiply high by scalar"],["vqrdmulhq_lane_s32","Vector rounding saturating doubling multiply high by scalar"],["vqrdmulhq_laneq_s16","Vector rounding saturating doubling multiply high by scalar"],["vqrdmulhq_laneq_s32","Vector rounding saturating doubling multiply high by scalar"],["vqrdmulhq_n_s16","Vector saturating rounding doubling multiply high with scalar"],["vqrdmulhq_n_s32","Vector saturating rounding doubling multiply high with scalar"],["vqrdmulhq_s16","Signed saturating rounding doubling multiply returning high half"],["vqrdmulhq_s32","Signed saturating rounding doubling multiply returning high half"],["vqrdmulhs_lane_s32","Signed saturating rounding doubling multiply returning high half"],["vqrdmulhs_laneq_s32","Signed saturating rounding doubling multiply returning high half"],["vqrdmulhs_s32","Signed saturating rounding doubling multiply returning high half"],["vqrshl_s16","Signed saturating rounding shift left"],["vqrshl_s32","Signed saturating rounding shift left"],["vqrshl_s64","Signed saturating rounding shift left"],["vqrshl_s8","Signed saturating rounding shift left"],["vqrshl_u16","Unsigned signed saturating rounding shift left"],["vqrshl_u32","Unsigned signed saturating rounding shift left"],["vqrshl_u64","Unsigned signed saturating rounding shift left"],["vqrshl_u8","Unsigned signed saturating rounding shift left"],["vqrshlb_s8","Signed saturating rounding shift left"],["vqrshlb_u8","Unsigned signed saturating rounding shift left"],["vqrshld_s64","Signed saturating rounding shift left"],["vqrshld_u64","Unsigned signed saturating rounding shift left"],["vqrshlh_s16","Signed saturating rounding shift left"],["vqrshlh_u16","Unsigned signed saturating rounding shift left"],["vqrshlq_s16","Signed saturating rounding shift left"],["vqrshlq_s32","Signed saturating rounding shift left"],["vqrshlq_s64","Signed saturating rounding shift left"],["vqrshlq_s8","Signed saturating rounding shift left"],["vqrshlq_u16","Unsigned signed saturating rounding shift left"],["vqrshlq_u32","Unsigned signed saturating rounding shift left"],["vqrshlq_u64","Unsigned signed saturating rounding shift left"],["vqrshlq_u8","Unsigned signed saturating rounding shift left"],["vqrshls_s32","Signed saturating rounding shift left"],["vqrshls_u32","Unsigned signed saturating rounding shift left"],["vqrshrn_high_n_s16","Signed saturating rounded shift right narrow"],["vqrshrn_high_n_s32","Signed saturating rounded shift right narrow"],["vqrshrn_high_n_s64","Signed saturating rounded shift right narrow"],["vqrshrn_high_n_u16","Unsigned saturating rounded shift right narrow"],["vqrshrn_high_n_u32","Unsigned saturating rounded shift right narrow"],["vqrshrn_high_n_u64","Unsigned saturating rounded shift right narrow"],["vqrshrnd_n_s64","Signed saturating rounded shift right narrow"],["vqrshrnd_n_u64","Unsigned saturating rounded shift right narrow"],["vqrshrnh_n_s16","Signed saturating rounded shift right narrow"],["vqrshrnh_n_u16","Unsigned saturating rounded shift right narrow"],["vqrshrns_n_s32","Signed saturating rounded shift right narrow"],["vqrshrns_n_u32","Unsigned saturating rounded shift right narrow"],["vqrshrun_high_n_s16","Signed saturating rounded shift right unsigned narrow"],["vqrshrun_high_n_s32","Signed saturating rounded shift right unsigned narrow"],["vqrshrun_high_n_s64","Signed saturating rounded shift right unsigned narrow"],["vqrshrund_n_s64","Signed saturating rounded shift right unsigned narrow"],["vqrshrunh_n_s16","Signed saturating rounded shift right unsigned narrow"],["vqrshruns_n_s32","Signed saturating rounded shift right unsigned narrow"],["vqshl_n_s16","Signed saturating shift left"],["vqshl_n_s32","Signed saturating shift left"],["vqshl_n_s64","Signed saturating shift left"],["vqshl_n_s8","Signed saturating shift left"],["vqshl_n_u16","Unsigned saturating shift left"],["vqshl_n_u32","Unsigned saturating shift left"],["vqshl_n_u64","Unsigned saturating shift left"],["vqshl_n_u8","Unsigned saturating shift left"],["vqshl_s16","Signed saturating shift left"],["vqshl_s32","Signed saturating shift left"],["vqshl_s64","Signed saturating shift left"],["vqshl_s8","Signed saturating shift left"],["vqshl_u16","Unsigned saturating shift left"],["vqshl_u32","Unsigned saturating shift left"],["vqshl_u64","Unsigned saturating shift left"],["vqshl_u8","Unsigned saturating shift left"],["vqshlb_n_s8","Signed saturating shift left"],["vqshlb_n_u8","Unsigned saturating shift left"],["vqshlb_s8","Signed saturating shift left"],["vqshlb_u8","Unsigned saturating shift left"],["vqshld_n_s64","Signed saturating shift left"],["vqshld_n_u64","Unsigned saturating shift left"],["vqshld_s64","Signed saturating shift left"],["vqshld_u64","Unsigned saturating shift left"],["vqshlh_n_s16","Signed saturating shift left"],["vqshlh_n_u16","Unsigned saturating shift left"],["vqshlh_s16","Signed saturating shift left"],["vqshlh_u16","Unsigned saturating shift left"],["vqshlq_n_s16","Signed saturating shift left"],["vqshlq_n_s32","Signed saturating shift left"],["vqshlq_n_s64","Signed saturating shift left"],["vqshlq_n_s8","Signed saturating shift left"],["vqshlq_n_u16","Unsigned saturating shift left"],["vqshlq_n_u32","Unsigned saturating shift left"],["vqshlq_n_u64","Unsigned saturating shift left"],["vqshlq_n_u8","Unsigned saturating shift left"],["vqshlq_s16","Signed saturating shift left"],["vqshlq_s32","Signed saturating shift left"],["vqshlq_s64","Signed saturating shift left"],["vqshlq_s8","Signed saturating shift left"],["vqshlq_u16","Unsigned saturating shift left"],["vqshlq_u32","Unsigned saturating shift left"],["vqshlq_u64","Unsigned saturating shift left"],["vqshlq_u8","Unsigned saturating shift left"],["vqshls_n_s32","Signed saturating shift left"],["vqshls_n_u32","Unsigned saturating shift left"],["vqshls_s32","Signed saturating shift left"],["vqshls_u32","Unsigned saturating shift left"],["vqshlub_n_s8","Signed saturating shift left unsigned"],["vqshlud_n_s64","Signed saturating shift left unsigned"],["vqshluh_n_s16","Signed saturating shift left unsigned"],["vqshlus_n_s32","Signed saturating shift left unsigned"],["vqshrn_high_n_s16","Signed saturating shift right narrow"],["vqshrn_high_n_s32","Signed saturating shift right narrow"],["vqshrn_high_n_s64","Signed saturating shift right narrow"],["vqshrn_high_n_u16","Unsigned saturating shift right narrow"],["vqshrn_high_n_u32","Unsigned saturating shift right narrow"],["vqshrn_high_n_u64","Unsigned saturating shift right narrow"],["vqshrnd_n_s64","Signed saturating shift right narrow"],["vqshrnd_n_u64","Unsigned saturating shift right narrow"],["vqshrnh_n_s16","Signed saturating shift right narrow"],["vqshrnh_n_u16","Unsigned saturating shift right narrow"],["vqshrns_n_s32","Signed saturating shift right narrow"],["vqshrns_n_u32","Unsigned saturating shift right narrow"],["vqshrun_high_n_s16","Signed saturating shift right unsigned narrow"],["vqshrun_high_n_s32","Signed saturating shift right unsigned narrow"],["vqshrun_high_n_s64","Signed saturating shift right unsigned narrow"],["vqshrund_n_s64","Signed saturating shift right unsigned narrow"],["vqshrunh_n_s16","Signed saturating shift right unsigned narrow"],["vqshruns_n_s32","Signed saturating shift right unsigned narrow"],["vqsub_s16","Saturating subtract"],["vqsub_s32","Saturating subtract"],["vqsub_s64","Saturating subtract"],["vqsub_s8","Saturating subtract"],["vqsub_u16","Saturating subtract"],["vqsub_u32","Saturating subtract"],["vqsub_u64","Saturating subtract"],["vqsub_u8","Saturating subtract"],["vqsubb_s8","Saturating subtract"],["vqsubb_u8","Saturating subtract"],["vqsubd_s64","Saturating subtract"],["vqsubd_u64","Saturating subtract"],["vqsubh_s16","Saturating subtract"],["vqsubh_u16","Saturating subtract"],["vqsubq_s16","Saturating subtract"],["vqsubq_s32","Saturating subtract"],["vqsubq_s64","Saturating subtract"],["vqsubq_s8","Saturating subtract"],["vqsubq_u16","Saturating subtract"],["vqsubq_u32","Saturating subtract"],["vqsubq_u64","Saturating subtract"],["vqsubq_u8","Saturating subtract"],["vqsubs_s32","Saturating subtract"],["vqsubs_u32","Saturating subtract"],["vqtbl1_p8","Table look-up"],["vqtbl1_s8","Table look-up"],["vqtbl1_u8","Table look-up"],["vqtbl1q_p8","Table look-up"],["vqtbl1q_s8","Table look-up"],["vqtbl1q_u8","Table look-up"],["vqtbl2_p8","Table look-up"],["vqtbl2_s8","Table look-up"],["vqtbl2_u8","Table look-up"],["vqtbl2q_p8","Table look-up"],["vqtbl2q_s8","Table look-up"],["vqtbl2q_u8","Table look-up"],["vqtbl3_p8","Table look-up"],["vqtbl3_s8","Table look-up"],["vqtbl3_u8","Table look-up"],["vqtbl3q_p8","Table look-up"],["vqtbl3q_s8","Table look-up"],["vqtbl3q_u8","Table look-up"],["vqtbl4_p8","Table look-up"],["vqtbl4_s8","Table look-up"],["vqtbl4_u8","Table look-up"],["vqtbl4q_p8","Table look-up"],["vqtbl4q_s8","Table look-up"],["vqtbl4q_u8","Table look-up"],["vqtbx1_p8","Extended table look-up"],["vqtbx1_s8","Extended table look-up"],["vqtbx1_u8","Extended table look-up"],["vqtbx1q_p8","Extended table look-up"],["vqtbx1q_s8","Extended table look-up"],["vqtbx1q_u8","Extended table look-up"],["vqtbx2_p8","Extended table look-up"],["vqtbx2_s8","Extended table look-up"],["vqtbx2_u8","Extended table look-up"],["vqtbx2q_p8","Extended table look-up"],["vqtbx2q_s8","Extended table look-up"],["vqtbx2q_u8","Extended table look-up"],["vqtbx3_p8","Extended table look-up"],["vqtbx3_s8","Extended table look-up"],["vqtbx3_u8","Extended table look-up"],["vqtbx3q_p8","Extended table look-up"],["vqtbx3q_s8","Extended table look-up"],["vqtbx3q_u8","Extended table look-up"],["vqtbx4_p8","Extended table look-up"],["vqtbx4_s8","Extended table look-up"],["vqtbx4_u8","Extended table look-up"],["vqtbx4q_p8","Extended table look-up"],["vqtbx4q_s8","Extended table look-up"],["vqtbx4q_u8","Extended table look-up"],["vraddhn_high_s16","Rounding Add returning High Narrow (high half)."],["vraddhn_high_s32","Rounding Add returning High Narrow (high half)."],["vraddhn_high_s64","Rounding Add returning High Narrow (high half)."],["vraddhn_high_u16","Rounding Add returning High Narrow (high half)."],["vraddhn_high_u32","Rounding Add returning High Narrow (high half)."],["vraddhn_high_u64","Rounding Add returning High Narrow (high half)."],["vraddhn_s16","Rounding Add returning High Narrow."],["vraddhn_s32","Rounding Add returning High Narrow."],["vraddhn_s64","Rounding Add returning High Narrow."],["vraddhn_u16","Rounding Add returning High Narrow."],["vraddhn_u32","Rounding Add returning High Narrow."],["vraddhn_u64","Rounding Add returning High Narrow."],["vrax1q_u64","Rotate and exclusive OR"],["vrbit_p8","Reverse bit order"],["vrbit_s8","Reverse bit order"],["vrbit_u8","Reverse bit order"],["vrbitq_p8","Reverse bit order"],["vrbitq_s8","Reverse bit order"],["vrbitq_u8","Reverse bit order"],["vrecpe_f32","Reciprocal estimate."],["vrecpe_f64","Reciprocal estimate."],["vrecpe_u32","Unsigned reciprocal estimate"],["vrecped_f64","Reciprocal estimate."],["vrecpeq_f32","Reciprocal estimate."],["vrecpeq_f64","Reciprocal estimate."],["vrecpeq_u32","Unsigned reciprocal estimate"],["vrecpes_f32","Reciprocal estimate."],["vrecps_f32","Floating-point reciprocal step"],["vrecps_f64","Floating-point reciprocal step"],["vrecpsd_f64","Floating-point reciprocal step"],["vrecpsq_f32","Floating-point reciprocal step"],["vrecpsq_f64","Floating-point reciprocal step"],["vrecpss_f32","Floating-point reciprocal step"],["vrecpxd_f64","Floating-point reciprocal exponent"],["vrecpxs_f32","Floating-point reciprocal exponent"],["vreinterpret_f32_f64","Vector reinterpret cast operation"],["vreinterpret_f32_p16","Vector reinterpret cast operation"],["vreinterpret_f32_p64","Vector reinterpret cast operation"],["vreinterpret_f32_p8","Vector reinterpret cast operation"],["vreinterpret_f32_s16","Vector reinterpret cast operation"],["vreinterpret_f32_s32","Vector reinterpret cast operation"],["vreinterpret_f32_s64","Vector reinterpret cast operation"],["vreinterpret_f32_s8","Vector reinterpret cast operation"],["vreinterpret_f32_u16","Vector reinterpret cast operation"],["vreinterpret_f32_u32","Vector reinterpret cast operation"],["vreinterpret_f32_u64","Vector reinterpret cast operation"],["vreinterpret_f32_u8","Vector reinterpret cast operation"],["vreinterpret_f64_f32","Vector reinterpret cast operation"],["vreinterpret_f64_p16","Vector reinterpret cast operation"],["vreinterpret_f64_p64","Vector reinterpret cast operation"],["vreinterpret_f64_p8","Vector reinterpret cast operation"],["vreinterpret_f64_s16","Vector reinterpret cast operation"],["vreinterpret_f64_s32","Vector reinterpret cast operation"],["vreinterpret_f64_s64","Vector reinterpret cast operation"],["vreinterpret_f64_s8","Vector reinterpret cast operation"],["vreinterpret_f64_u16","Vector reinterpret cast operation"],["vreinterpret_f64_u32","Vector reinterpret cast operation"],["vreinterpret_f64_u64","Vector reinterpret cast operation"],["vreinterpret_f64_u8","Vector reinterpret cast operation"],["vreinterpret_p16_f32","Vector reinterpret cast operation"],["vreinterpret_p16_f64","Vector reinterpret cast operation"],["vreinterpret_p16_p64","Vector reinterpret cast operation"],["vreinterpret_p16_p8","Vector reinterpret cast operation"],["vreinterpret_p16_s16","Vector reinterpret cast operation"],["vreinterpret_p16_s32","Vector reinterpret cast operation"],["vreinterpret_p16_s64","Vector reinterpret cast operation"],["vreinterpret_p16_s8","Vector reinterpret cast operation"],["vreinterpret_p16_u16","Vector reinterpret cast operation"],["vreinterpret_p16_u32","Vector reinterpret cast operation"],["vreinterpret_p16_u64","Vector reinterpret cast operation"],["vreinterpret_p16_u8","Vector reinterpret cast operation"],["vreinterpret_p64_f32","Vector reinterpret cast operation"],["vreinterpret_p64_f64","Vector reinterpret cast operation"],["vreinterpret_p64_p16","Vector reinterpret cast operation"],["vreinterpret_p64_p8","Vector reinterpret cast operation"],["vreinterpret_p64_s16","Vector reinterpret cast operation"],["vreinterpret_p64_s32","Vector reinterpret cast operation"],["vreinterpret_p64_s64","Vector reinterpret cast operation"],["vreinterpret_p64_s8","Vector reinterpret cast operation"],["vreinterpret_p64_u16","Vector reinterpret cast operation"],["vreinterpret_p64_u32","Vector reinterpret cast operation"],["vreinterpret_p64_u64","Vector reinterpret cast operation"],["vreinterpret_p64_u8","Vector reinterpret cast operation"],["vreinterpret_p8_f32","Vector reinterpret cast operation"],["vreinterpret_p8_f64","Vector reinterpret cast operation"],["vreinterpret_p8_p16","Vector reinterpret cast operation"],["vreinterpret_p8_p64","Vector reinterpret cast operation"],["vreinterpret_p8_s16","Vector reinterpret cast operation"],["vreinterpret_p8_s32","Vector reinterpret cast operation"],["vreinterpret_p8_s64","Vector reinterpret cast operation"],["vreinterpret_p8_s8","Vector reinterpret cast operation"],["vreinterpret_p8_u16","Vector reinterpret cast operation"],["vreinterpret_p8_u32","Vector reinterpret cast operation"],["vreinterpret_p8_u64","Vector reinterpret cast operation"],["vreinterpret_p8_u8","Vector reinterpret cast operation"],["vreinterpret_s16_f32","Vector reinterpret cast operation"],["vreinterpret_s16_f64","Vector reinterpret cast operation"],["vreinterpret_s16_p16","Vector reinterpret cast operation"],["vreinterpret_s16_p64","Vector reinterpret cast operation"],["vreinterpret_s16_p8","Vector reinterpret cast operation"],["vreinterpret_s16_s32","Vector reinterpret cast operation"],["vreinterpret_s16_s64","Vector reinterpret cast operation"],["vreinterpret_s16_s8","Vector reinterpret cast operation"],["vreinterpret_s16_u16","Vector reinterpret cast operation"],["vreinterpret_s16_u32","Vector reinterpret cast operation"],["vreinterpret_s16_u64","Vector reinterpret cast operation"],["vreinterpret_s16_u8","Vector reinterpret cast operation"],["vreinterpret_s32_f32","Vector reinterpret cast operation"],["vreinterpret_s32_f64","Vector reinterpret cast operation"],["vreinterpret_s32_p16","Vector reinterpret cast operation"],["vreinterpret_s32_p64","Vector reinterpret cast operation"],["vreinterpret_s32_p8","Vector reinterpret cast operation"],["vreinterpret_s32_s16","Vector reinterpret cast operation"],["vreinterpret_s32_s64","Vector reinterpret cast operation"],["vreinterpret_s32_s8","Vector reinterpret cast operation"],["vreinterpret_s32_u16","Vector reinterpret cast operation"],["vreinterpret_s32_u32","Vector reinterpret cast operation"],["vreinterpret_s32_u64","Vector reinterpret cast operation"],["vreinterpret_s32_u8","Vector reinterpret cast operation"],["vreinterpret_s64_f32","Vector reinterpret cast operation"],["vreinterpret_s64_f64","Vector reinterpret cast operation"],["vreinterpret_s64_p16","Vector reinterpret cast operation"],["vreinterpret_s64_p64","Vector reinterpret cast operation"],["vreinterpret_s64_p8","Vector reinterpret cast operation"],["vreinterpret_s64_s16","Vector reinterpret cast operation"],["vreinterpret_s64_s32","Vector reinterpret cast operation"],["vreinterpret_s64_s8","Vector reinterpret cast operation"],["vreinterpret_s64_u16","Vector reinterpret cast operation"],["vreinterpret_s64_u32","Vector reinterpret cast operation"],["vreinterpret_s64_u64","Vector reinterpret cast operation"],["vreinterpret_s64_u8","Vector reinterpret cast operation"],["vreinterpret_s8_f32","Vector reinterpret cast operation"],["vreinterpret_s8_f64","Vector reinterpret cast operation"],["vreinterpret_s8_p16","Vector reinterpret cast operation"],["vreinterpret_s8_p64","Vector reinterpret cast operation"],["vreinterpret_s8_p8","Vector reinterpret cast operation"],["vreinterpret_s8_s16","Vector reinterpret cast operation"],["vreinterpret_s8_s32","Vector reinterpret cast operation"],["vreinterpret_s8_s64","Vector reinterpret cast operation"],["vreinterpret_s8_u16","Vector reinterpret cast operation"],["vreinterpret_s8_u32","Vector reinterpret cast operation"],["vreinterpret_s8_u64","Vector reinterpret cast operation"],["vreinterpret_s8_u8","Vector reinterpret cast operation"],["vreinterpret_u16_f32","Vector reinterpret cast operation"],["vreinterpret_u16_f64","Vector reinterpret cast operation"],["vreinterpret_u16_p16","Vector reinterpret cast operation"],["vreinterpret_u16_p64","Vector reinterpret cast operation"],["vreinterpret_u16_p8","Vector reinterpret cast operation"],["vreinterpret_u16_s16","Vector reinterpret cast operation"],["vreinterpret_u16_s32","Vector reinterpret cast operation"],["vreinterpret_u16_s64","Vector reinterpret cast operation"],["vreinterpret_u16_s8","Vector reinterpret cast operation"],["vreinterpret_u16_u32","Vector reinterpret cast operation"],["vreinterpret_u16_u64","Vector reinterpret cast operation"],["vreinterpret_u16_u8","Vector reinterpret cast operation"],["vreinterpret_u32_f32","Vector reinterpret cast operation"],["vreinterpret_u32_f64","Vector reinterpret cast operation"],["vreinterpret_u32_p16","Vector reinterpret cast operation"],["vreinterpret_u32_p64","Vector reinterpret cast operation"],["vreinterpret_u32_p8","Vector reinterpret cast operation"],["vreinterpret_u32_s16","Vector reinterpret cast operation"],["vreinterpret_u32_s32","Vector reinterpret cast operation"],["vreinterpret_u32_s64","Vector reinterpret cast operation"],["vreinterpret_u32_s8","Vector reinterpret cast operation"],["vreinterpret_u32_u16","Vector reinterpret cast operation"],["vreinterpret_u32_u64","Vector reinterpret cast operation"],["vreinterpret_u32_u8","Vector reinterpret cast operation"],["vreinterpret_u64_f32","Vector reinterpret cast operation"],["vreinterpret_u64_f64","Vector reinterpret cast operation"],["vreinterpret_u64_p16","Vector reinterpret cast operation"],["vreinterpret_u64_p64","Vector reinterpret cast operation"],["vreinterpret_u64_p8","Vector reinterpret cast operation"],["vreinterpret_u64_s16","Vector reinterpret cast operation"],["vreinterpret_u64_s32","Vector reinterpret cast operation"],["vreinterpret_u64_s64","Vector reinterpret cast operation"],["vreinterpret_u64_s8","Vector reinterpret cast operation"],["vreinterpret_u64_u16","Vector reinterpret cast operation"],["vreinterpret_u64_u32","Vector reinterpret cast operation"],["vreinterpret_u64_u8","Vector reinterpret cast operation"],["vreinterpret_u8_f32","Vector reinterpret cast operation"],["vreinterpret_u8_f64","Vector reinterpret cast operation"],["vreinterpret_u8_p16","Vector reinterpret cast operation"],["vreinterpret_u8_p64","Vector reinterpret cast operation"],["vreinterpret_u8_p8","Vector reinterpret cast operation"],["vreinterpret_u8_s16","Vector reinterpret cast operation"],["vreinterpret_u8_s32","Vector reinterpret cast operation"],["vreinterpret_u8_s64","Vector reinterpret cast operation"],["vreinterpret_u8_s8","Vector reinterpret cast operation"],["vreinterpret_u8_u16","Vector reinterpret cast operation"],["vreinterpret_u8_u32","Vector reinterpret cast operation"],["vreinterpret_u8_u64","Vector reinterpret cast operation"],["vreinterpretq_f32_f64","Vector reinterpret cast operation"],["vreinterpretq_f32_p128","Vector reinterpret cast operation"],["vreinterpretq_f32_p16","Vector reinterpret cast operation"],["vreinterpretq_f32_p64","Vector reinterpret cast operation"],["vreinterpretq_f32_p8","Vector reinterpret cast operation"],["vreinterpretq_f32_s16","Vector reinterpret cast operation"],["vreinterpretq_f32_s32","Vector reinterpret cast operation"],["vreinterpretq_f32_s64","Vector reinterpret cast operation"],["vreinterpretq_f32_s8","Vector reinterpret cast operation"],["vreinterpretq_f32_u16","Vector reinterpret cast operation"],["vreinterpretq_f32_u32","Vector reinterpret cast operation"],["vreinterpretq_f32_u64","Vector reinterpret cast operation"],["vreinterpretq_f32_u8","Vector reinterpret cast operation"],["vreinterpretq_f64_f32","Vector reinterpret cast operation"],["vreinterpretq_f64_p128","Vector reinterpret cast operation"],["vreinterpretq_f64_p16","Vector reinterpret cast operation"],["vreinterpretq_f64_p64","Vector reinterpret cast operation"],["vreinterpretq_f64_p8","Vector reinterpret cast operation"],["vreinterpretq_f64_s16","Vector reinterpret cast operation"],["vreinterpretq_f64_s32","Vector reinterpret cast operation"],["vreinterpretq_f64_s64","Vector reinterpret cast operation"],["vreinterpretq_f64_s8","Vector reinterpret cast operation"],["vreinterpretq_f64_u16","Vector reinterpret cast operation"],["vreinterpretq_f64_u32","Vector reinterpret cast operation"],["vreinterpretq_f64_u64","Vector reinterpret cast operation"],["vreinterpretq_f64_u8","Vector reinterpret cast operation"],["vreinterpretq_p128_f32","Vector reinterpret cast operation"],["vreinterpretq_p128_f64","Vector reinterpret cast operation"],["vreinterpretq_p128_p16","Vector reinterpret cast operation"],["vreinterpretq_p128_p64","Vector reinterpret cast operation"],["vreinterpretq_p128_p8","Vector reinterpret cast operation"],["vreinterpretq_p128_s16","Vector reinterpret cast operation"],["vreinterpretq_p128_s32","Vector reinterpret cast operation"],["vreinterpretq_p128_s64","Vector reinterpret cast operation"],["vreinterpretq_p128_s8","Vector reinterpret cast operation"],["vreinterpretq_p128_u16","Vector reinterpret cast operation"],["vreinterpretq_p128_u32","Vector reinterpret cast operation"],["vreinterpretq_p128_u64","Vector reinterpret cast operation"],["vreinterpretq_p128_u8","Vector reinterpret cast operation"],["vreinterpretq_p16_f32","Vector reinterpret cast operation"],["vreinterpretq_p16_f64","Vector reinterpret cast operation"],["vreinterpretq_p16_p128","Vector reinterpret cast operation"],["vreinterpretq_p16_p64","Vector reinterpret cast operation"],["vreinterpretq_p16_p8","Vector reinterpret cast operation"],["vreinterpretq_p16_s16","Vector reinterpret cast operation"],["vreinterpretq_p16_s32","Vector reinterpret cast operation"],["vreinterpretq_p16_s64","Vector reinterpret cast operation"],["vreinterpretq_p16_s8","Vector reinterpret cast operation"],["vreinterpretq_p16_u16","Vector reinterpret cast operation"],["vreinterpretq_p16_u32","Vector reinterpret cast operation"],["vreinterpretq_p16_u64","Vector reinterpret cast operation"],["vreinterpretq_p16_u8","Vector reinterpret cast operation"],["vreinterpretq_p64_f32","Vector reinterpret cast operation"],["vreinterpretq_p64_f64","Vector reinterpret cast operation"],["vreinterpretq_p64_p128","Vector reinterpret cast operation"],["vreinterpretq_p64_p16","Vector reinterpret cast operation"],["vreinterpretq_p64_p8","Vector reinterpret cast operation"],["vreinterpretq_p64_s16","Vector reinterpret cast operation"],["vreinterpretq_p64_s32","Vector reinterpret cast operation"],["vreinterpretq_p64_s64","Vector reinterpret cast operation"],["vreinterpretq_p64_s8","Vector reinterpret cast operation"],["vreinterpretq_p64_u16","Vector reinterpret cast operation"],["vreinterpretq_p64_u32","Vector reinterpret cast operation"],["vreinterpretq_p64_u64","Vector reinterpret cast operation"],["vreinterpretq_p64_u8","Vector reinterpret cast operation"],["vreinterpretq_p8_f32","Vector reinterpret cast operation"],["vreinterpretq_p8_f64","Vector reinterpret cast operation"],["vreinterpretq_p8_p128","Vector reinterpret cast operation"],["vreinterpretq_p8_p16","Vector reinterpret cast operation"],["vreinterpretq_p8_p64","Vector reinterpret cast operation"],["vreinterpretq_p8_s16","Vector reinterpret cast operation"],["vreinterpretq_p8_s32","Vector reinterpret cast operation"],["vreinterpretq_p8_s64","Vector reinterpret cast operation"],["vreinterpretq_p8_s8","Vector reinterpret cast operation"],["vreinterpretq_p8_u16","Vector reinterpret cast operation"],["vreinterpretq_p8_u32","Vector reinterpret cast operation"],["vreinterpretq_p8_u64","Vector reinterpret cast operation"],["vreinterpretq_p8_u8","Vector reinterpret cast operation"],["vreinterpretq_s16_f32","Vector reinterpret cast operation"],["vreinterpretq_s16_f64","Vector reinterpret cast operation"],["vreinterpretq_s16_p128","Vector reinterpret cast operation"],["vreinterpretq_s16_p16","Vector reinterpret cast operation"],["vreinterpretq_s16_p64","Vector reinterpret cast operation"],["vreinterpretq_s16_p8","Vector reinterpret cast operation"],["vreinterpretq_s16_s32","Vector reinterpret cast operation"],["vreinterpretq_s16_s64","Vector reinterpret cast operation"],["vreinterpretq_s16_s8","Vector reinterpret cast operation"],["vreinterpretq_s16_u16","Vector reinterpret cast operation"],["vreinterpretq_s16_u32","Vector reinterpret cast operation"],["vreinterpretq_s16_u64","Vector reinterpret cast operation"],["vreinterpretq_s16_u8","Vector reinterpret cast operation"],["vreinterpretq_s32_f32","Vector reinterpret cast operation"],["vreinterpretq_s32_f64","Vector reinterpret cast operation"],["vreinterpretq_s32_p128","Vector reinterpret cast operation"],["vreinterpretq_s32_p16","Vector reinterpret cast operation"],["vreinterpretq_s32_p64","Vector reinterpret cast operation"],["vreinterpretq_s32_p8","Vector reinterpret cast operation"],["vreinterpretq_s32_s16","Vector reinterpret cast operation"],["vreinterpretq_s32_s64","Vector reinterpret cast operation"],["vreinterpretq_s32_s8","Vector reinterpret cast operation"],["vreinterpretq_s32_u16","Vector reinterpret cast operation"],["vreinterpretq_s32_u32","Vector reinterpret cast operation"],["vreinterpretq_s32_u64","Vector reinterpret cast operation"],["vreinterpretq_s32_u8","Vector reinterpret cast operation"],["vreinterpretq_s64_f32","Vector reinterpret cast operation"],["vreinterpretq_s64_f64","Vector reinterpret cast operation"],["vreinterpretq_s64_p128","Vector reinterpret cast operation"],["vreinterpretq_s64_p16","Vector reinterpret cast operation"],["vreinterpretq_s64_p64","Vector reinterpret cast operation"],["vreinterpretq_s64_p8","Vector reinterpret cast operation"],["vreinterpretq_s64_s16","Vector reinterpret cast operation"],["vreinterpretq_s64_s32","Vector reinterpret cast operation"],["vreinterpretq_s64_s8","Vector reinterpret cast operation"],["vreinterpretq_s64_u16","Vector reinterpret cast operation"],["vreinterpretq_s64_u32","Vector reinterpret cast operation"],["vreinterpretq_s64_u64","Vector reinterpret cast operation"],["vreinterpretq_s64_u8","Vector reinterpret cast operation"],["vreinterpretq_s8_f32","Vector reinterpret cast operation"],["vreinterpretq_s8_f64","Vector reinterpret cast operation"],["vreinterpretq_s8_p128","Vector reinterpret cast operation"],["vreinterpretq_s8_p16","Vector reinterpret cast operation"],["vreinterpretq_s8_p64","Vector reinterpret cast operation"],["vreinterpretq_s8_p8","Vector reinterpret cast operation"],["vreinterpretq_s8_s16","Vector reinterpret cast operation"],["vreinterpretq_s8_s32","Vector reinterpret cast operation"],["vreinterpretq_s8_s64","Vector reinterpret cast operation"],["vreinterpretq_s8_u16","Vector reinterpret cast operation"],["vreinterpretq_s8_u32","Vector reinterpret cast operation"],["vreinterpretq_s8_u64","Vector reinterpret cast operation"],["vreinterpretq_s8_u8","Vector reinterpret cast operation"],["vreinterpretq_u16_f32","Vector reinterpret cast operation"],["vreinterpretq_u16_f64","Vector reinterpret cast operation"],["vreinterpretq_u16_p128","Vector reinterpret cast operation"],["vreinterpretq_u16_p16","Vector reinterpret cast operation"],["vreinterpretq_u16_p64","Vector reinterpret cast operation"],["vreinterpretq_u16_p8","Vector reinterpret cast operation"],["vreinterpretq_u16_s16","Vector reinterpret cast operation"],["vreinterpretq_u16_s32","Vector reinterpret cast operation"],["vreinterpretq_u16_s64","Vector reinterpret cast operation"],["vreinterpretq_u16_s8","Vector reinterpret cast operation"],["vreinterpretq_u16_u32","Vector reinterpret cast operation"],["vreinterpretq_u16_u64","Vector reinterpret cast operation"],["vreinterpretq_u16_u8","Vector reinterpret cast operation"],["vreinterpretq_u32_f32","Vector reinterpret cast operation"],["vreinterpretq_u32_f64","Vector reinterpret cast operation"],["vreinterpretq_u32_p128","Vector reinterpret cast operation"],["vreinterpretq_u32_p16","Vector reinterpret cast operation"],["vreinterpretq_u32_p64","Vector reinterpret cast operation"],["vreinterpretq_u32_p8","Vector reinterpret cast operation"],["vreinterpretq_u32_s16","Vector reinterpret cast operation"],["vreinterpretq_u32_s32","Vector reinterpret cast operation"],["vreinterpretq_u32_s64","Vector reinterpret cast operation"],["vreinterpretq_u32_s8","Vector reinterpret cast operation"],["vreinterpretq_u32_u16","Vector reinterpret cast operation"],["vreinterpretq_u32_u64","Vector reinterpret cast operation"],["vreinterpretq_u32_u8","Vector reinterpret cast operation"],["vreinterpretq_u64_f32","Vector reinterpret cast operation"],["vreinterpretq_u64_f64","Vector reinterpret cast operation"],["vreinterpretq_u64_p128","Vector reinterpret cast operation"],["vreinterpretq_u64_p16","Vector reinterpret cast operation"],["vreinterpretq_u64_p64","Vector reinterpret cast operation"],["vreinterpretq_u64_p8","Vector reinterpret cast operation"],["vreinterpretq_u64_s16","Vector reinterpret cast operation"],["vreinterpretq_u64_s32","Vector reinterpret cast operation"],["vreinterpretq_u64_s64","Vector reinterpret cast operation"],["vreinterpretq_u64_s8","Vector reinterpret cast operation"],["vreinterpretq_u64_u16","Vector reinterpret cast operation"],["vreinterpretq_u64_u32","Vector reinterpret cast operation"],["vreinterpretq_u64_u8","Vector reinterpret cast operation"],["vreinterpretq_u8_f32","Vector reinterpret cast operation"],["vreinterpretq_u8_f64","Vector reinterpret cast operation"],["vreinterpretq_u8_p128","Vector reinterpret cast operation"],["vreinterpretq_u8_p16","Vector reinterpret cast operation"],["vreinterpretq_u8_p64","Vector reinterpret cast operation"],["vreinterpretq_u8_p8","Vector reinterpret cast operation"],["vreinterpretq_u8_s16","Vector reinterpret cast operation"],["vreinterpretq_u8_s32","Vector reinterpret cast operation"],["vreinterpretq_u8_s64","Vector reinterpret cast operation"],["vreinterpretq_u8_s8","Vector reinterpret cast operation"],["vreinterpretq_u8_u16","Vector reinterpret cast operation"],["vreinterpretq_u8_u32","Vector reinterpret cast operation"],["vreinterpretq_u8_u64","Vector reinterpret cast operation"],["vrev16_p8","Reversing vector elements (swap endianness)"],["vrev16_s8","Reversing vector elements (swap endianness)"],["vrev16_u8","Reversing vector elements (swap endianness)"],["vrev16q_p8","Reversing vector elements (swap endianness)"],["vrev16q_s8","Reversing vector elements (swap endianness)"],["vrev16q_u8","Reversing vector elements (swap endianness)"],["vrev32_p16","Reversing vector elements (swap endianness)"],["vrev32_p8","Reversing vector elements (swap endianness)"],["vrev32_s16","Reversing vector elements (swap endianness)"],["vrev32_s8","Reversing vector elements (swap endianness)"],["vrev32_u16","Reversing vector elements (swap endianness)"],["vrev32_u8","Reversing vector elements (swap endianness)"],["vrev32q_p16","Reversing vector elements (swap endianness)"],["vrev32q_p8","Reversing vector elements (swap endianness)"],["vrev32q_s16","Reversing vector elements (swap endianness)"],["vrev32q_s8","Reversing vector elements (swap endianness)"],["vrev32q_u16","Reversing vector elements (swap endianness)"],["vrev32q_u8","Reversing vector elements (swap endianness)"],["vrev64_f32","Reversing vector elements (swap endianness)"],["vrev64_p16","Reversing vector elements (swap endianness)"],["vrev64_p8","Reversing vector elements (swap endianness)"],["vrev64_s16","Reversing vector elements (swap endianness)"],["vrev64_s32","Reversing vector elements (swap endianness)"],["vrev64_s8","Reversing vector elements (swap endianness)"],["vrev64_u16","Reversing vector elements (swap endianness)"],["vrev64_u32","Reversing vector elements (swap endianness)"],["vrev64_u8","Reversing vector elements (swap endianness)"],["vrev64q_f32","Reversing vector elements (swap endianness)"],["vrev64q_p16","Reversing vector elements (swap endianness)"],["vrev64q_p8","Reversing vector elements (swap endianness)"],["vrev64q_s16","Reversing vector elements (swap endianness)"],["vrev64q_s32","Reversing vector elements (swap endianness)"],["vrev64q_s8","Reversing vector elements (swap endianness)"],["vrev64q_u16","Reversing vector elements (swap endianness)"],["vrev64q_u32","Reversing vector elements (swap endianness)"],["vrev64q_u8","Reversing vector elements (swap endianness)"],["vrhadd_s16","Rounding halving add"],["vrhadd_s32","Rounding halving add"],["vrhadd_s8","Rounding halving add"],["vrhadd_u16","Rounding halving add"],["vrhadd_u32","Rounding halving add"],["vrhadd_u8","Rounding halving add"],["vrhaddq_s16","Rounding halving add"],["vrhaddq_s32","Rounding halving add"],["vrhaddq_s8","Rounding halving add"],["vrhaddq_u16","Rounding halving add"],["vrhaddq_u32","Rounding halving add"],["vrhaddq_u8","Rounding halving add"],["vrnd32x_f32","Floating-point round to 32-bit integer, using current rounding mode"],["vrnd32xq_f32","Floating-point round to 32-bit integer, using current rounding mode"],["vrnd32z_f32","Floating-point round to 32-bit integer toward zero"],["vrnd32zq_f32","Floating-point round to 32-bit integer toward zero"],["vrnd64x_f32","Floating-point round to 64-bit integer, using current rounding mode"],["vrnd64xq_f32","Floating-point round to 64-bit integer, using current rounding mode"],["vrnd64z_f32","Floating-point round to 64-bit integer toward zero"],["vrnd64zq_f32","Floating-point round to 64-bit integer toward zero"],["vrnd_f32","Floating-point round to integral, toward zero"],["vrnd_f64","Floating-point round to integral, toward zero"],["vrnda_f32","Floating-point round to integral, to nearest with ties to away"],["vrnda_f64","Floating-point round to integral, to nearest with ties to away"],["vrndaq_f32","Floating-point round to integral, to nearest with ties to away"],["vrndaq_f64","Floating-point round to integral, to nearest with ties to away"],["vrndi_f32","Floating-point round to integral, using current rounding mode"],["vrndi_f64","Floating-point round to integral, using current rounding mode"],["vrndiq_f32","Floating-point round to integral, using current rounding mode"],["vrndiq_f64","Floating-point round to integral, using current rounding mode"],["vrndm_f32","Floating-point round to integral, toward minus infinity"],["vrndm_f64","Floating-point round to integral, toward minus infinity"],["vrndmq_f32","Floating-point round to integral, toward minus infinity"],["vrndmq_f64","Floating-point round to integral, toward minus infinity"],["vrndn_f32","Floating-point round to integral, to nearest with ties to even"],["vrndn_f64","Floating-point round to integral, to nearest with ties to even"],["vrndnq_f32","Floating-point round to integral, to nearest with ties to even"],["vrndnq_f64","Floating-point round to integral, to nearest with ties to even"],["vrndns_f32","Floating-point round to integral, to nearest with ties to even"],["vrndp_f32","Floating-point round to integral, toward plus infinity"],["vrndp_f64","Floating-point round to integral, toward plus infinity"],["vrndpq_f32","Floating-point round to integral, toward plus infinity"],["vrndpq_f64","Floating-point round to integral, toward plus infinity"],["vrndq_f32","Floating-point round to integral, toward zero"],["vrndq_f64","Floating-point round to integral, toward zero"],["vrndx_f32","Floating-point round to integral exact, using current rounding mode"],["vrndx_f64","Floating-point round to integral exact, using current rounding mode"],["vrndxq_f32","Floating-point round to integral exact, using current rounding mode"],["vrndxq_f64","Floating-point round to integral exact, using current rounding mode"],["vrshl_s16","Signed rounding shift left"],["vrshl_s32","Signed rounding shift left"],["vrshl_s64","Signed rounding shift left"],["vrshl_s8","Signed rounding shift left"],["vrshl_u16","Unsigned rounding shift left"],["vrshl_u32","Unsigned rounding shift left"],["vrshl_u64","Unsigned rounding shift left"],["vrshl_u8","Unsigned rounding shift left"],["vrshld_s64","Signed rounding shift left"],["vrshld_u64","Unsigned rounding shift left"],["vrshlq_s16","Signed rounding shift left"],["vrshlq_s32","Signed rounding shift left"],["vrshlq_s64","Signed rounding shift left"],["vrshlq_s8","Signed rounding shift left"],["vrshlq_u16","Unsigned rounding shift left"],["vrshlq_u32","Unsigned rounding shift left"],["vrshlq_u64","Unsigned rounding shift left"],["vrshlq_u8","Unsigned rounding shift left"],["vrshr_n_s16","Signed rounding shift right"],["vrshr_n_s32","Signed rounding shift right"],["vrshr_n_s64","Signed rounding shift right"],["vrshr_n_s8","Signed rounding shift right"],["vrshr_n_u16","Unsigned rounding shift right"],["vrshr_n_u32","Unsigned rounding shift right"],["vrshr_n_u64","Unsigned rounding shift right"],["vrshr_n_u8","Unsigned rounding shift right"],["vrshrd_n_s64","Signed rounding shift right"],["vrshrd_n_u64","Unsigned rounding shift right"],["vrshrn_high_n_s16","Rounding shift right narrow"],["vrshrn_high_n_s32","Rounding shift right narrow"],["vrshrn_high_n_s64","Rounding shift right narrow"],["vrshrn_high_n_u16","Rounding shift right narrow"],["vrshrn_high_n_u32","Rounding shift right narrow"],["vrshrn_high_n_u64","Rounding shift right narrow"],["vrshrn_n_u16","Rounding shift right narrow"],["vrshrn_n_u32","Rounding shift right narrow"],["vrshrn_n_u64","Rounding shift right narrow"],["vrshrq_n_s16","Signed rounding shift right"],["vrshrq_n_s32","Signed rounding shift right"],["vrshrq_n_s64","Signed rounding shift right"],["vrshrq_n_s8","Signed rounding shift right"],["vrshrq_n_u16","Unsigned rounding shift right"],["vrshrq_n_u32","Unsigned rounding shift right"],["vrshrq_n_u64","Unsigned rounding shift right"],["vrshrq_n_u8","Unsigned rounding shift right"],["vrsqrte_f32","Reciprocal square-root estimate."],["vrsqrte_f64","Reciprocal square-root estimate."],["vrsqrte_u32","Unsigned reciprocal square root estimate"],["vrsqrted_f64","Reciprocal square-root estimate."],["vrsqrteq_f32","Reciprocal square-root estimate."],["vrsqrteq_f64","Reciprocal square-root estimate."],["vrsqrteq_u32","Unsigned reciprocal square root estimate"],["vrsqrtes_f32","Reciprocal square-root estimate."],["vrsqrts_f32","Floating-point reciprocal square root step"],["vrsqrts_f64","Floating-point reciprocal square root step"],["vrsqrtsd_f64","Floating-point reciprocal square root step"],["vrsqrtsq_f32","Floating-point reciprocal square root step"],["vrsqrtsq_f64","Floating-point reciprocal square root step"],["vrsqrtss_f32","Floating-point reciprocal square root step"],["vrsra_n_s16","Signed rounding shift right and accumulate"],["vrsra_n_s32","Signed rounding shift right and accumulate"],["vrsra_n_s64","Signed rounding shift right and accumulate"],["vrsra_n_s8","Signed rounding shift right and accumulate"],["vrsra_n_u16","Unsigned rounding shift right and accumulate"],["vrsra_n_u32","Unsigned rounding shift right and accumulate"],["vrsra_n_u64","Unsigned rounding shift right and accumulate"],["vrsra_n_u8","Unsigned rounding shift right and accumulate"],["vrsrad_n_s64","Signed rounding shift right and accumulate."],["vrsrad_n_u64","Ungisned rounding shift right and accumulate."],["vrsraq_n_s16","Signed rounding shift right and accumulate"],["vrsraq_n_s32","Signed rounding shift right and accumulate"],["vrsraq_n_s64","Signed rounding shift right and accumulate"],["vrsraq_n_s8","Signed rounding shift right and accumulate"],["vrsraq_n_u16","Unsigned rounding shift right and accumulate"],["vrsraq_n_u32","Unsigned rounding shift right and accumulate"],["vrsraq_n_u64","Unsigned rounding shift right and accumulate"],["vrsraq_n_u8","Unsigned rounding shift right and accumulate"],["vrsubhn_high_s16","Rounding subtract returning high narrow"],["vrsubhn_high_s32","Rounding subtract returning high narrow"],["vrsubhn_high_s64","Rounding subtract returning high narrow"],["vrsubhn_high_u16","Rounding subtract returning high narrow"],["vrsubhn_high_u32","Rounding subtract returning high narrow"],["vrsubhn_high_u64","Rounding subtract returning high narrow"],["vrsubhn_s16","Rounding subtract returning high narrow"],["vrsubhn_s32","Rounding subtract returning high narrow"],["vrsubhn_s64","Rounding subtract returning high narrow"],["vrsubhn_u16","Rounding subtract returning high narrow"],["vrsubhn_u32","Rounding subtract returning high narrow"],["vrsubhn_u64","Rounding subtract returning high narrow"],["vset_lane_f32","Insert vector element from another vector element"],["vset_lane_f64","Insert vector element from another vector element"],["vset_lane_p16","Insert vector element from another vector element"],["vset_lane_p64","Insert vector element from another vector element"],["vset_lane_p8","Insert vector element from another vector element"],["vset_lane_s16","Insert vector element from another vector element"],["vset_lane_s32","Insert vector element from another vector element"],["vset_lane_s64","Insert vector element from another vector element"],["vset_lane_s8","Insert vector element from another vector element"],["vset_lane_u16","Insert vector element from another vector element"],["vset_lane_u32","Insert vector element from another vector element"],["vset_lane_u64","Insert vector element from another vector element"],["vset_lane_u8","Insert vector element from another vector element"],["vsetq_lane_f32","Insert vector element from another vector element"],["vsetq_lane_f64","Insert vector element from another vector element"],["vsetq_lane_p16","Insert vector element from another vector element"],["vsetq_lane_p64","Insert vector element from another vector element"],["vsetq_lane_p8","Insert vector element from another vector element"],["vsetq_lane_s16","Insert vector element from another vector element"],["vsetq_lane_s32","Insert vector element from another vector element"],["vsetq_lane_s64","Insert vector element from another vector element"],["vsetq_lane_s8","Insert vector element from another vector element"],["vsetq_lane_u16","Insert vector element from another vector element"],["vsetq_lane_u32","Insert vector element from another vector element"],["vsetq_lane_u64","Insert vector element from another vector element"],["vsetq_lane_u8","Insert vector element from another vector element"],["vsha1cq_u32","SHA1 hash update accelerator, choose."],["vsha1h_u32","SHA1 fixed rotate."],["vsha1mq_u32","SHA1 hash update accelerator, majority."],["vsha1pq_u32","SHA1 hash update accelerator, parity."],["vsha1su0q_u32","SHA1 schedule update accelerator, first part."],["vsha1su1q_u32","SHA1 schedule update accelerator, second part."],["vsha256h2q_u32","SHA256 hash update accelerator, upper part."],["vsha256hq_u32","SHA256 hash update accelerator."],["vsha256su0q_u32","SHA256 schedule update accelerator, first part."],["vsha256su1q_u32","SHA256 schedule update accelerator, second part."],["vsha512h2q_u64","SHA512 hash update part 2"],["vsha512hq_u64","SHA512 hash update part 1"],["vsha512su0q_u64","SHA512 schedule update 0"],["vsha512su1q_u64","SHA512 schedule update 1"],["vshl_n_s16","Shift left"],["vshl_n_s32","Shift left"],["vshl_n_s64","Shift left"],["vshl_n_s8","Shift left"],["vshl_n_u16","Shift left"],["vshl_n_u32","Shift left"],["vshl_n_u64","Shift left"],["vshl_n_u8","Shift left"],["vshl_s16","Signed Shift left"],["vshl_s32","Signed Shift left"],["vshl_s64","Signed Shift left"],["vshl_s8","Signed Shift left"],["vshl_u16","Unsigned Shift left"],["vshl_u32","Unsigned Shift left"],["vshl_u64","Unsigned Shift left"],["vshl_u8","Unsigned Shift left"],["vshld_n_s64","Shift left"],["vshld_n_u64","Shift left"],["vshld_s64","Signed Shift left"],["vshld_u64","Unsigned Shift left"],["vshll_high_n_s16","Signed shift left long"],["vshll_high_n_s32","Signed shift left long"],["vshll_high_n_s8","Signed shift left long"],["vshll_high_n_u16","Signed shift left long"],["vshll_high_n_u32","Signed shift left long"],["vshll_high_n_u8","Signed shift left long"],["vshll_n_s16","Signed shift left long"],["vshll_n_s32","Signed shift left long"],["vshll_n_s8","Signed shift left long"],["vshll_n_u16","Signed shift left long"],["vshll_n_u32","Signed shift left long"],["vshll_n_u8","Signed shift left long"],["vshlq_n_s16","Shift left"],["vshlq_n_s32","Shift left"],["vshlq_n_s64","Shift left"],["vshlq_n_s8","Shift left"],["vshlq_n_u16","Shift left"],["vshlq_n_u32","Shift left"],["vshlq_n_u64","Shift left"],["vshlq_n_u8","Shift left"],["vshlq_s16","Signed Shift left"],["vshlq_s32","Signed Shift left"],["vshlq_s64","Signed Shift left"],["vshlq_s8","Signed Shift left"],["vshlq_u16","Unsigned Shift left"],["vshlq_u32","Unsigned Shift left"],["vshlq_u64","Unsigned Shift left"],["vshlq_u8","Unsigned Shift left"],["vshr_n_s16","Shift right"],["vshr_n_s32","Shift right"],["vshr_n_s64","Shift right"],["vshr_n_s8","Shift right"],["vshr_n_u16","Shift right"],["vshr_n_u32","Shift right"],["vshr_n_u64","Shift right"],["vshr_n_u8","Shift right"],["vshrd_n_s64","Signed shift right"],["vshrd_n_u64","Unsigned shift right"],["vshrn_high_n_s16","Shift right narrow"],["vshrn_high_n_s32","Shift right narrow"],["vshrn_high_n_s64","Shift right narrow"],["vshrn_high_n_u16","Shift right narrow"],["vshrn_high_n_u32","Shift right narrow"],["vshrn_high_n_u64","Shift right narrow"],["vshrn_n_s16","Shift right narrow"],["vshrn_n_s32","Shift right narrow"],["vshrn_n_s64","Shift right narrow"],["vshrn_n_u16","Shift right narrow"],["vshrn_n_u32","Shift right narrow"],["vshrn_n_u64","Shift right narrow"],["vshrq_n_s16","Shift right"],["vshrq_n_s32","Shift right"],["vshrq_n_s64","Shift right"],["vshrq_n_s8","Shift right"],["vshrq_n_u16","Shift right"],["vshrq_n_u32","Shift right"],["vshrq_n_u64","Shift right"],["vshrq_n_u8","Shift right"],["vsli_n_p16","Shift Left and Insert (immediate)"],["vsli_n_p64","Shift Left and Insert (immediate)"],["vsli_n_p8","Shift Left and Insert (immediate)"],["vsli_n_s16","Shift Left and Insert (immediate)"],["vsli_n_s32","Shift Left and Insert (immediate)"],["vsli_n_s64","Shift Left and Insert (immediate)"],["vsli_n_s8","Shift Left and Insert (immediate)"],["vsli_n_u16","Shift Left and Insert (immediate)"],["vsli_n_u32","Shift Left and Insert (immediate)"],["vsli_n_u64","Shift Left and Insert (immediate)"],["vsli_n_u8","Shift Left and Insert (immediate)"],["vslid_n_s64","Shift left and insert"],["vslid_n_u64","Shift left and insert"],["vsliq_n_p16","Shift Left and Insert (immediate)"],["vsliq_n_p64","Shift Left and Insert (immediate)"],["vsliq_n_p8","Shift Left and Insert (immediate)"],["vsliq_n_s16","Shift Left and Insert (immediate)"],["vsliq_n_s32","Shift Left and Insert (immediate)"],["vsliq_n_s64","Shift Left and Insert (immediate)"],["vsliq_n_s8","Shift Left and Insert (immediate)"],["vsliq_n_u16","Shift Left and Insert (immediate)"],["vsliq_n_u32","Shift Left and Insert (immediate)"],["vsliq_n_u64","Shift Left and Insert (immediate)"],["vsliq_n_u8","Shift Left and Insert (immediate)"],["vsm3partw1q_u32","SM3PARTW1"],["vsm3partw2q_u32","SM3PARTW2"],["vsm3ss1q_u32","SM3SS1"],["vsm3tt1aq_u32","SM3TT1A"],["vsm3tt1bq_u32","SM3TT1B"],["vsm3tt2aq_u32","SM3TT2A"],["vsm3tt2bq_u32","SM3TT2B"],["vsm4ekeyq_u32","SM4 key"],["vsm4eq_u32","SM4 encode"],["vsqadd_u16","Unsigned saturating Accumulate of Signed value."],["vsqadd_u32","Unsigned saturating Accumulate of Signed value."],["vsqadd_u64","Unsigned saturating Accumulate of Signed value."],["vsqadd_u8","Unsigned saturating Accumulate of Signed value."],["vsqaddb_u8","Unsigned saturating accumulate of signed value"],["vsqaddd_u64","Unsigned saturating accumulate of signed value"],["vsqaddh_u16","Unsigned saturating accumulate of signed value"],["vsqaddq_u16","Unsigned saturating Accumulate of Signed value."],["vsqaddq_u32","Unsigned saturating Accumulate of Signed value."],["vsqaddq_u64","Unsigned saturating Accumulate of Signed value."],["vsqaddq_u8","Unsigned saturating Accumulate of Signed value."],["vsqadds_u32","Unsigned saturating accumulate of signed value"],["vsqrt_f32","Calculates the square root of each lane."],["vsqrt_f64","Calculates the square root of each lane."],["vsqrtq_f32","Calculates the square root of each lane."],["vsqrtq_f64","Calculates the square root of each lane."],["vsra_n_s16","Signed shift right and accumulate"],["vsra_n_s32","Signed shift right and accumulate"],["vsra_n_s64","Signed shift right and accumulate"],["vsra_n_s8","Signed shift right and accumulate"],["vsra_n_u16","Unsigned shift right and accumulate"],["vsra_n_u32","Unsigned shift right and accumulate"],["vsra_n_u64","Unsigned shift right and accumulate"],["vsra_n_u8","Unsigned shift right and accumulate"],["vsrad_n_s64","Signed shift right and accumulate"],["vsrad_n_u64","Unsigned shift right and accumulate"],["vsraq_n_s16","Signed shift right and accumulate"],["vsraq_n_s32","Signed shift right and accumulate"],["vsraq_n_s64","Signed shift right and accumulate"],["vsraq_n_s8","Signed shift right and accumulate"],["vsraq_n_u16","Unsigned shift right and accumulate"],["vsraq_n_u32","Unsigned shift right and accumulate"],["vsraq_n_u64","Unsigned shift right and accumulate"],["vsraq_n_u8","Unsigned shift right and accumulate"],["vsri_n_p16","Shift Right and Insert (immediate)"],["vsri_n_p64","Shift Right and Insert (immediate)"],["vsri_n_p8","Shift Right and Insert (immediate)"],["vsri_n_s16","Shift Right and Insert (immediate)"],["vsri_n_s32","Shift Right and Insert (immediate)"],["vsri_n_s64","Shift Right and Insert (immediate)"],["vsri_n_s8","Shift Right and Insert (immediate)"],["vsri_n_u16","Shift Right and Insert (immediate)"],["vsri_n_u32","Shift Right and Insert (immediate)"],["vsri_n_u64","Shift Right and Insert (immediate)"],["vsri_n_u8","Shift Right and Insert (immediate)"],["vsrid_n_s64","Shift right and insert"],["vsrid_n_u64","Shift right and insert"],["vsriq_n_p16","Shift Right and Insert (immediate)"],["vsriq_n_p64","Shift Right and Insert (immediate)"],["vsriq_n_p8","Shift Right and Insert (immediate)"],["vsriq_n_s16","Shift Right and Insert (immediate)"],["vsriq_n_s32","Shift Right and Insert (immediate)"],["vsriq_n_s64","Shift Right and Insert (immediate)"],["vsriq_n_s8","Shift Right and Insert (immediate)"],["vsriq_n_u16","Shift Right and Insert (immediate)"],["vsriq_n_u32","Shift Right and Insert (immediate)"],["vsriq_n_u64","Shift Right and Insert (immediate)"],["vsriq_n_u8","Shift Right and Insert (immediate)"],["vst1_f32",""],["vst1_f64",""],["vst1_f64_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1_f64_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1_f64_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1_lane_f32","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_f64","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_p16","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_p64","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_p8","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_s16","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_s32","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_s64","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_s8","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_u16","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_u32","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_u64","Store multiple single-element structures from one, two, three, or four registers"],["vst1_lane_u8","Store multiple single-element structures from one, two, three, or four registers"],["vst1_p16","Store multiple single-element structures from one, two, three, or four registers."],["vst1_p16_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1_p16_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1_p16_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1_p64",""],["vst1_p64_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1_p64_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1_p64_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1_p8","Store multiple single-element structures from one, two, three, or four registers."],["vst1_p8_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1_p8_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1_p8_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1_s16","Store multiple single-element structures from one, two, three, or four registers."],["vst1_s32","Store multiple single-element structures from one, two, three, or four registers."],["vst1_s64","Store multiple single-element structures from one, two, three, or four registers."],["vst1_s8","Store multiple single-element structures from one, two, three, or four registers."],["vst1_u16","Store multiple single-element structures from one, two, three, or four registers."],["vst1_u16_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1_u16_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1_u16_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1_u32","Store multiple single-element structures from one, two, three, or four registers."],["vst1_u32_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1_u32_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1_u32_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1_u64","Store multiple single-element structures from one, two, three, or four registers."],["vst1_u64_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1_u64_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1_u64_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1_u8","Store multiple single-element structures from one, two, three, or four registers."],["vst1_u8_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1_u8_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1_u8_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_f32",""],["vst1q_f64",""],["vst1q_f64_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_f64_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_f64_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_lane_f32","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_f64","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_p16","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_p64","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_p8","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_s16","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_s32","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_s64","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_s8","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_u16","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_u32","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_u64","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_lane_u8","Store multiple single-element structures from one, two, three, or four registers"],["vst1q_p16","Store multiple single-element structures from one, two, three, or four registers."],["vst1q_p16_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_p16_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_p16_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_p64",""],["vst1q_p64_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_p64_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_p64_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_p8","Store multiple single-element structures from one, two, three, or four registers."],["vst1q_p8_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_p8_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_p8_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_s16","Store multiple single-element structures from one, two, three, or four registers."],["vst1q_s32","Store multiple single-element structures from one, two, three, or four registers."],["vst1q_s64","Store multiple single-element structures from one, two, three, or four registers."],["vst1q_s8","Store multiple single-element structures from one, two, three, or four registers."],["vst1q_u16","Store multiple single-element structures from one, two, three, or four registers."],["vst1q_u16_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_u16_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_u16_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_u32","Store multiple single-element structures from one, two, three, or four registers."],["vst1q_u32_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_u32_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_u32_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_u64","Store multiple single-element structures from one, two, three, or four registers."],["vst1q_u64_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_u64_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_u64_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_u8","Store multiple single-element structures from one, two, three, or four registers."],["vst1q_u8_x2","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_u8_x3","Store multiple single-element structures to one, two, three, or four registers"],["vst1q_u8_x4","Store multiple single-element structures to one, two, three, or four registers"],["vst2_f64","Store multiple 2-element structures from two registers"],["vst2_lane_f64","Store multiple 2-element structures from two registers"],["vst2_lane_p16","Store multiple 2-element structures from two registers"],["vst2_lane_p64","Store multiple 2-element structures from two registers"],["vst2_lane_p8","Store multiple 2-element structures from two registers"],["vst2_lane_s64","Store multiple 2-element structures from two registers"],["vst2_lane_u16","Store multiple 2-element structures from two registers"],["vst2_lane_u32","Store multiple 2-element structures from two registers"],["vst2_lane_u64","Store multiple 2-element structures from two registers"],["vst2_lane_u8","Store multiple 2-element structures from two registers"],["vst2_p16","Store multiple 2-element structures from two registers"],["vst2_p64","Store multiple 2-element structures from two registers"],["vst2_p8","Store multiple 2-element structures from two registers"],["vst2_u16","Store multiple 2-element structures from two registers"],["vst2_u32","Store multiple 2-element structures from two registers"],["vst2_u64","Store multiple 2-element structures from two registers"],["vst2_u8","Store multiple 2-element structures from two registers"],["vst2q_f64","Store multiple 2-element structures from two registers"],["vst2q_lane_f64","Store multiple 2-element structures from two registers"],["vst2q_lane_p16","Store multiple 2-element structures from two registers"],["vst2q_lane_p64","Store multiple 2-element structures from two registers"],["vst2q_lane_p8","Store multiple 2-element structures from two registers"],["vst2q_lane_s64","Store multiple 2-element structures from two registers"],["vst2q_lane_s8","Store multiple 2-element structures from two registers"],["vst2q_lane_u16","Store multiple 2-element structures from two registers"],["vst2q_lane_u32","Store multiple 2-element structures from two registers"],["vst2q_lane_u64","Store multiple 2-element structures from two registers"],["vst2q_lane_u8","Store multiple 2-element structures from two registers"],["vst2q_p16","Store multiple 2-element structures from two registers"],["vst2q_p64","Store multiple 2-element structures from two registers"],["vst2q_p8","Store multiple 2-element structures from two registers"],["vst2q_s64","Store multiple 2-element structures from two registers"],["vst2q_u16","Store multiple 2-element structures from two registers"],["vst2q_u32","Store multiple 2-element structures from two registers"],["vst2q_u64","Store multiple 2-element structures from two registers"],["vst2q_u8","Store multiple 2-element structures from two registers"],["vst3_f64","Store multiple 3-element structures from three registers"],["vst3_lane_f64","Store multiple 3-element structures from three registers"],["vst3_lane_p16","Store multiple 3-element structures from three registers"],["vst3_lane_p64","Store multiple 3-element structures from three registers"],["vst3_lane_p8","Store multiple 3-element structures from three registers"],["vst3_lane_s64","Store multiple 3-element structures from three registers"],["vst3_lane_u16","Store multiple 3-element structures from three registers"],["vst3_lane_u32","Store multiple 3-element structures from three registers"],["vst3_lane_u64","Store multiple 3-element structures from three registers"],["vst3_lane_u8","Store multiple 3-element structures from three registers"],["vst3_p16","Store multiple 3-element structures from three registers"],["vst3_p64","Store multiple 3-element structures from three registers"],["vst3_p8","Store multiple 3-element structures from three registers"],["vst3_u16","Store multiple 3-element structures from three registers"],["vst3_u32","Store multiple 3-element structures from three registers"],["vst3_u64","Store multiple 3-element structures from three registers"],["vst3_u8","Store multiple 3-element structures from three registers"],["vst3q_f64","Store multiple 3-element structures from three registers"],["vst3q_lane_f64","Store multiple 3-element structures from three registers"],["vst3q_lane_p16","Store multiple 3-element structures from three registers"],["vst3q_lane_p64","Store multiple 3-element structures from three registers"],["vst3q_lane_p8","Store multiple 3-element structures from three registers"],["vst3q_lane_s64","Store multiple 3-element structures from three registers"],["vst3q_lane_s8","Store multiple 3-element structures from three registers"],["vst3q_lane_u16","Store multiple 3-element structures from three registers"],["vst3q_lane_u32","Store multiple 3-element structures from three registers"],["vst3q_lane_u64","Store multiple 3-element structures from three registers"],["vst3q_lane_u8","Store multiple 3-element structures from three registers"],["vst3q_p16","Store multiple 3-element structures from three registers"],["vst3q_p64","Store multiple 3-element structures from three registers"],["vst3q_p8","Store multiple 3-element structures from three registers"],["vst3q_s64","Store multiple 3-element structures from three registers"],["vst3q_u16","Store multiple 3-element structures from three registers"],["vst3q_u32","Store multiple 3-element structures from three registers"],["vst3q_u64","Store multiple 3-element structures from three registers"],["vst3q_u8","Store multiple 3-element structures from three registers"],["vst4_f64","Store multiple 4-element structures from four registers"],["vst4_lane_f64","Store multiple 4-element structures from four registers"],["vst4_lane_p16","Store multiple 4-element structures from four registers"],["vst4_lane_p64","Store multiple 4-element structures from four registers"],["vst4_lane_p8","Store multiple 4-element structures from four registers"],["vst4_lane_s64","Store multiple 4-element structures from four registers"],["vst4_lane_u16","Store multiple 4-element structures from four registers"],["vst4_lane_u32","Store multiple 4-element structures from four registers"],["vst4_lane_u64","Store multiple 4-element structures from four registers"],["vst4_lane_u8","Store multiple 4-element structures from four registers"],["vst4_p16","Store multiple 4-element structures from four registers"],["vst4_p64","Store multiple 4-element structures from four registers"],["vst4_p8","Store multiple 4-element structures from four registers"],["vst4_u16","Store multiple 4-element structures from four registers"],["vst4_u32","Store multiple 4-element structures from four registers"],["vst4_u64","Store multiple 4-element structures from four registers"],["vst4_u8","Store multiple 4-element structures from four registers"],["vst4q_f64","Store multiple 4-element structures from four registers"],["vst4q_lane_f64","Store multiple 4-element structures from four registers"],["vst4q_lane_p16","Store multiple 4-element structures from four registers"],["vst4q_lane_p64","Store multiple 4-element structures from four registers"],["vst4q_lane_p8","Store multiple 4-element structures from four registers"],["vst4q_lane_s64","Store multiple 4-element structures from four registers"],["vst4q_lane_s8","Store multiple 4-element structures from four registers"],["vst4q_lane_u16","Store multiple 4-element structures from four registers"],["vst4q_lane_u32","Store multiple 4-element structures from four registers"],["vst4q_lane_u64","Store multiple 4-element structures from four registers"],["vst4q_lane_u8","Store multiple 4-element structures from four registers"],["vst4q_p16","Store multiple 4-element structures from four registers"],["vst4q_p64","Store multiple 4-element structures from four registers"],["vst4q_p8","Store multiple 4-element structures from four registers"],["vst4q_s64","Store multiple 4-element structures from four registers"],["vst4q_u16","Store multiple 4-element structures from four registers"],["vst4q_u32","Store multiple 4-element structures from four registers"],["vst4q_u64","Store multiple 4-element structures from four registers"],["vst4q_u8","Store multiple 4-element structures from four registers"],["vstrq_p128","Store SIMD&FP register (immediate offset)"],["vsub_f32","Subtract"],["vsub_f64","Subtract"],["vsub_s16","Subtract"],["vsub_s32","Subtract"],["vsub_s64","Subtract"],["vsub_s8","Subtract"],["vsub_u16","Subtract"],["vsub_u32","Subtract"],["vsub_u64","Subtract"],["vsub_u8","Subtract"],["vsubd_s64","Subtract"],["vsubd_u64","Subtract"],["vsubhn_high_s16","Subtract returning high narrow"],["vsubhn_high_s32","Subtract returning high narrow"],["vsubhn_high_s64","Subtract returning high narrow"],["vsubhn_high_u16","Subtract returning high narrow"],["vsubhn_high_u32","Subtract returning high narrow"],["vsubhn_high_u64","Subtract returning high narrow"],["vsubhn_s16","Subtract returning high narrow"],["vsubhn_s32","Subtract returning high narrow"],["vsubhn_s64","Subtract returning high narrow"],["vsubhn_u16","Subtract returning high narrow"],["vsubhn_u32","Subtract returning high narrow"],["vsubhn_u64","Subtract returning high narrow"],["vsubl_high_s16","Signed Subtract Long"],["vsubl_high_s32","Signed Subtract Long"],["vsubl_high_s8","Signed Subtract Long"],["vsubl_high_u16","Unsigned Subtract Long"],["vsubl_high_u32","Unsigned Subtract Long"],["vsubl_high_u8","Unsigned Subtract Long"],["vsubl_s16","Signed Subtract Long"],["vsubl_s32","Signed Subtract Long"],["vsubl_s8","Signed Subtract Long"],["vsubl_u16","Unsigned Subtract Long"],["vsubl_u32","Unsigned Subtract Long"],["vsubl_u8","Unsigned Subtract Long"],["vsubq_f32","Subtract"],["vsubq_f64","Subtract"],["vsubq_s16","Subtract"],["vsubq_s32","Subtract"],["vsubq_s64","Subtract"],["vsubq_s8","Subtract"],["vsubq_u16","Subtract"],["vsubq_u32","Subtract"],["vsubq_u64","Subtract"],["vsubq_u8","Subtract"],["vsubw_high_s16","Signed Subtract Wide"],["vsubw_high_s32","Signed Subtract Wide"],["vsubw_high_s8","Signed Subtract Wide"],["vsubw_high_u16","Unsigned Subtract Wide"],["vsubw_high_u32","Unsigned Subtract Wide"],["vsubw_high_u8","Unsigned Subtract Wide"],["vsubw_s16","Signed Subtract Wide"],["vsubw_s32","Signed Subtract Wide"],["vsubw_s8","Signed Subtract Wide"],["vsubw_u16","Unsigned Subtract Wide"],["vsubw_u32","Unsigned Subtract Wide"],["vsubw_u8","Unsigned Subtract Wide"],["vtbl1_p8","Table look-up"],["vtbl1_s8","Table look-up"],["vtbl1_u8","Table look-up"],["vtbl2_p8","Table look-up"],["vtbl2_s8","Table look-up"],["vtbl2_u8","Table look-up"],["vtbl3_p8","Table look-up"],["vtbl3_s8","Table look-up"],["vtbl3_u8","Table look-up"],["vtbl4_p8","Table look-up"],["vtbl4_s8","Table look-up"],["vtbl4_u8","Table look-up"],["vtbx1_p8","Extended table look-up"],["vtbx1_s8","Extended table look-up"],["vtbx1_u8","Extended table look-up"],["vtbx2_p8","Extended table look-up"],["vtbx2_s8","Extended table look-up"],["vtbx2_u8","Extended table look-up"],["vtbx3_p8","Extended table look-up"],["vtbx3_s8","Extended table look-up"],["vtbx3_u8","Extended table look-up"],["vtbx4_p8","Extended table look-up"],["vtbx4_s8","Extended table look-up"],["vtbx4_u8","Extended table look-up"],["vtrn1_f32","Transpose vectors"],["vtrn1_p16","Transpose vectors"],["vtrn1_p8","Transpose vectors"],["vtrn1_s16","Transpose vectors"],["vtrn1_s32","Transpose vectors"],["vtrn1_s8","Transpose vectors"],["vtrn1_u16","Transpose vectors"],["vtrn1_u32","Transpose vectors"],["vtrn1_u8","Transpose vectors"],["vtrn1q_f32","Transpose vectors"],["vtrn1q_f64","Transpose vectors"],["vtrn1q_p16","Transpose vectors"],["vtrn1q_p64","Transpose vectors"],["vtrn1q_p8","Transpose vectors"],["vtrn1q_s16","Transpose vectors"],["vtrn1q_s32","Transpose vectors"],["vtrn1q_s64","Transpose vectors"],["vtrn1q_s8","Transpose vectors"],["vtrn1q_u16","Transpose vectors"],["vtrn1q_u32","Transpose vectors"],["vtrn1q_u64","Transpose vectors"],["vtrn1q_u8","Transpose vectors"],["vtrn2_f32","Transpose vectors"],["vtrn2_p16","Transpose vectors"],["vtrn2_p8","Transpose vectors"],["vtrn2_s16","Transpose vectors"],["vtrn2_s32","Transpose vectors"],["vtrn2_s8","Transpose vectors"],["vtrn2_u16","Transpose vectors"],["vtrn2_u32","Transpose vectors"],["vtrn2_u8","Transpose vectors"],["vtrn2q_f32","Transpose vectors"],["vtrn2q_f64","Transpose vectors"],["vtrn2q_p16","Transpose vectors"],["vtrn2q_p64","Transpose vectors"],["vtrn2q_p8","Transpose vectors"],["vtrn2q_s16","Transpose vectors"],["vtrn2q_s32","Transpose vectors"],["vtrn2q_s64","Transpose vectors"],["vtrn2q_s8","Transpose vectors"],["vtrn2q_u16","Transpose vectors"],["vtrn2q_u32","Transpose vectors"],["vtrn2q_u64","Transpose vectors"],["vtrn2q_u8","Transpose vectors"],["vtrn_f32","Transpose elements"],["vtrn_p16","Transpose elements"],["vtrn_p8","Transpose elements"],["vtrn_s16","Transpose elements"],["vtrn_s32","Transpose elements"],["vtrn_s8","Transpose elements"],["vtrn_u16","Transpose elements"],["vtrn_u32","Transpose elements"],["vtrn_u8","Transpose elements"],["vtrnq_f32","Transpose elements"],["vtrnq_p16","Transpose elements"],["vtrnq_p8","Transpose elements"],["vtrnq_s16","Transpose elements"],["vtrnq_s32","Transpose elements"],["vtrnq_s8","Transpose elements"],["vtrnq_u16","Transpose elements"],["vtrnq_u32","Transpose elements"],["vtrnq_u8","Transpose elements"],["vtst_p16","Signed compare bitwise Test bits nonzero"],["vtst_p64","Signed compare bitwise Test bits nonzero"],["vtst_p8","Signed compare bitwise Test bits nonzero"],["vtst_s16","Signed compare bitwise Test bits nonzero"],["vtst_s32","Signed compare bitwise Test bits nonzero"],["vtst_s64","Signed compare bitwise Test bits nonzero"],["vtst_s8","Signed compare bitwise Test bits nonzero"],["vtst_u16","Unsigned compare bitwise Test bits nonzero"],["vtst_u32","Unsigned compare bitwise Test bits nonzero"],["vtst_u64","Unsigned compare bitwise Test bits nonzero"],["vtst_u8","Unsigned compare bitwise Test bits nonzero"],["vtstd_s64","Compare bitwise test bits nonzero"],["vtstd_u64","Compare bitwise test bits nonzero"],["vtstq_p16","Signed compare bitwise Test bits nonzero"],["vtstq_p64","Signed compare bitwise Test bits nonzero"],["vtstq_p8","Signed compare bitwise Test bits nonzero"],["vtstq_s16","Signed compare bitwise Test bits nonzero"],["vtstq_s32","Signed compare bitwise Test bits nonzero"],["vtstq_s64","Signed compare bitwise Test bits nonzero"],["vtstq_s8","Signed compare bitwise Test bits nonzero"],["vtstq_u16","Unsigned compare bitwise Test bits nonzero"],["vtstq_u32","Unsigned compare bitwise Test bits nonzero"],["vtstq_u64","Unsigned compare bitwise Test bits nonzero"],["vtstq_u8","Unsigned compare bitwise Test bits nonzero"],["vuqadd_s16","Signed saturating Accumulate of Unsigned value."],["vuqadd_s32","Signed saturating Accumulate of Unsigned value."],["vuqadd_s64","Signed saturating Accumulate of Unsigned value."],["vuqadd_s8","Signed saturating Accumulate of Unsigned value."],["vuqaddb_s8","Signed saturating accumulate of unsigned value"],["vuqaddd_s64","Signed saturating accumulate of unsigned value"],["vuqaddh_s16","Signed saturating accumulate of unsigned value"],["vuqaddq_s16","Signed saturating Accumulate of Unsigned value."],["vuqaddq_s32","Signed saturating Accumulate of Unsigned value."],["vuqaddq_s64","Signed saturating Accumulate of Unsigned value."],["vuqaddq_s8","Signed saturating Accumulate of Unsigned value."],["vuqadds_s32","Signed saturating accumulate of unsigned value"],["vusmmlaq_s32","Unsigned and signed 8-bit integer matrix multiply-accumulate"],["vuzp1_f32","Unzip vectors"],["vuzp1_p16","Unzip vectors"],["vuzp1_p8","Unzip vectors"],["vuzp1_s16","Unzip vectors"],["vuzp1_s32","Unzip vectors"],["vuzp1_s8","Unzip vectors"],["vuzp1_u16","Unzip vectors"],["vuzp1_u32","Unzip vectors"],["vuzp1_u8","Unzip vectors"],["vuzp1q_f32","Unzip vectors"],["vuzp1q_f64","Unzip vectors"],["vuzp1q_p16","Unzip vectors"],["vuzp1q_p64","Unzip vectors"],["vuzp1q_p8","Unzip vectors"],["vuzp1q_s16","Unzip vectors"],["vuzp1q_s32","Unzip vectors"],["vuzp1q_s64","Unzip vectors"],["vuzp1q_s8","Unzip vectors"],["vuzp1q_u16","Unzip vectors"],["vuzp1q_u32","Unzip vectors"],["vuzp1q_u64","Unzip vectors"],["vuzp1q_u8","Unzip vectors"],["vuzp2_f32","Unzip vectors"],["vuzp2_p16","Unzip vectors"],["vuzp2_p8","Unzip vectors"],["vuzp2_s16","Unzip vectors"],["vuzp2_s32","Unzip vectors"],["vuzp2_s8","Unzip vectors"],["vuzp2_u16","Unzip vectors"],["vuzp2_u32","Unzip vectors"],["vuzp2_u8","Unzip vectors"],["vuzp2q_f32","Unzip vectors"],["vuzp2q_f64","Unzip vectors"],["vuzp2q_p16","Unzip vectors"],["vuzp2q_p64","Unzip vectors"],["vuzp2q_p8","Unzip vectors"],["vuzp2q_s16","Unzip vectors"],["vuzp2q_s32","Unzip vectors"],["vuzp2q_s64","Unzip vectors"],["vuzp2q_s8","Unzip vectors"],["vuzp2q_u16","Unzip vectors"],["vuzp2q_u32","Unzip vectors"],["vuzp2q_u64","Unzip vectors"],["vuzp2q_u8","Unzip vectors"],["vuzp_f32","Unzip vectors"],["vuzp_p16","Unzip vectors"],["vuzp_p8","Unzip vectors"],["vuzp_s16","Unzip vectors"],["vuzp_s32","Unzip vectors"],["vuzp_s8","Unzip vectors"],["vuzp_u16","Unzip vectors"],["vuzp_u32","Unzip vectors"],["vuzp_u8","Unzip vectors"],["vuzpq_f32","Unzip vectors"],["vuzpq_p16","Unzip vectors"],["vuzpq_p8","Unzip vectors"],["vuzpq_s16","Unzip vectors"],["vuzpq_s32","Unzip vectors"],["vuzpq_s8","Unzip vectors"],["vuzpq_u16","Unzip vectors"],["vuzpq_u32","Unzip vectors"],["vuzpq_u8","Unzip vectors"],["vxarq_u64","Exclusive OR and rotate"],["vzip1_f32","Zip vectors"],["vzip1_p16","Zip vectors"],["vzip1_p8","Zip vectors"],["vzip1_s16","Zip vectors"],["vzip1_s32","Zip vectors"],["vzip1_s8","Zip vectors"],["vzip1_u16","Zip vectors"],["vzip1_u32","Zip vectors"],["vzip1_u8","Zip vectors"],["vzip1q_f32","Zip vectors"],["vzip1q_f64","Zip vectors"],["vzip1q_p16","Zip vectors"],["vzip1q_p64","Zip vectors"],["vzip1q_p8","Zip vectors"],["vzip1q_s16","Zip vectors"],["vzip1q_s32","Zip vectors"],["vzip1q_s64","Zip vectors"],["vzip1q_s8","Zip vectors"],["vzip1q_u16","Zip vectors"],["vzip1q_u32","Zip vectors"],["vzip1q_u64","Zip vectors"],["vzip1q_u8","Zip vectors"],["vzip2_f32","Zip vectors"],["vzip2_p16","Zip vectors"],["vzip2_p8","Zip vectors"],["vzip2_s16","Zip vectors"],["vzip2_s32","Zip vectors"],["vzip2_s8","Zip vectors"],["vzip2_u16","Zip vectors"],["vzip2_u32","Zip vectors"],["vzip2_u8","Zip vectors"],["vzip2q_f32","Zip vectors"],["vzip2q_f64","Zip vectors"],["vzip2q_p16","Zip vectors"],["vzip2q_p64","Zip vectors"],["vzip2q_p8","Zip vectors"],["vzip2q_s16","Zip vectors"],["vzip2q_s32","Zip vectors"],["vzip2q_s64","Zip vectors"],["vzip2q_s8","Zip vectors"],["vzip2q_u16","Zip vectors"],["vzip2q_u32","Zip vectors"],["vzip2q_u64","Zip vectors"],["vzip2q_u8","Zip vectors"],["vzip_f32","Zip vectors"],["vzip_p16","Zip vectors"],["vzip_p8","Zip vectors"],["vzip_s16","Zip vectors"],["vzip_s32","Zip vectors"],["vzip_s8","Zip vectors"],["vzip_u16","Zip vectors"],["vzip_u32","Zip vectors"],["vzip_u8","Zip vectors"],["vzipq_f32","Zip vectors"],["vzipq_p16","Zip vectors"],["vzipq_p8","Zip vectors"],["vzipq_s16","Zip vectors"],["vzipq_s32","Zip vectors"],["vzipq_s8","Zip vectors"],["vzipq_u16","Zip vectors"],["vzipq_u32","Zip vectors"],["vzipq_u8","Zip vectors"]],"struct":[["APSR","Application Program Status Register"],["SY","Full system is the required shareability domain, reads and writes are the required access types"],["float32x2_t","ARM-specific 64-bit wide vector of two packed `f32`."],["float32x2x2_t","ARM-specific type containing two `float32x2_t` vectors."],["float32x2x3_t","ARM-specific type containing three `float32x2_t` vectors."],["float32x2x4_t","ARM-specific type containing four `float32x2_t` vectors."],["float32x4_t","ARM-specific 128-bit wide vector of four packed `f32`."],["float32x4x2_t","ARM-specific type containing two `float32x4_t` vectors."],["float32x4x3_t","ARM-specific type containing three `float32x4_t` vectors."],["float32x4x4_t","ARM-specific type containing four `float32x4_t` vectors."],["float64x1_t","ARM-specific 64-bit wide vector of one packed `f64`."],["float64x1x2_t","ARM-specific type containing two `float64x1_t` vectors."],["float64x1x3_t","ARM-specific type containing three `float64x1_t` vectors."],["float64x1x4_t","ARM-specific type containing four `float64x1_t` vectors."],["float64x2_t","ARM-specific 128-bit wide vector of two packed `f64`."],["float64x2x2_t","ARM-specific type containing two `float64x2_t` vectors."],["float64x2x3_t","ARM-specific type containing three `float64x2_t` vectors."],["float64x2x4_t","ARM-specific type containing four `float64x2_t` vectors."],["int16x4_t","ARM-specific 64-bit wide vector of four packed `i16`."],["int16x4x2_t","ARM-specific type containing two `int16x4_t` vectors."],["int16x4x3_t","ARM-specific type containing three `int16x4_t` vectors."],["int16x4x4_t","ARM-specific type containing four `int16x4_t` vectors."],["int16x8_t","ARM-specific 128-bit wide vector of eight packed `i16`."],["int16x8x2_t","ARM-specific type containing two `int16x8_t` vectors."],["int16x8x3_t","ARM-specific type containing three `int16x8_t` vectors."],["int16x8x4_t","ARM-specific type containing four `int16x8_t` vectors."],["int32x2_t","ARM-specific 64-bit wide vector of two packed `i32`."],["int32x2x2_t","ARM-specific type containing two `int32x2_t` vectors."],["int32x2x3_t","ARM-specific type containing three `int32x2_t` vectors."],["int32x2x4_t","ARM-specific type containing four `int32x2_t` vectors."],["int32x4_t","ARM-specific 128-bit wide vector of four packed `i32`."],["int32x4x2_t","ARM-specific type containing two `int32x4_t` vectors."],["int32x4x3_t","ARM-specific type containing three `int32x4_t` vectors."],["int32x4x4_t","ARM-specific type containing four `int32x4_t` vectors."],["int64x1_t","ARM-specific 64-bit wide vector of one packed `i64`."],["int64x1x2_t","ARM-specific type containing four `int64x1_t` vectors."],["int64x1x3_t","ARM-specific type containing four `int64x1_t` vectors."],["int64x1x4_t","ARM-specific type containing four `int64x1_t` vectors."],["int64x2_t","ARM-specific 128-bit wide vector of two packed `i64`."],["int64x2x2_t","ARM-specific type containing four `int64x2_t` vectors."],["int64x2x3_t","ARM-specific type containing four `int64x2_t` vectors."],["int64x2x4_t","ARM-specific type containing four `int64x2_t` vectors."],["int8x16_t","ARM-specific 128-bit wide vector of sixteen packed `i8`."],["int8x16x2_t","ARM-specific type containing two `int8x16_t` vectors."],["int8x16x3_t","ARM-specific type containing three `int8x16_t` vectors."],["int8x16x4_t","ARM-specific type containing four `int8x16_t` vectors."],["int8x8_t","ARM-specific 64-bit wide vector of eight packed `i8`."],["int8x8x2_t","ARM-specific type containing two `int8x8_t` vectors."],["int8x8x3_t","ARM-specific type containing three `int8x8_t` vectors."],["int8x8x4_t","ARM-specific type containing four `int8x8_t` vectors."],["poly16x4_t","ARM-specific 64-bit wide vector of four packed `p16`."],["poly16x4x2_t","ARM-specific type containing two `poly16x4_t` vectors."],["poly16x4x3_t","ARM-specific type containing three `poly16x4_t` vectors."],["poly16x4x4_t","ARM-specific type containing four `poly16x4_t` vectors."],["poly16x8_t","ARM-specific 128-bit wide vector of eight packed `p16`."],["poly16x8x2_t","ARM-specific type containing two `poly16x8_t` vectors."],["poly16x8x3_t","ARM-specific type containing three `poly16x8_t` vectors."],["poly16x8x4_t","ARM-specific type containing four `poly16x8_t` vectors."],["poly64x1_t","ARM-specific 64-bit wide vector of one packed `p64`."],["poly64x1x2_t","ARM-specific type containing four `poly64x1_t` vectors."],["poly64x1x3_t","ARM-specific type containing four `poly64x1_t` vectors."],["poly64x1x4_t","ARM-specific type containing four `poly64x1_t` vectors."],["poly64x2_t","ARM-specific 128-bit wide vector of two packed `p64`."],["poly64x2x2_t","ARM-specific type containing four `poly64x2_t` vectors."],["poly64x2x3_t","ARM-specific type containing four `poly64x2_t` vectors."],["poly64x2x4_t","ARM-specific type containing four `poly64x2_t` vectors."],["poly8x16_t","ARM-specific 128-bit wide vector of sixteen packed `p8`."],["poly8x16x2_t","ARM-specific type containing two `poly8x16_t` vectors."],["poly8x16x3_t","ARM-specific type containing three `poly8x16_t` vectors."],["poly8x16x4_t","ARM-specific type containing four `poly8x16_t` vectors."],["poly8x8_t","ARM-specific 64-bit wide polynomial vector of eight packed `p8`."],["poly8x8x2_t","ARM-specific type containing two `poly8x8_t` vectors."],["poly8x8x3_t","ARM-specific type containing three `poly8x8_t` vectors."],["poly8x8x4_t","ARM-specific type containing four `poly8x8_t` vectors."],["uint16x4_t","ARM-specific 64-bit wide vector of four packed `u16`."],["uint16x4x2_t","ARM-specific type containing two `uint16x4_t` vectors."],["uint16x4x3_t","ARM-specific type containing three `uint16x4_t` vectors."],["uint16x4x4_t","ARM-specific type containing four `uint16x4_t` vectors."],["uint16x8_t","ARM-specific 128-bit wide vector of eight packed `u16`."],["uint16x8x2_t","ARM-specific type containing two `uint16x8_t` vectors."],["uint16x8x3_t","ARM-specific type containing three `uint16x8_t` vectors."],["uint16x8x4_t","ARM-specific type containing four `uint16x8_t` vectors."],["uint32x2_t","ARM-specific 64-bit wide vector of two packed `u32`."],["uint32x2x2_t","ARM-specific type containing two `uint32x2_t` vectors."],["uint32x2x3_t","ARM-specific type containing three `uint32x2_t` vectors."],["uint32x2x4_t","ARM-specific type containing four `uint32x2_t` vectors."],["uint32x4_t","ARM-specific 128-bit wide vector of four packed `u32`."],["uint32x4x2_t","ARM-specific type containing two `uint32x4_t` vectors."],["uint32x4x3_t","ARM-specific type containing three `uint32x4_t` vectors."],["uint32x4x4_t","ARM-specific type containing four `uint32x4_t` vectors."],["uint64x1_t","ARM-specific 64-bit wide vector of one packed `u64`."],["uint64x1x2_t","ARM-specific type containing four `uint64x1_t` vectors."],["uint64x1x3_t","ARM-specific type containing four `uint64x1_t` vectors."],["uint64x1x4_t","ARM-specific type containing four `uint64x1_t` vectors."],["uint64x2_t","ARM-specific 128-bit wide vector of two packed `u64`."],["uint64x2x2_t","ARM-specific type containing four `uint64x2_t` vectors."],["uint64x2x3_t","ARM-specific type containing four `uint64x2_t` vectors."],["uint64x2x4_t","ARM-specific type containing four `uint64x2_t` vectors."],["uint8x16_t","ARM-specific 128-bit wide vector of sixteen packed `u8`."],["uint8x16x2_t","ARM-specific type containing two `uint8x16_t` vectors."],["uint8x16x3_t","ARM-specific type containing three `uint8x16_t` vectors."],["uint8x16x4_t","ARM-specific type containing four `uint8x16_t` vectors."],["uint8x8_t","ARM-specific 64-bit wide vector of eight packed `u8`."],["uint8x8x2_t","ARM-specific type containing two `uint8x8_t` vectors."],["uint8x8x3_t","ARM-specific type containing three `uint8x8_t` vectors."],["uint8x8x4_t","ARM-specific type containing four `uint8x8_t` vectors."]]});